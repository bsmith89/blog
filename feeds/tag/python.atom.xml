<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Deep Ecology - python</title><link href="//blog.byronjsmith.com/" rel="alternate"></link><link href="//blog.byronjsmith.com/feeds/tag/python.atom.xml" rel="self"></link><id>//blog.byronjsmith.com/</id><updated>2017-11-21T09:30:00-05:00</updated><subtitle>A blog of the new microbiology.</subtitle><entry><title>Tutorial: Reproducible data analysis pipelines using Snakemake</title><link href="//blog.byronjsmith.com/snakemake-analysis.html" rel="alternate"></link><published>2017-11-19T17:00:00-05:00</published><updated>2017-11-19T17:00:00-05:00</updated><author><name>Byron J. Smith</name></author><id>tag:blog.byronjsmith.com,2017-11-19:/snakemake-analysis.html</id><summary type="html">&lt;p&gt;In many areas of natural and social science, as well as engineering, data
analysis involves a series of transformations: filtering, aggregating,
comparing to theoretical models, culminating in the visualization and
communication of results.
This process is rarely static, however, and
components of the analysis pipeline are frequently subject to replacement
and refinement, resulting in challenges for reproducing computational
results.
Describing data analysis as a directed network of transformations
has proven useful for translating between human intuition and computer
automation.
In the past I've &lt;a href="//blog.byronjsmith.com/makefile-shortcuts.html"&gt;evangelized extensively for GNU Make&lt;/a&gt;,
which takes advantage of this graph representation to enable incremental builds
and parallelization.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Snakemake&lt;/em&gt; is a next-generation tool based on this concept and designed
specifically for bioinformatics and other complex, computationally
challenging analyses.
I've started using &lt;em&gt;Snakemake&lt;/em&gt; for my own data analysis projects, and I've
found it to be a consistent improvement, enabling more complex pipelines with
fewer of the "hacks" that …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In many areas of natural and social science, as well as engineering, data
analysis involves a series of transformations: filtering, aggregating,
comparing to theoretical models, culminating in the visualization and
communication of results.
This process is rarely static, however, and
components of the analysis pipeline are frequently subject to replacement
and refinement, resulting in challenges for reproducing computational
results.
Describing data analysis as a directed network of transformations
has proven useful for translating between human intuition and computer
automation.
In the past I've &lt;a href="//blog.byronjsmith.com/makefile-shortcuts.html"&gt;evangelized extensively for GNU Make&lt;/a&gt;,
which takes advantage of this graph representation to enable incremental builds
and parallelization.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Snakemake&lt;/em&gt; is a next-generation tool based on this concept and designed
specifically for bioinformatics and other complex, computationally
challenging analyses.
I've started using &lt;em&gt;Snakemake&lt;/em&gt; for my own data analysis projects, and I've
found it to be a consistent improvement, enabling more complex pipelines with
fewer of the "hacks" that are often necessary when using &lt;em&gt;Make&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;I've taught &lt;a href="//blog.byronjsmith.com/make-analysis.html"&gt;&lt;em&gt;Make&lt;/em&gt; workshops in the past&lt;/a&gt;,
so, when I was invited to present to the Boise State University Joint
User Groups, I was excited to convert that tutorial to &lt;em&gt;Snakemake&lt;/em&gt;.
Here, I've converted that tutorial into a blog post.
The original (and therefore this lesson as well) is inspired by the
&lt;a href="https://swcarpentry.github.io/make-novice/"&gt;Software Carpentry &lt;em&gt;Make&lt;/em&gt; lesson&lt;/a&gt;,
to which I am also a contributor.&lt;/p&gt;
&lt;p&gt;Some prior experience with the command line is assumed, and learners are
encouraged to follow along on their own computers.
The entire tutorial, including questions for the learner are designed to
take 2 hours as a live-coded, Software Carpentry style lesson.
A standalone lesson repository can be found &lt;a href="https://github.com/bsmith89/snakemake-boise"&gt;here&lt;/a&gt; and is
licensed CC-BY.&lt;/p&gt;
&lt;h1&gt;Setup&lt;/h1&gt;
&lt;p&gt;If not already on your computer, install the following prerequistes.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A &lt;em&gt;Bash&lt;/em&gt; terminal&lt;/li&gt;
&lt;li&gt;Python 3.6 and the following packages&lt;ul&gt;
&lt;li&gt;&lt;code&gt;snakemake&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;matplotlib&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;numpy&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The lesson assumes the following programs are also installed, but
    they're not absolutely necessary for the flow of the lesson,
    and/or alternatives are widely available:&lt;ul&gt;
&lt;li&gt;&lt;code&gt;head&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nano&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dot&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tree&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://github.com/bsmith89/zipf-example"&gt;This example directory&lt;/a&gt; should be downloaded to the user's
desktop and navigated into at the command line.
(e.g. &lt;code&gt;git clone https://github.com/bsmith89/zipf-example; cd zipf-example&lt;/code&gt;)&lt;/p&gt;
&lt;h1&gt;Motivation&lt;/h1&gt;
&lt;h2&gt;Zipf's Law [10 minutes]&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;The most frequently-occurring word occurs approximately twice as
often as the second most frequent word. This is
&lt;a href="http://en.wikipedia.org/wiki/Zipf%27s_law"&gt;Zipf's Law&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let's imagine that we're interested in testing Zipf's law in some of our
favorite books.
We've compiled our raw data: the books we want to analyze,
and have prepared several Python scripts that together make up our
analysis pipeline.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;tree&lt;/code&gt; command produces a handy tree-diagram of the directory.
(You may not have this program installed on your computer.)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="n"&gt;analysis&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sh&lt;/span&gt;
&lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="n"&gt;books&lt;/span&gt;
&lt;span class="err"&gt;│&lt;/span&gt;   &lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="n"&gt;LICENSE_TEXTS&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;md&lt;/span&gt;
&lt;span class="err"&gt;│&lt;/span&gt;   &lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="n"&gt;abyss&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;txt&lt;/span&gt;
&lt;span class="err"&gt;│&lt;/span&gt;   &lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="n"&gt;isles&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;txt&lt;/span&gt;
&lt;span class="err"&gt;│&lt;/span&gt;   &lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="k"&gt;last&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;txt&lt;/span&gt;
&lt;span class="err"&gt;│&lt;/span&gt;   &lt;span class="err"&gt;└──&lt;/span&gt; &lt;span class="n"&gt;sierra&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;txt&lt;/span&gt;
&lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="n"&gt;matplotlibrc&lt;/span&gt;
&lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="n"&gt;requirements&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pip&lt;/span&gt;
&lt;span class="err"&gt;└──&lt;/span&gt; &lt;span class="n"&gt;scripts&lt;/span&gt;
    &lt;span class="err"&gt;├──&lt;/span&gt; &lt;span class="n"&gt;plotcount&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;
    &lt;span class="err"&gt;└──&lt;/span&gt; &lt;span class="n"&gt;wordcount&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;

&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="n"&gt;directories&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;files&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here you see that we're starting with a well designed project directory.
The raw data (books) are stored in their own directory, and scripts have
informative names.&lt;/p&gt;
&lt;p&gt;Let's take a look at our raw data&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;head books/isles.txt
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Our first step is to count the frequency of each word in a book.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;scripts/wordcount.py books/isles.txt isles.tsv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Let's take a quick peek at the result.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;head -5 isles.tsv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;shows us the top 5 lines in the output file:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;the 3822    6.7371760973&lt;/span&gt;
&lt;span class="err"&gt;of  2460    4.33632998414&lt;/span&gt;
&lt;span class="err"&gt;and 1723    3.03719372466&lt;/span&gt;
&lt;span class="err"&gt;to  1479    2.60708619778&lt;/span&gt;
&lt;span class="err"&gt;a   1308    2.30565838181&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Each row shows the word itself, the number of occurrences of that
word, and the number of occurrences as a percentage of the total
number of words in the text file.&lt;/p&gt;
&lt;p&gt;We can do the same thing for a different book:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;scripts/wordcount.py books/abyss.txt abyss.tsv
head -5 abyss.tsv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Finally, let's visualize the results.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;scripts/plotcount.py isles.tsv ascii
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code&gt;ascii&lt;/code&gt; argument has been added so that we get a text-based
bar-plot printed to the screen.&lt;/p&gt;
&lt;p&gt;The script is also able to render a graphical bar-plot using matplotlib
and save the figure to a named file.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;scripts/plotcount.py isles.tsv isles.png
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Together these scripts implement a common workflow:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Read a data file.&lt;/li&gt;
&lt;li&gt;Perform an analysis on this data file.&lt;/li&gt;
&lt;li&gt;Write the analysis results to a new file.&lt;/li&gt;
&lt;li&gt;Plot a graph of the analysis results.&lt;/li&gt;
&lt;li&gt;Save the graph as an image, so we can publish it.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Writing a script to do our analysis [5 minutes]&lt;/h2&gt;
&lt;p&gt;Running this pipeline for one book is relatively simple using the command-line.
But once the number of files and the number of steps in the pipeline
expands, this can turn into a lot of work.
Plus, no one wants to sit and wait for a command to finish, even just for 30
seconds.&lt;/p&gt;
&lt;p&gt;The most common solution to the tedium of data processing is to write
a master script that runs the whole pipeline from start to finish.&lt;/p&gt;
&lt;p&gt;We can see such a script in &lt;code&gt;analysis.sh&lt;/code&gt;, which contains:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="ch"&gt;#!/usr/bin/env bash&lt;/span&gt;
&lt;span class="c1"&gt;# USAGE: bash analysis.sh&lt;/span&gt;
&lt;span class="c1"&gt;# to produce plots for isles and abyss.&lt;/span&gt;

scripts/wordcount.py books/isles.txt isles.tsv
scripts/wordcount.py books/abyss.txt abyss.tsv

scripts/plotcount.py isles.tsv isles.png
scripts/plotcount.py abyss.tsv abyss.png

&lt;span class="c1"&gt;# Archive the results.&lt;/span&gt;
rm -rf zipf_results
mkdir zipf_results
cp isles.tsv abyss.tsv isles.png abyss.png zipf_results/
tar -czf zipf_results.tgz zipf_results
rm -r zipf_results
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This master script solved several problems in computational reproducibility:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It explicitly documents our pipeline,
    making communication with colleagues (and our future selves) more efficient.&lt;/li&gt;
&lt;li&gt;It allows us to type a single command, &lt;code&gt;bash analysis.sh&lt;/code&gt;, to
    reproduce the full analysis.&lt;/li&gt;
&lt;li&gt;It prevents us from &lt;em&gt;repeating&lt;/em&gt; typos or mistakes.
    You might not get it right the first time, but once you fix something
    it'll (probably) stay that way.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;What are the problems with this approach? [10 minutes]&lt;/h2&gt;
&lt;p&gt;A master script is a good start, but it has a few shortcomings.&lt;/p&gt;
&lt;p&gt;Let's imagine that we adjusted the width of the bars in our plot
by editing &lt;code&gt;scripts/plotcount.py&lt;/code&gt;;
in the function definition for
&lt;code&gt;plot_word_counts&lt;/code&gt;, &lt;code&gt;width = 1.0&lt;/code&gt; is now &lt;code&gt;width = 0.8&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now we want to recreate our figures.
We &lt;em&gt;could&lt;/em&gt; &lt;code&gt;bash analysis.sh&lt;/code&gt; again.
That would work, but it could also be a big pain if counting words takes
more than a few seconds.
The word counting routine hasn't changed; we shouldn't need to recreate
those files.&lt;/p&gt;
&lt;p&gt;Alternatively, we could manually rerun the plotting for each word-count file
and recreate the archive.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;for&lt;/span&gt; file in *.tsv&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
    scripts/plotcount.py &lt;span class="nv"&gt;$file&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;file&lt;/span&gt;&lt;span class="p"&gt;/.tsv/.png&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;

rm -rf zipf_results
mkdir zipf_results
cp isles.tsv abyss.tsv isles.png abyss.png zipf_results/
tar -czf zipf_results.tgz zipf_results
rm -r zipf_results
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;But by then we've nullified many of the benefits of having a master script in
the first place.&lt;/p&gt;
&lt;p&gt;Another popular option is to comment out a subset of the lines in
&lt;code&gt;analysis.sh&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="ch"&gt;#!/usr/bin/env bash&lt;/span&gt;
&lt;span class="c1"&gt;# USAGE: bash analysis.sh&lt;/span&gt;
&lt;span class="c1"&gt;# to produce plots for isles and abyss.&lt;/span&gt;

&lt;span class="c1"&gt;# These lines are commented out because they don&amp;#39;t need to be rerun.&lt;/span&gt;
&lt;span class="c1"&gt;#scripts/wordcount.py isles.txt isles.tsv&lt;/span&gt;
&lt;span class="c1"&gt;#scripts/wordcount.py abyss.txt abyss.tsv&lt;/span&gt;

scripts/plotcount.py isles.tsv isles.png
scripts/plotcount.py abyss.tsv abyss.png

&lt;span class="c1"&gt;# Archive the results.&lt;/span&gt;
rm -rf zipf_results
mkdir zipf_results
cp isles.tsv abyss.tsv isles.png abyss.png zipf_results/
tar -czf zipf_results.tgz zipf_results
rm -r zipf_results
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Followed by &lt;code&gt;bash analysis.sh&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;But this process, and subsequently undoing it,
can be a hassle and source of errors in complicated pipelines.&lt;/p&gt;
&lt;p&gt;What we really want is an executable &lt;em&gt;description&lt;/em&gt; of our pipeline that
allows software to do the tricky part for us:
figuring out what steps need to be rerun.
It would also be nice if this tool encourage a &lt;em&gt;modular&lt;/em&gt; analysis
and reusing instead of rewriting parts of our pipeline.
As an added benefit, we'd like it all to play nice with the other
mainstays of reproducible research: version control, Unix-style tools,
and a variety of scripting languages.&lt;/p&gt;
&lt;h1&gt;Snakemake background [5 minutes]&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;Snakemake&lt;/em&gt; comes from a lineage of computer programs&amp;mdash;most notably
 &lt;em&gt;Make&lt;/em&gt;&amp;mdash;originally designed to
automate the compilation and installation of software.
Programs like &lt;em&gt;Make&lt;/em&gt; automate the building of target files through a series of
discrete steps.
Despite the original purpose, this design makes it a great fit for
bioinformatics pipelines, which usually work by transforming data from one form
to another
(e.g. &lt;em&gt;raw data&lt;/em&gt; &amp;#8594; &lt;em&gt;word counts&lt;/em&gt; &amp;#8594; &lt;em&gt;???&lt;/em&gt; &amp;#8594; &lt;em&gt;profit&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Snakemake&lt;/em&gt; is inspired by this approach, but designed specifically for
computationally intensive and/or complex data analysis pipelines.
The name is a reference to the programming language &lt;em&gt;Python&lt;/em&gt;, which forms
the basis for the &lt;em&gt;Snakemake&lt;/em&gt; syntax.
You don't need to be an expert at &lt;em&gt;Python&lt;/em&gt; to use &lt;em&gt;Snakemake&lt;/em&gt;, but it can
sometimes be very useful.
There are pros and cons to using &lt;em&gt;Snakemake&lt;/em&gt; versus any other analysis pipeline
tools, and it is worth considering other options, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;GNU Make&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;doit&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Galaxy&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Tutorial&lt;/h1&gt;
&lt;h2&gt;Writing and Running Snakefiles [10 minutes]&lt;/h2&gt;
&lt;p&gt;Let's get started writing a description of our analysis for &lt;em&gt;Snakemake&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Open up a file called &lt;code&gt;Snakefile&lt;/code&gt; in your editor and add the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;rule wordcount_isles:&lt;/span&gt;
&lt;span class="err"&gt;    input: &amp;quot;books/isles.txt&amp;quot;&lt;/span&gt;
&lt;span class="err"&gt;    output: &amp;quot;isles.tsv&amp;quot;&lt;/span&gt;
&lt;span class="err"&gt;    shell: &amp;quot;scripts/wordcount.py books/isles.txt isles.tsv&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We have now written the simplest, non-trivial snakefile.
The &lt;code&gt;shell:&lt;/code&gt; line is pretty reminiscent of one of the lines from our master
script.
I bet you can already see what this snakefile means.&lt;/p&gt;
&lt;p&gt;Let's walk through what we've written.
The first line uses the keyword &lt;code&gt;rule&lt;/code&gt; followed by the name of our rule:
&lt;code&gt;wordcount_isles&lt;/code&gt;.
We end that line with a colon.
All of the following lines in our rule are indented with four spaces.
The second line says that it takes an input file, using the &lt;code&gt;input&lt;/code&gt;
keyword which is again followed by a colon.
We then give it the path to this prerequisite (&lt;code&gt;books/isles.txt&lt;/code&gt;), wrapped in
quotes.
The third line does the same thing with the output file (&lt;code&gt;isles.tsv&lt;/code&gt;).
And the last line is the exact shell command that we used in our shell script
earlier to create the target output file.
Like scripting, &lt;em&gt;Snakemake&lt;/em&gt; allows us to wrap a series of shell commands, but
is more expressive and flexible than a script.&lt;/p&gt;
&lt;p&gt;Our snakefile describes a (very short) pipeline:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We are generating a file called &lt;code&gt;isles.tsv&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Creating this file requires &lt;code&gt;books/isles.txt&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;The command to create this file runs the script runs &lt;code&gt;wordcount.py&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We'll think about our pipeline as a network of files that are dependent
on one another.
Right now our Snakefile describes a pretty simple &lt;strong&gt;dependency graph&lt;/strong&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;books/isles.txt&lt;/code&gt; &amp;#8594; &lt;code&gt;isles.tsv&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;where the "&amp;#8594;" is pointing from requirements to targets.&lt;/p&gt;
&lt;h3&gt;Running Snakemake&lt;/h3&gt;
&lt;p&gt;Now that we have a (currently incomplete) description of our pipeline,
let's use &lt;em&gt;Snakemake&lt;/em&gt; to execute it.&lt;/p&gt;
&lt;p&gt;First, remove the previously generated files.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;rm *.tsv *.png zipf_results.tgz
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;snakemake isles.tsv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;You should see the following print to the terminal:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;Provided&lt;/span&gt; &lt;span class="n"&gt;cores&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;Rules&lt;/span&gt; &lt;span class="n"&gt;claiming&lt;/span&gt; &lt;span class="k"&gt;more&lt;/span&gt; &lt;span class="n"&gt;threads&lt;/span&gt; &lt;span class="n"&gt;will&lt;/span&gt; &lt;span class="n"&gt;be&lt;/span&gt; &lt;span class="n"&gt;scaled&lt;/span&gt; &lt;span class="n"&gt;down&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;span class="n"&gt;Job&lt;/span&gt; &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;count&lt;/span&gt;   &lt;span class="n"&gt;jobs&lt;/span&gt;
        &lt;span class="mi"&gt;1&lt;/span&gt;       &lt;span class="n"&gt;wordcount_isles&lt;/span&gt;
        &lt;span class="mi"&gt;1&lt;/span&gt;

&lt;span class="k"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;wordcount_isles&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;books&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;isles&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;txt&lt;/span&gt;
    &lt;span class="k"&gt;output&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;isles&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tsv&lt;/span&gt;
    &lt;span class="n"&gt;jobid&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

&lt;span class="n"&gt;Finished&lt;/span&gt; &lt;span class="n"&gt;job&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;steps&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;By default, &lt;em&gt;Snakemake&lt;/em&gt; prints a summary of the recipes that it
executes.&lt;/p&gt;
&lt;p&gt;Let's see if we got what we expected.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;head -5 isles.tsv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The first 5 lines of that file should look exactly like before.&lt;/p&gt;
&lt;h3&gt;Re-running Snakemake&lt;/h3&gt;
&lt;p&gt;Let's try running &lt;em&gt;Snakemake&lt;/em&gt; the same way again.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;snakemake isles.tsv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This time, instead of executing the same recipe,
&lt;em&gt;Snakemake&lt;/em&gt; prints &lt;code&gt;Nothing to be done.&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;What's happening here?&lt;/p&gt;
&lt;p&gt;When you ask &lt;em&gt;Snakemake&lt;/em&gt; to make &lt;code&gt;isles.tsv&lt;/code&gt; it first looks at
the modification time of that target.
Next it looks at the modification time for the target's prerequisites.
If the target is newer than the prerequisites &lt;em&gt;Snakemake&lt;/em&gt; decides that
the target is up-to-date and does not need to be remade.&lt;/p&gt;
&lt;p&gt;Much has been said about using modification times as the cue for remaking
files.
This can be another &lt;em&gt;Snakemake&lt;/em&gt; gotcha, so keep it in mind.&lt;/p&gt;
&lt;p&gt;If you want to induce the original behavior, you only have to
change the modification time of &lt;code&gt;books/isles.txt&lt;/code&gt; so that it is newer
than &lt;code&gt;isles.tsv&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;touch books/isles.txt
snakemake isles.tsv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The original behavior is restored.&lt;/p&gt;
&lt;p&gt;Sometimes you only want &lt;em&gt;Snakemake&lt;/em&gt; to tell you what it thinks about the
current state of your files.
&lt;code&gt;snakemake --dryrun isles.tsv&lt;/code&gt; will print &lt;em&gt;Snakemake&lt;/em&gt;'s execution plan,
without actually carrying it out.
The flag can also be abbreviated as &lt;code&gt;-n&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If you don't pass a target as an argument to snakemake (i.e. run
&lt;code&gt;snakemake&lt;/code&gt;) it will assume that you want to build the first target in the
snakefile.&lt;/p&gt;
&lt;h2&gt;Expanding our Snakefile with more recipes (and challenge) [20 minutes]&lt;/h2&gt;
&lt;p&gt;Now that &lt;em&gt;Make&lt;/em&gt; knows how to build &lt;code&gt;isles.tsv&lt;/code&gt;,
we can add a rule for plotting those results.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;rule plotcount_isles:&lt;/span&gt;
&lt;span class="err"&gt;    input: &amp;quot;isles.tsv&amp;quot;&lt;/span&gt;
&lt;span class="err"&gt;    output: &amp;quot;isles.png&amp;quot;&lt;/span&gt;
&lt;span class="err"&gt;    shell: &amp;quot;scripts/plotcount.py isles.tsv isles.png&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The dependency graph now looks like:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;books/isles.txt&lt;/code&gt; &amp;#8594; &lt;code&gt;isles.tsv&lt;/code&gt; &amp;#8594; &lt;code&gt;isles.png&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Let's add a few more recipes to our Snakefile.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;wordcount_abyss&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;books/abyss.txt&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;output&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;abyss.tsv&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;scripts/wordcount.py books/abyss.txt abyss.tsv&amp;quot;&lt;/span&gt;

&lt;span class="k"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;archive_results&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;isles.tsv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;abyss.tsv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;isles.png&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;abyss.png&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;output&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;zipf_results.tgz&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="ss"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="ss"&gt;        rm -rf zipf_results/&lt;/span&gt;
&lt;span class="ss"&gt;        mkdir zipf_results/&lt;/span&gt;
&lt;span class="ss"&gt;        cp isles.tsv abyss.tsv isles.png abyss.png zipf_results/&lt;/span&gt;
&lt;span class="ss"&gt;        tar -czf zipf_results.tgz zipf_results/&lt;/span&gt;
&lt;span class="ss"&gt;        rm -r zipf_results/&lt;/span&gt;
&lt;span class="ss"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here the recipe for &lt;code&gt;zipf_results.tgz&lt;/code&gt; takes multiple input files,
each of which must be quoted and separated by commas, and involves
involves running a series of shell commands.
When building the archive, &lt;em&gt;Snakemake&lt;/em&gt; will run each line successively unless
any return an error.&lt;/p&gt;
&lt;blockquote&gt;
&lt;h4&gt;Question&lt;/h4&gt;
&lt;p&gt;Without doing it, what happens if you run &lt;code&gt;snakemake isles.png&lt;/code&gt;?&lt;/p&gt;
&lt;h4&gt;Challenge&lt;/h4&gt;
&lt;p&gt;What does the dependency graph look like for your Snakefile?&lt;/p&gt;
&lt;h4&gt;Try it&lt;/h4&gt;
&lt;p&gt;What happens if you run &lt;code&gt;snakemake zipf_results.tgz&lt;/code&gt; right now?&lt;/p&gt;
&lt;h4&gt;Practice&lt;/h4&gt;
&lt;p&gt;Write a recipe for &lt;code&gt;abyss.png&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Once you've written a recipe for &lt;code&gt;abyss.png&lt;/code&gt; you should be able to
run &lt;code&gt;snakemake zipf_results.tgz&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let's delete all of our files and try it out.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;rm abyss.* isles.*
snakemake zipf_results.tgz
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;You should get the something like the following output
(the order may be different)
to your terminal:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;Provided&lt;/span&gt; &lt;span class="n"&gt;cores&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;Rules&lt;/span&gt; &lt;span class="n"&gt;claiming&lt;/span&gt; &lt;span class="k"&gt;more&lt;/span&gt; &lt;span class="n"&gt;threads&lt;/span&gt; &lt;span class="n"&gt;will&lt;/span&gt; &lt;span class="n"&gt;be&lt;/span&gt; &lt;span class="n"&gt;scaled&lt;/span&gt; &lt;span class="n"&gt;down&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;span class="n"&gt;Job&lt;/span&gt; &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;count&lt;/span&gt;   &lt;span class="n"&gt;jobs&lt;/span&gt;
        &lt;span class="mi"&gt;1&lt;/span&gt;       &lt;span class="n"&gt;archive_results&lt;/span&gt;
        &lt;span class="mi"&gt;1&lt;/span&gt;       &lt;span class="n"&gt;plotcount_abyss&lt;/span&gt;
        &lt;span class="mi"&gt;1&lt;/span&gt;       &lt;span class="n"&gt;plotcount_isles&lt;/span&gt;
        &lt;span class="mi"&gt;1&lt;/span&gt;       &lt;span class="n"&gt;wordcount_abyss&lt;/span&gt;
        &lt;span class="mi"&gt;1&lt;/span&gt;       &lt;span class="n"&gt;wordcount_isles&lt;/span&gt;
        &lt;span class="mi"&gt;5&lt;/span&gt;

&lt;span class="k"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;wordcount_abyss&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;books&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;abyss&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;txt&lt;/span&gt;
    &lt;span class="k"&gt;output&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;abyss&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tsv&lt;/span&gt;
    &lt;span class="n"&gt;jobid&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

&lt;span class="n"&gt;Finished&lt;/span&gt; &lt;span class="n"&gt;job&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;steps&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;

&lt;span class="k"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;wordcount_isles&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;books&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;abyss&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;txt&lt;/span&gt;
    &lt;span class="k"&gt;output&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;abyss&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tsv&lt;/span&gt;
    &lt;span class="n"&gt;jobid&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;

&lt;span class="n"&gt;Finished&lt;/span&gt; &lt;span class="n"&gt;job&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;steps&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;

&lt;span class="k"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;plotcount_abyss&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;abyss&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tsv&lt;/span&gt;
    &lt;span class="k"&gt;output&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;abyss&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;png&lt;/span&gt;
    &lt;span class="n"&gt;jobid&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;

&lt;span class="n"&gt;Finished&lt;/span&gt; &lt;span class="n"&gt;job&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;steps&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;60&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;

&lt;span class="k"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;plotcount_isles&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;isles&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tsv&lt;/span&gt;
    &lt;span class="k"&gt;output&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;isles&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;png&lt;/span&gt;
    &lt;span class="n"&gt;jobid&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;

&lt;span class="n"&gt;Finished&lt;/span&gt; &lt;span class="n"&gt;job&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;steps&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;80&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;

&lt;span class="k"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;archive_results&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;isles&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tsv&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;abyss&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tsv&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;isles&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;png&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;abyss&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;png&lt;/span&gt;
    &lt;span class="k"&gt;output&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;zipf_results&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tgz&lt;/span&gt;
    &lt;span class="n"&gt;jobid&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

&lt;span class="n"&gt;Finished&lt;/span&gt; &lt;span class="n"&gt;job&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="k"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;steps&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;done&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Since you asked for &lt;code&gt;zipf_results.tgz&lt;/code&gt; &lt;em&gt;Snakemake&lt;/em&gt; looked first for that file.
Not finding it, &lt;em&gt;Snakemake&lt;/em&gt; looked for its prerequisites.
Since none of those existed it remade the ones it could,
&lt;code&gt;abyss.tsv&lt;/code&gt; and &lt;code&gt;isles.tsv&lt;/code&gt;.
Once those were finished it was able to make &lt;code&gt;abyss.png&lt;/code&gt; and
&lt;code&gt;isles.png&lt;/code&gt;, before finally building &lt;code&gt;zipf_results.tgz&lt;/code&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;h4&gt;Try it&lt;/h4&gt;
&lt;p&gt;What happens if you &lt;code&gt;touch abyss.tsv&lt;/code&gt; and
then &lt;code&gt;snakemake zipf_results.tgz&lt;/code&gt;?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Running Snakemake in parallel&lt;/h2&gt;
&lt;p&gt;And check this out!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;snakemake clean
snakemake --threads &lt;span class="m"&gt;2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Did you see it?
The &lt;code&gt;--threads 2&lt;/code&gt; flag (just "&lt;code&gt;-j2&lt;/code&gt;" works too) tells &lt;em&gt;Make&lt;/em&gt; to run recipes in
two &lt;em&gt;parallel&lt;/em&gt; threads.
Our dependency graph clearly shows that
&lt;code&gt;abyss.tsv&lt;/code&gt; and &lt;code&gt;isles.tsv&lt;/code&gt; are mutually independent and can
both be built at the same time.
Likewise for &lt;code&gt;abyss.png&lt;/code&gt; and &lt;code&gt;isles.png&lt;/code&gt;.
If you've got a bunch of independent branches in your analysis, this can
greatly speed up your build process.&lt;/p&gt;
&lt;h3&gt;Phony targets&lt;/h3&gt;
&lt;p&gt;Sometimes we want to build a bunch of different files simultaneously.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;rule all:&lt;/span&gt;
&lt;span class="err"&gt;    input: &amp;quot;isles.png&amp;quot;, &amp;quot;abyss.png&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Even though this rule doesn't have a recipe, it does have prerequisites.
Now, when you run &lt;code&gt;snakemake all&lt;/code&gt; &lt;em&gt;Snakemake&lt;/em&gt; will do what it needs to to bring
both of those targets up to date.&lt;/p&gt;
&lt;p&gt;It is traditional for "&lt;code&gt;all&lt;/code&gt;" to be the first recipe in a snakefile,
since the first recipe is what is built by default
when no other target is passed as an argument.&lt;/p&gt;
&lt;p&gt;Another traditional target is "&lt;code&gt;clean&lt;/code&gt;".
Add the following to your snakefile.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;rule clean:&lt;/span&gt;
&lt;span class="err"&gt;    shell: &amp;quot;rm --force *.tsv *.png zipf_results.tgz&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Running &lt;code&gt;snakemake clean&lt;/code&gt; will now remove all of the cruft.&lt;/p&gt;
&lt;h2&gt;Diagramming the DAG [5 minutes]&lt;/h2&gt;
&lt;p&gt;(If you'd prefer not to bake this Snakefile from scratch, you can
get one we've been hiding in the oven the whole time:
&lt;code&gt;cp .extra/Snakefile.1 Snakefile&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;Right now, our snakefile looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="o"&gt;#&lt;/span&gt; &lt;span class="n"&gt;Dummy&lt;/span&gt; &lt;span class="n"&gt;targets&lt;/span&gt;
&lt;span class="k"&gt;rule&lt;/span&gt; &lt;span class="k"&gt;all&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;isles.png&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;abyss.png&amp;quot;&lt;/span&gt;

&lt;span class="k"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;clean&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;rm --force *.tsv *.png zipf_results.tgz&amp;quot;&lt;/span&gt;

&lt;span class="o"&gt;#&lt;/span&gt; &lt;span class="n"&gt;Analysis&lt;/span&gt;
&lt;span class="k"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;wordcount_isles&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;books/isles.txt&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;output&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;isles.tsv&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;scripts/wordcount.py books/isles.txt isles.tsv&amp;quot;&lt;/span&gt;

&lt;span class="k"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;wordcount_abyss&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;books/abyss.txt&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;output&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;abyss.tsv&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;scripts/wordcount.py books/abyss.txt abyss.tsv&amp;quot;&lt;/span&gt;

&lt;span class="o"&gt;#&lt;/span&gt; &lt;span class="n"&gt;Plotting&lt;/span&gt;
&lt;span class="k"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;plotcount_isles&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;isles.tsv&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;output&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;isles.png&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;scripts/plotcount.py isles.tsv isles.png&amp;quot;&lt;/span&gt;

&lt;span class="k"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;plotcount_abyss&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;abyss.tsv&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;output&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;abyss.png&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;scripts/plotcount.py abyss.tsv abyss.png&amp;quot;&lt;/span&gt;

&lt;span class="o"&gt;#&lt;/span&gt; &lt;span class="n"&gt;Deliverables&lt;/span&gt;
&lt;span class="k"&gt;rule&lt;/span&gt; &lt;span class="n"&gt;archive_results&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;input&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;isles.tsv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;abyss.tsv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;isles.png&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;abyss.png&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;output&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="ss"&gt;&amp;quot;zipf_results.tgz&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="ss"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="ss"&gt;        rm -rf zipf_results/&lt;/span&gt;
&lt;span class="ss"&gt;        mkdir zipf_results/&lt;/span&gt;
&lt;span class="ss"&gt;        cp isles.tsv abyss.tsv isles.png abyss.png zipf_results/&lt;/span&gt;
&lt;span class="ss"&gt;        tar -czf zipf_results.tgz zipf_results/&lt;/span&gt;
&lt;span class="ss"&gt;        rm -r zipf_results/&lt;/span&gt;
&lt;span class="ss"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Looks good, don't you think?
Notice the added comments, starting with the "&lt;code&gt;#&lt;/code&gt;" character just like in
Python, R, shell, etc.&lt;/p&gt;
&lt;p&gt;Using these recipes, a simple call to &lt;code&gt;snakemake&lt;/code&gt; builds all the same files
that we were originally making either manually or using the master script, but
with a few bonus features.&lt;/p&gt;
&lt;p&gt;Now, if we change one of the inputs, we don't have to rebuild everything.
Instead, &lt;em&gt;Snakemake&lt;/em&gt; knows to only rebuild the files that, either directly or
indirectly, depend on the file that changed.
This is called an &lt;strong&gt;incremental build&lt;/strong&gt;.
It's no longer our job to track those dependencies.
One fewer cognitive burden getting in the way of research progress!&lt;/p&gt;
&lt;p&gt;In addition, a snakefile explicitly documents the inputs to and outputs
from every step in the analysis.
These are like informal "USAGE:" documentation for our scripts.&lt;/p&gt;
&lt;p&gt;It is worth pointing out that our pipeline (and every pipeline) &lt;em&gt;must&lt;/em&gt; be
acyclic: no file can be an input to itself or to any of its inputs, &lt;em&gt;ad
infinitum&lt;/em&gt;.
Officially we talk about the relationships between files as a Directed Acyclic
Graph (DAG).
While earlier we took the time to diagram our DAG by hand, &lt;em&gt;Snakemake&lt;/em&gt;
has tools for plotting this network automatically.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;snakemake --dag zipf_results.tgz &lt;span class="p"&gt;|&lt;/span&gt; dot -Tpng &amp;gt; dag.png
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Open that file and check it out.&lt;/p&gt;
&lt;p&gt;&lt;img alt="A visualization of the analysis DAG" src="//blog.byronjsmith.com/static/images/snakemake-dag.png"&gt;&lt;/p&gt;
&lt;p&gt;Diagrams like this one can be a very useful way to debug problems with an
analysis pipeline.&lt;/p&gt;
&lt;h2&gt;Don't repeat yourself&lt;/h2&gt;
&lt;p&gt;In many programming language, the bulk of the language features are there
to allow the programmer to describe long-winded computational routines as
short, expressive, beautiful code.
Features in Python or R like user-defined variables and functions are
useful in part because they mean we don't have to write out (or think about)
all of the details over and over again.
This good habit of writing things out only once is known as the D.R.Y.
principle.&lt;/p&gt;
&lt;p&gt;In &lt;em&gt;Snakemake&lt;/em&gt; a number of features are designed to minimize repetitive code.
Our current snakefile does &lt;em&gt;not&lt;/em&gt; conform to this principle,
but &lt;em&gt;Snakemake&lt;/em&gt; is perfectly capable of doing so.&lt;/p&gt;
&lt;h3&gt;Automatic variables [10 minutes]&lt;/h3&gt;
&lt;blockquote&gt;
&lt;h4&gt;Question&lt;/h4&gt;
&lt;p&gt;What are some of the repetitive components of our snakefile?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;One overly repetitive part of our Snakefile:
Inputs and outputs are in both the header &lt;em&gt;and&lt;/em&gt; the recipe of each rule.&lt;/p&gt;
&lt;p&gt;It turns out, that&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;rule wordcount_isles:&lt;/span&gt;
&lt;span class="err"&gt;    input: &amp;quot;books/isles.txt&amp;quot;&lt;/span&gt;
&lt;span class="err"&gt;    output: &amp;quot;isles.tsv&amp;quot;&lt;/span&gt;
&lt;span class="err"&gt;    shell: &amp;quot;scripts/wordcount.py books/isles.txt isles.tsv&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Can be rewritten as&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;rule wordcount_isles:&lt;/span&gt;
&lt;span class="err"&gt;    input: &amp;quot;books/isles.txt&amp;quot;&lt;/span&gt;
&lt;span class="err"&gt;    output: &amp;quot;isles.tsv&amp;quot;&lt;/span&gt;
&lt;span class="err"&gt;    shell: &amp;quot;scripts/wordcount.py {input} {output}&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here we've replaced the input "&lt;code&gt;books/isles.txt&lt;/code&gt;" in the recipe
with "&lt;code&gt;{input}&lt;/code&gt;" and the output "&lt;code&gt;isles.dat&lt;/code&gt;" with "&lt;code&gt;{output}&lt;/code&gt;".
Both "&lt;code&gt;{input}&lt;/code&gt;" and "&lt;code&gt;{output}&lt;/code&gt;" are placeholders that refer to all of the
prerequisites and target of a rule, respectively.
In &lt;em&gt;Snakemake&lt;/em&gt;, placeholders are all wrapped in opening and closing brackets,
and are replaced with the value of that variable at runtime.
If you are familiar with modern Python format strings, that's where the syntax
comes from.&lt;/p&gt;
&lt;p&gt;Likewise&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;rule archive_results:&lt;/span&gt;
&lt;span class="err"&gt;    input: &amp;quot;isles.tsv&amp;quot;, &amp;quot;abyss.tsv&amp;quot;, &amp;quot;isles.png&amp;quot;, &amp;quot;abyss.png&amp;quot;&lt;/span&gt;
&lt;span class="err"&gt;    output: &amp;quot;zipf_results.tgz&amp;quot;&lt;/span&gt;
&lt;span class="err"&gt;    shell:&lt;/span&gt;
&lt;span class="err"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="err"&gt;        rm -rf zipf_results/&lt;/span&gt;
&lt;span class="err"&gt;        mkdir zipf_results/&lt;/span&gt;
&lt;span class="err"&gt;        cp isles.tsv abyss.tsv isles.png abyss.png zipf_results/&lt;/span&gt;
&lt;span class="err"&gt;        tar -czf zipf_results.tgz zipf_results/&lt;/span&gt;
&lt;span class="err"&gt;        rm -r zipf_results/&lt;/span&gt;
&lt;span class="err"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;can now be rewritten as&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;rule archive_results:&lt;/span&gt;
&lt;span class="err"&gt;    input: &amp;quot;isles.tsv&amp;quot;, &amp;quot;abyss.tsv&amp;quot;, &amp;quot;isles.png&amp;quot;, &amp;quot;abyss.png&amp;quot;&lt;/span&gt;
&lt;span class="err"&gt;    output: &amp;quot;zipf_results.tgz&amp;quot;&lt;/span&gt;
&lt;span class="err"&gt;    shell:&lt;/span&gt;
&lt;span class="err"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="err"&gt;        rm -rf zipf_results/&lt;/span&gt;
&lt;span class="err"&gt;        mkdir zipf_results/&lt;/span&gt;
&lt;span class="err"&gt;        cp {input} zipf_results/&lt;/span&gt;
&lt;span class="err"&gt;        tar -czf {output} zipf_results/&lt;/span&gt;
&lt;span class="err"&gt;        rm -r zipf_results/&lt;/span&gt;
&lt;span class="err"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;That's a little less cluttered,
and still perfectly understandable once you know what the variables mean.
The best part, is that if I want to change the input files, I only need to
edit my snakefile in one place.&lt;/p&gt;
&lt;blockquote&gt;
&lt;h4&gt;Try it&lt;/h4&gt;
&lt;p&gt;```bash
snakemake clean
snakemake isles.tsv
``````````&lt;/p&gt;
&lt;/blockquote&gt;
&lt;!--Those extra backticks are because of Vim syntax highlighting.--&gt;

&lt;p&gt;You should get the same output as last time.
Internally, &lt;em&gt;Snakemake&lt;/em&gt; replaced "&lt;code&gt;{output}&lt;/code&gt;" with "&lt;code&gt;isles.tsv&lt;/code&gt;"
and "&lt;code&gt;{input}&lt;/code&gt;" with "&lt;code&gt;books/isles.txt&lt;/code&gt;"
before running the recipe.&lt;/p&gt;
&lt;blockquote&gt;
&lt;h4&gt;Practice&lt;/h4&gt;
&lt;p&gt;Go ahead and rewrite all of the rules in Snakefile to minimize
repetition and take advantage of the "&lt;code&gt;{input}&lt;/code&gt;" and "&lt;code&gt;{output}&lt;/code&gt;"
placeholders.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;Wildcard Filenames [10 minutes]&lt;/h3&gt;
&lt;p&gt;Another deviation from D.R.Y.:
We have nearly identical recipes for &lt;code&gt;abyss.tsv&lt;/code&gt; and &lt;code&gt;isles.tsv&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;It turns out we can replace &lt;em&gt;both&lt;/em&gt; of those rules with a single rule,
by telling &lt;em&gt;Snakemake&lt;/em&gt; about the relationships between filenames with
&lt;em&gt;wildcards&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Using wildcards looks like this&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;rule wordcount:&lt;/span&gt;
&lt;span class="err"&gt;    input: &amp;quot;books/{name}.txt&amp;quot;&lt;/span&gt;
&lt;span class="err"&gt;    output: &amp;quot;{name}.tsv&amp;quot;&lt;/span&gt;
&lt;span class="err"&gt;    shell: &amp;quot;scripts/wordcount.py {input} {output}&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here we've replaced the book name with "&lt;code&gt;{name}&lt;/code&gt;".
The "&lt;code&gt;{name}&lt;/code&gt;" matches any part of the input filename between "&lt;code&gt;books/&lt;/code&gt;"
and "&lt;code&gt;.txt&lt;/code&gt;", and must be the same as "&lt;code&gt;{name}&lt;/code&gt;" in the output filename.
You don't have to use "name" as your wildcard name, and you should be
descriptive.&lt;/p&gt;
&lt;p&gt;This rule can be interpreted as:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In order to build a file named &lt;code&gt;[something].tsv&lt;/code&gt; (the target)
find a file named &lt;code&gt;books/[that same something].txt&lt;/code&gt; (the prerequisite)
and run &lt;code&gt;scripts/wordcount.py [the prerequisite] [the target]&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Notice how helpful the automatic input/output variables were here.
This recipe will work no matter what stem is being matched!&lt;/p&gt;
&lt;p&gt;Go ahead and make this change in your snakefile.&lt;/p&gt;
&lt;blockquote&gt;
&lt;h4&gt;Try it&lt;/h4&gt;
&lt;p&gt;After you've replaced the two rules with one
rule using wildcards, try removing all of the products (&lt;code&gt;snakemake clean&lt;/code&gt;)
and rerunning the pipeline.&lt;/p&gt;
&lt;p&gt;Is anything different now that you're using the new, universal rule?&lt;/p&gt;
&lt;h4&gt;Practice&lt;/h4&gt;
&lt;p&gt;Replace the rules for &lt;code&gt;abyss.png&lt;/code&gt; and &lt;code&gt;isles.png&lt;/code&gt;
with a single rule.&lt;/p&gt;
&lt;h4&gt;Challenge&lt;/h4&gt;
&lt;p&gt;Add &lt;code&gt;books/sierra.txt&lt;/code&gt; to your pipeline.&lt;/p&gt;
&lt;p&gt;(i.e. &lt;code&gt;snakemake all&lt;/code&gt; should plot the word counts and add the plots to
&lt;code&gt;zipf_results.tgz&lt;/code&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;(If you'd prefer a pre-cooked snakefile: &lt;code&gt;cp .extra/Snakefile.2 Snakefile&lt;/code&gt;)&lt;/p&gt;
&lt;h2&gt;Scripts as prerequisites [10 minutes]&lt;/h2&gt;
&lt;p&gt;We've talked a lot about the power of &lt;em&gt;Snakemake&lt;/em&gt; for
rebuilding research outputs when input data changes.
When doing novel data analysis, however, it's very common for our &lt;em&gt;scripts&lt;/em&gt; to
be as or &lt;em&gt;more&lt;/em&gt; dynamic than the data.&lt;/p&gt;
&lt;p&gt;What happens when we edit our scripts instead of changing our data?&lt;/p&gt;
&lt;blockquote&gt;
&lt;h4&gt;Try it&lt;/h4&gt;
&lt;p&gt;First, run &lt;code&gt;snakemake all&lt;/code&gt; so your analysis is up-to-date.&lt;/p&gt;
&lt;p&gt;Let's change the default number of entries in the rank/frequency
plot from 10 to 5.&lt;/p&gt;
&lt;p&gt;(Hint: edit the function definition for &lt;code&gt;plot_word_counts&lt;/code&gt; in
&lt;code&gt;plotcount.py&lt;/code&gt; to read &lt;code&gt;limit=5&lt;/code&gt;.)&lt;/p&gt;
&lt;p&gt;Now run &lt;code&gt;snakemake all&lt;/code&gt; again.  What happened?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As it stands, we have to run &lt;code&gt;snakemake clean&lt;/code&gt; followed by &lt;code&gt;snakemake all&lt;/code&gt;
to update our analysis with the new script.
We're missing out on the benefits of incremental analysis when our scripts
are changing too.&lt;/p&gt;
&lt;p&gt;There must be a better way...and there is.
Scripts should be considered inputs too!&lt;/p&gt;
&lt;p&gt;Let's edit the rule for &lt;code&gt;{name}.png&lt;/code&gt; to include &lt;code&gt;plotcount.py&lt;/code&gt;
as an input.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;rule plotcount:&lt;/span&gt;
&lt;span class="err"&gt;    input:&lt;/span&gt;
&lt;span class="err"&gt;        script=&amp;quot;scripts/plotcount.py&amp;quot;,&lt;/span&gt;
&lt;span class="err"&gt;        data=&amp;quot;{name}.tsv&amp;quot;&lt;/span&gt;
&lt;span class="err"&gt;    output: &amp;quot;{name}.png&amp;quot;&lt;/span&gt;
&lt;span class="err"&gt;    shell: &amp;quot;{input.script} {input.data} {output}&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here we've assigned names to our two inputs.&lt;/p&gt;
&lt;p&gt;This recipe works because "&lt;code&gt;{input.script}&lt;/code&gt;" is replaced with
"&lt;code&gt;scripts/plotcount.py&lt;/code&gt;"
and "&lt;code&gt;{input.data}&lt;/code&gt;" with the appropriate expansion of "&lt;code&gt;{name}.tsv&lt;/code&gt;".
When building &lt;code&gt;abyss.png&lt;/code&gt;, for instance,
"&lt;code&gt;{input.script} {input.data} {output}&lt;/code&gt;" becomes
"&lt;code&gt;scripts/plotcount.py abyss.tsv abyss.png&lt;/code&gt;", which is exactly what we want.&lt;/p&gt;
&lt;blockquote&gt;
&lt;h4&gt;Try it&lt;/h4&gt;
&lt;p&gt;What happens when you run the pipeline after modifying your script again?&lt;/p&gt;
&lt;p&gt;(Changes to your script can be simulated with &lt;code&gt;touch plotcount.py&lt;/code&gt;.)&lt;/p&gt;
&lt;h4&gt;Practice&lt;/h4&gt;
&lt;p&gt;Update your other rules to include the relevant scripts as inputs.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;(Final snakefile: &lt;code&gt;cp .extra/Snakefile.3 Snakefile&lt;/code&gt;)&lt;/p&gt;
&lt;h1&gt;Conclusion [1 minutes]&lt;/h1&gt;
&lt;p&gt;I hope that I've convinced you of the value of &lt;em&gt;Snakemake&lt;/em&gt; for data analysis.
What I have shown you today barely scratches the surface of the software's
functionality;
I encourage you to check out the &lt;a href="https://snakemake.readthedocs.io"&gt;website&lt;/a&gt;.
In my experience, though, the topics we've gone over today already provide
90% of the benefits:
we can forget about script names
and intermediate steps and focus instead on the output files that we want.
This &lt;a href="https://en.wikipedia.org/wiki/Declarative_programming"&gt;'declarative'&lt;/a&gt; approach to pipelines
pipelines has transformed the way I do data analysis.
I think it can do the same for you.&lt;/p&gt;</content><category term="Computing"></category><category term="teaching"></category><category term="programming"></category><category term="python"></category><category term="pipelines"></category><category term="bioinformatics"></category><category term="software"></category></entry><entry><title>Teaching Python by the (Note)Book</title><link href="//blog.byronjsmith.com/python-lesson-balance.html" rel="alternate"></link><published>2017-01-01T18:30:00-05:00</published><updated>2017-01-01T18:30:00-05:00</updated><author><name>Byron J. Smith</name></author><id>tag:blog.byronjsmith.com,2017-01-01:/python-lesson-balance.html</id><summary type="html">&lt;p&gt;&lt;em&gt;&lt;strong&gt;tl;dr:&lt;/strong&gt; I tried out a &lt;a href="https://gist.github.com/bsmith89/5eeb9e7da35bd6b8bf28ae884f6478ff"&gt;modified Python lesson&lt;/a&gt;
and I think it was successful at balancing learner motivation with teaching
foundational (and sometimes boring) concepts.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In many ways, &lt;a href="https://software-carpentry.org"&gt;teaching Python to scientists&lt;/a&gt;
is easier than just about every other audience.
The learning objective is clear: write code to make my science more accurate,
more efficient, and more impactful.
The motivation is apparent: data is increasingly plentiful and increasingly
complex.
The learners are both engaged and prepared to put in the effort
required to develop new skills.&lt;/p&gt;
&lt;p&gt;But, despite all of the advantages, teaching &lt;em&gt;anybody&lt;/em&gt; to program is hard.&lt;/p&gt;
&lt;p&gt;In my experience, one of the most challenging trade-offs for lesson planners
is between motivating the material and teaching a mental model
for code execution.
For example, scientists are easily motivated by simple data munging and
plotting using &lt;code&gt;pandas&lt;/code&gt; and &lt;code&gt;matplotlib&lt;/code&gt;;
these are features of the Python ecosystem that can convince …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;&lt;strong&gt;tl;dr:&lt;/strong&gt; I tried out a &lt;a href="https://gist.github.com/bsmith89/5eeb9e7da35bd6b8bf28ae884f6478ff"&gt;modified Python lesson&lt;/a&gt;
and I think it was successful at balancing learner motivation with teaching
foundational (and sometimes boring) concepts.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In many ways, &lt;a href="https://software-carpentry.org"&gt;teaching Python to scientists&lt;/a&gt;
is easier than just about every other audience.
The learning objective is clear: write code to make my science more accurate,
more efficient, and more impactful.
The motivation is apparent: data is increasingly plentiful and increasingly
complex.
The learners are both engaged and prepared to put in the effort
required to develop new skills.&lt;/p&gt;
&lt;p&gt;But, despite all of the advantages, teaching &lt;em&gt;anybody&lt;/em&gt; to program is hard.&lt;/p&gt;
&lt;p&gt;In my experience, one of the most challenging trade-offs for lesson planners
is between motivating the material and teaching a mental model
for code execution.
For example, scientists are easily motivated by simple data munging and
plotting using &lt;code&gt;pandas&lt;/code&gt; and &lt;code&gt;matplotlib&lt;/code&gt;;
these are features of the Python ecosystem that can convince a graduate
student to pay attention to the material instead of answering emails.
Actually &lt;em&gt;using&lt;/em&gt; these features, however, requires a long list of basic
concepts: Python syntax, libraries, function calls, objects and methods,
conditionals, and variable assignment, to name just a few.&lt;/p&gt;
&lt;p&gt;A lesson planner can start from the basics, working in to these features
along the branches of the dependency tree, but that could require hours
(or even days) of "boring programming".
It's all too easy to dismiss learners who lose interest before you get
to the good stuff, but it is more a reflection of the materials and
instructor, than the students.&lt;/p&gt;
&lt;p&gt;At the other extreme, a lesson could start with working code,
or, in the Software Carpentry style the instructor could lead learners
through writing code that uses these features, before the concepts have
been fully introduced.
This in-at-the-deep-end approach quickly demonstrates exciting uses of Python,
but at the risk of intimidating learners, making them wonder if they're the
only one in the room who's confused by what's going on under the hood and what
all of the syntax means.
I'm not aware of any studies on this topic (if you are, please pass them my
way), but I'm willing to speculate that this second approach has
a higher risk of subjecting learners from underrepresented groups to stereotype
threat, a major risk when teaching a subject with a pervasive diversity
problem.&lt;/p&gt;
&lt;p&gt;Luckily for us all, there's a whole spectrum of approaches in between the
motivations-first and foundations-first extremes.
We can trust learners to self-motivate for a time, especially when we're
teaching scientists.
Attendees are there voluntarily (I would hope).
Likewise, learners will never have a perfect understanding of how their code is
working, regardless of how long you spend teaching the basics.
The key is to avoid unintentionally teaching pathological mental models that
are difficult for the instructor to diagnose and iterate beyond.&lt;/p&gt;
&lt;h1&gt;State of the Python lesson&lt;/h1&gt;
&lt;p&gt;As of this writing, the current default Python lesson for Software Carpentry is
&lt;a href="http://swcarpentry.github.io/python-novice-inflammation/"&gt;"Novice Inflammation"&lt;/a&gt;&lt;sup id="fnref:inflammation-commit"&gt;&lt;a class="footnote-ref" href="#fn:inflammation-commit"&gt;1&lt;/a&gt;&lt;/sup&gt;.
I have &lt;a href="//blog.byronjsmith.com/swc-python-lesson.html"&gt;written previously&lt;/a&gt; about my experience
with the lesson, and have not been shy with my criticism.
There is a &lt;em&gt;lot&lt;/em&gt; to be positive about in the composition of Inflammation.
It has been an effective approach to teaching Python to what at this point
must be several thousand workshop attendees.&lt;/p&gt;
&lt;p&gt;However, this post is about how we can do better.
My primary criticism focuses on the first section:
&lt;a href="http://swcarpentry.github.io/python-novice-inflammation/01-numpy/"&gt;"Analyzing Patient Data"&lt;/a&gt;.
The approach here falls towards the motivation-first extreme.
Learners are shown how one might go from raw data in a CSV to heatmaps
and line plots, two useful skills.&lt;/p&gt;
&lt;p&gt;The downside, however, is that this happens without fully explaining the
syntax, what libraries are, &lt;code&gt;numpy&lt;/code&gt; arrays versus Python lists, &lt;code&gt;dtypes&lt;/code&gt; vs
built-in Python types, and more.
I think that by using this particular motivating example while glossing over
those details we're giving learners a challenging mental model to iterate
beyond.
What's more, I believe that this results in a &lt;em&gt;diversity&lt;/em&gt; of models
making later instruction more likely to leave some learners behind.
Novice Inflammation also gets stuck in the weeds over difficult concepts which,
in my opinion, aren't nearly as important for learners, for example,
accumulating over particular axes in &lt;code&gt;numpy&lt;/code&gt; arrays.&lt;/p&gt;
&lt;p&gt;For this and other reasons Greg Wilson spearheaded an attempt to
reinvent the Python lesson.
The &lt;a href="http://swcarpentry.github.io/python-novice-gapminder/"&gt;"Novice Gapminder" lesson&lt;/a&gt;&lt;sup id="fnref:gapminder-commit"&gt;&lt;a class="footnote-ref" href="#fn:gapminder-commit"&gt;2&lt;/a&gt;&lt;/sup&gt;
is a from-scratch re-write.
It's worth noting that SWC's normal pull-request model for lesson development
is unable to accommodate a major overhaul like this one.&lt;/p&gt;
&lt;p&gt;Gapminder is different in several ways, for instance using &lt;code&gt;pandas&lt;/code&gt; as a focal
library instead of &lt;code&gt;numpy&lt;/code&gt;.
Notably for this commentary, though, it also takes a much more gradual approach
to motivating the material.
&lt;code&gt;pandas&lt;/code&gt; and &lt;code&gt;matplotlib&lt;/code&gt; are not introduced until the end of the first
half-day,
and only &lt;em&gt;after&lt;/em&gt; a thorough discussion of variable assignment, functions, and
data types.
The Gapminder lesson also appears to lack the distractions and rabbit holes
that I've criticized in Inflammation.&lt;/p&gt;
&lt;p&gt;Overall, I think Gapminder hits a superior balance between motivation
and basics, while also improve the structure and refining the details.
I have to applaud everyone who's contributed to its development.
I've now taught from the new lesson once, and co-instructed a workshop that
used the first half.
The improvements in the design were apparent both times.
I expect it to be well received by the SWC community when it becomes the
default.&lt;/p&gt;
&lt;h1&gt;Continual improvement&lt;/h1&gt;
&lt;p&gt;That's not to say, however, that it cannot be improved.
The same motivation-vs-foundations question has already come up in
&lt;a href="https://github.com/swcarpentry/python-novice-gapminder/issues/113"&gt;a discussion on GitHub&lt;/a&gt;.
A proposal was made to delay the use of &lt;code&gt;pandas&lt;/code&gt; and &lt;code&gt;matplotlib&lt;/code&gt; until the
second half, further front-loading the basics.
My personal opinion, having taught the lesson is that
this is unnecessary.
With the Gapminder lesson, by the time we got to these more advanced topics at
the end of the first half-day, learners appeared to be ready for the material,
comfortably updating their mental models in an appropriate way.
And, thankfully, I also didn't notice a loss of engagement due to the delayed
pay-off.&lt;/p&gt;
&lt;p&gt;Like many trade-offs in lesson design, the optimal position on the
motivations/foundations spectrum is context dependent.
I would focus on cool application instead of basic concepts
for the first session if I were
teaching high school students or any learners skeptical about the utility of
the material.
A room full of scientists who were there specifically to learn Python, however,
could probably tolerate even more front-loading of syntax and control-flow.
A framework to help instructors customize the materials for their audience
would be a very useful addition.&lt;/p&gt;
&lt;p&gt;The main purpose of this post is to nominate a slightly different approach
which introduces an advanced example early in the lesson without the
risk (I believe) of intimidating learners.&lt;/p&gt;
&lt;p&gt;In December 2016 I co-instructed a (not officially SWC)
&lt;a href="https://umswc.github.io/2016-12-14-umich/"&gt;workshop&lt;/a&gt; which taught Python over two half-day sessions to
about 20 learners, primarily graduate students in the biological sciences.&lt;/p&gt;
&lt;p&gt;My co-instructor, Jackie Cohen (&lt;a href="https://twitter.com/jczetta"&gt;\@jczetta&lt;/a&gt;),
taught the first half-day using the Gapminder lesson.
The positive reception from learners to the first half of the material was
testament not only to her skillful instruction, but also the quality of the
design.&lt;/p&gt;
&lt;p&gt;I then taught the second day with the
same gapminder dataset and covering the same
topics as the normal materials, but using &lt;a href="https://gist.github.com/bsmith89/5eeb9e7da35bd6b8bf28ae884f6478ff"&gt;a custom lesson plan&lt;/a&gt;.
Inspired by &lt;a href="https://github.com/swcarpentry/python-novice-gapminder/issues/113#issuecomment-256230540"&gt;a comment&lt;/a&gt; on the Gapminder GitHub repository,
I constructed a "realistic" analysis of the gapminder data
as a Jupyter notebook.
In particular, the notebook includes code to generate a fairly involved
figure telling a story about the relationship between per-capita GDP and
life-expectancy.&lt;/p&gt;
&lt;p&gt;&lt;img alt="An example visualization of the gapminder data." src="//blog.byronjsmith.com/static/images/gapminder-analysis.png"&gt;&lt;/p&gt;
&lt;p&gt;I started the second day by having learners download and run this notebook,
demonstrating the quality of analyses they could produce with fewer than 100
lines of code.
By &lt;em&gt;not&lt;/em&gt; live-coding, and &lt;em&gt;not&lt;/em&gt; expecting the learners to type along during the
introduction, I believe this approach minimizes the likelihood of intimidating
the learners with syntax.
To that end, I also did not walk through the code itself, but instead focused
on describing the overarching flow of the analysis:
loading external data, selecting a subset, plotting two columns as a
scatter-plot with a third column determining the size of the points, running a
linear regression, and plotting a best-fit line.
The purpose of this introduction was purely to motivate the material, not
to introduce the concepts.&lt;/p&gt;
&lt;p&gt;I then had them open a new, empty notebook, and the remainder of the lesson
(which &lt;em&gt;was&lt;/em&gt; done in the traditional live-coding style)
then revolved around reconstructing the same analysis from scratch,
a thematic unification, that I found to be elegant.
Since the pre-constructed analysis made use of for-loops, if-statements,
and functions, I was able to limit my use of foo/bar style examples and
quickly return to the core analysis demonstrating the use of these elements
in a realistic setting.
Our workshop was advertised as an introduction to Jupyter notebooks, data
manipulation, and plotting, (as well as novice Python) so a significant
fraction of the time was spent on these topics and libraries instead of more
foundational concepts.&lt;/p&gt;
&lt;h1&gt;Where to go from here?&lt;/h1&gt;
&lt;p&gt;I found this approach to be quite successful.
In-person and exit survey feedback has been uniformly positive and
learners appeared to have achieved most or all of the learning objectives
of the core Gapminder lesson.
While the "realistic analysis" approach sounds more like the
&lt;a href="http://www.datacarpentry.org/"&gt;Data Carpentry&lt;/a&gt;
style, in this particular case it was a great fit for the Software Carpentry
learning objectives.&lt;/p&gt;
&lt;p&gt;I believe that this model could be implemented in the core Gapminder lesson,
perhaps starting in the second half (as we did), or with a different
example notebook for each half-day.
That would, however, entail modifying most or all of the sections to
focus on the new unified example.
Is it worth expending the tens of hours required to implement it?
Even if it were implemented, I'm not convinced that the SWC lesson development
model makes this kind of large-scale refactoring feasible.&lt;/p&gt;
&lt;p&gt;As an alternative to submitting a pull request,
I'm hoping that I can convince a few instructors to try it out for themselves.
Positive experiences with an unofficial fork makes patching the main branch a
more rational investment.
I've already been &lt;a href="http://lists.software-carpentry.org/pipermail/discuss/2016-May/004529.html"&gt;evangelizing&lt;/a&gt; in a similar way for an
&lt;a href="https://github.com/bsmith89/git-novice-outline"&gt;alternative Git lesson&lt;/a&gt;,
sharing my immature outline and encouraging folks to try it out
themselves.
Is there a better approach to making medium to large changes to the design of
a SWC lesson?&lt;/p&gt;
&lt;p&gt;In conclusion: I think we need additional discussion (and data) about the
motivations/foundations trade-off in our lessons.
I'd also like to hear your thoughts on the best way to lobby for and introduce
moderately sized changes to the core materials.
What do you think about my approach?
If you're feeling brave, please try it out and let me know how it goes!&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:inflammation-commit"&gt;
&lt;p&gt;HEAD at
&lt;a href="https://github.com/swcarpentry/python-novice-inflammation/tree/030f3fbd3006cea06e42bbd14a62ddb33098b9f6"&gt;030f3fbd30&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:inflammation-commit" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:gapminder-commit"&gt;
&lt;p&gt;HEAD at &lt;a href="https://github.com/swcarpentry/python-novice-gapminder/tree/e303e6a9d309bdcbcfb370c8125b7792d4096968"&gt;e303e6a9d3&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:gapminder-commit" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Education"></category><category term="software-carpentry"></category><category term="teaching"></category><category term="programming"></category><category term="python"></category><category term="jupyter"></category></entry><entry><title>Take five minutes to simplify your life with Make</title><link href="//blog.byronjsmith.com/makefile-shortcuts.html" rel="alternate"></link><published>2016-06-14T12:00:00-04:00</published><updated>2017-11-21T09:30:00-05:00</updated><author><name>Byron J. Smith</name></author><id>tag:blog.byronjsmith.com,2016-06-14:/makefile-shortcuts.html</id><summary type="html">&lt;p&gt;&lt;em&gt;WARNING: Because of the Markdown rendering of this blog, tab characters
have been replaced with 4 spaces in code blocks.
For this reason, &lt;strong&gt;the makefile code will not work&lt;/strong&gt; when copied directly from
the post.
Instead, you must first replace all 4-space indents with a tab character.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I use &lt;em&gt;GNU Make&lt;/em&gt; to automate my data processing pipelines.
I've written a &lt;a href="//blog.byronjsmith.com/make-analysis.html"&gt;tutorial&lt;/a&gt; &lt;sup id="fnref:shorter-tutorials"&gt;&lt;a class="footnote-ref" href="#fn:shorter-tutorials"&gt;1&lt;/a&gt;&lt;/sup&gt; for novices on the
basics of using &lt;em&gt;Make&lt;/em&gt; for reproducible analysis and I think that everyone who
writes more than one script, or runs more than one shell command to process
their data can benefit from automating that process.
&lt;a href="http://kbroman.org/minimal_make/"&gt;I'm&lt;/a&gt; &lt;a href="https://bost.ocks.org/mike/make/"&gt;not&lt;/a&gt;
&lt;a href="http://zmjones.com/make/"&gt;alone&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;However, the investment required to learn &lt;em&gt;Make&lt;/em&gt; and to convert an
entire project can seem daunting to many time-strapped researchers.
Even if you aren't
living the dream—rebuilding
a paper from raw data with a single invocation of
&lt;code&gt;make paper&lt;/code&gt;—I still
think you can benefit …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;WARNING: Because of the Markdown rendering of this blog, tab characters
have been replaced with 4 spaces in code blocks.
For this reason, &lt;strong&gt;the makefile code will not work&lt;/strong&gt; when copied directly from
the post.
Instead, you must first replace all 4-space indents with a tab character.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I use &lt;em&gt;GNU Make&lt;/em&gt; to automate my data processing pipelines.
I've written a &lt;a href="//blog.byronjsmith.com/make-analysis.html"&gt;tutorial&lt;/a&gt; &lt;sup id="fnref:shorter-tutorials"&gt;&lt;a class="footnote-ref" href="#fn:shorter-tutorials"&gt;1&lt;/a&gt;&lt;/sup&gt; for novices on the
basics of using &lt;em&gt;Make&lt;/em&gt; for reproducible analysis and I think that everyone who
writes more than one script, or runs more than one shell command to process
their data can benefit from automating that process.
&lt;a href="http://kbroman.org/minimal_make/"&gt;I'm&lt;/a&gt; &lt;a href="https://bost.ocks.org/mike/make/"&gt;not&lt;/a&gt;
&lt;a href="http://zmjones.com/make/"&gt;alone&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;However, the investment required to learn &lt;em&gt;Make&lt;/em&gt; and to convert an
entire project can seem daunting to many time-strapped researchers.
Even if you aren't
living the dream—rebuilding
a paper from raw data with a single invocation of
&lt;code&gt;make paper&lt;/code&gt;—I still
think you can benefit from adding a simple &lt;code&gt;Makefile&lt;/code&gt; to your project root.&lt;/p&gt;
&lt;p&gt;When done right, scripting the tedious parts of your job &lt;em&gt;can&lt;/em&gt;
save you time in the long run&lt;sup id="fnref:xkcd-refs"&gt;&lt;a class="footnote-ref" href="#fn:xkcd-refs"&gt;2&lt;/a&gt;&lt;/sup&gt;.
But the time savings aren't the only reason to do it.
For me, a bigger advantage is that I get to save my mental energy for
more interesting problems&lt;sup id="fnref:cook-ref"&gt;&lt;a class="footnote-ref" href="#fn:cook-ref"&gt;3&lt;/a&gt;&lt;/sup&gt;.
&lt;em&gt;Make&lt;/em&gt; goes a step further and lets me forget about everything but my
real objective.
With a &lt;code&gt;make [target]&lt;/code&gt; invocation I don't even need to remember the name of the
script.&lt;/p&gt;
&lt;h2&gt;The default makefile&lt;/h2&gt;
&lt;p&gt;TL;DR: All of the code in this post is available as a &lt;a href="https://gist.github.com/bsmith89/c6811893c1cbd2a72cc1d144a197bef2"&gt;gist&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here's what a minimal makefile might look like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="cp"&gt;define PROJECT_HELP_MSG&lt;/span&gt;

&lt;span class="nf"&gt;Usage&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    make &lt;span class="nb"&gt;help&lt;/span&gt;                   show this message
    make clean                  remove intermediate files &lt;span class="o"&gt;(&lt;/span&gt;see CLEANUP&lt;span class="o"&gt;)&lt;/span&gt;

    make &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;VENV&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;                make a virtualenv in the base directory &lt;span class="o"&gt;(&lt;/span&gt;see VENV&lt;span class="o"&gt;)&lt;/span&gt;
    make python-reqs            install python packages in requirements.pip
    make git-config             &lt;span class="nb"&gt;set&lt;/span&gt; &lt;span class="nb"&gt;local&lt;/span&gt; git configuration
    make setup                  git init&lt;span class="p"&gt;;&lt;/span&gt; make python-reqs git-config

    make start-jupyter          launch a jupyter server from the &lt;span class="nb"&gt;local&lt;/span&gt; virtualenv

&lt;span class="cp"&gt;endef&lt;/span&gt;
&lt;span class="k"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;PROJECT_HELP_MSG&lt;/span&gt;

&lt;span class="nf"&gt;help&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$$&lt;/span&gt;PROJECT_HELP_MSG &lt;span class="p"&gt;|&lt;/span&gt; less

&lt;span class="nf"&gt;.git&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    git init

&lt;span class="nf"&gt;git-config&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; .&lt;span class="n"&gt;git&lt;/span&gt; 
    git config --local filter.dropoutput_jupyter.clean &lt;span class="se"&gt;\&lt;/span&gt;
        drop_jupyter_output.sh
    git config --local filter.dropoutput_jupyter.smudge cat
    git config --local core.page &lt;span class="s1"&gt;&amp;#39;less -x4&amp;#39;&lt;/span&gt;
    git config --local &lt;span class="se"&gt;\&lt;/span&gt;
        diff.daff-csv.command &lt;span class="s2"&gt;&amp;quot;daff.py diff --git&amp;quot;&lt;/span&gt;
    git config --local &lt;span class="se"&gt;\&lt;/span&gt;
        merge.daff-csv.name &lt;span class="s2"&gt;&amp;quot;daff.py tabular merge&amp;quot;&lt;/span&gt;
    git config --local &lt;span class="se"&gt;\&lt;/span&gt;
        merge.daff-csv.driver &lt;span class="s2"&gt;&amp;quot;daff.py merge --output %A %O %A %B&amp;quot;&lt;/span&gt;

&lt;span class="nv"&gt;VENV&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; .venv
&lt;span class="k"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;VIRTUAL_ENV&lt;/span&gt; &lt;span class="o"&gt;:=&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;abspath &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;VENV&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;PATH&lt;/span&gt; &lt;span class="o"&gt;:=&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;VIRTUAL_ENV&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;/bin:&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;PATH&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;

&lt;span class="nf"&gt;${VENV}&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    python3 -m venv &lt;span class="nv"&gt;$@&lt;/span&gt;

&lt;span class="nf"&gt;python-reqs&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;requirements&lt;/span&gt;.&lt;span class="n"&gt;pip&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; ${&lt;span class="n"&gt;VENV&lt;/span&gt;}
    pip install --upgrade -r requirements.pip

&lt;span class="nf"&gt;setup&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; ${&lt;span class="n"&gt;VENV&lt;/span&gt;} &lt;span class="n"&gt;python&lt;/span&gt;-&lt;span class="n"&gt;reqs&lt;/span&gt; &lt;span class="n"&gt;git&lt;/span&gt;-&lt;span class="n"&gt;config&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; .&lt;span class="n"&gt;git&lt;/span&gt;

&lt;span class="nf"&gt;start-jupyter&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    jupyter notebook --config&lt;span class="o"&gt;=&lt;/span&gt;jupyter_notebook_config.py

&lt;span class="nv"&gt;CLEANUP&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; *.pyc

&lt;span class="nf"&gt;clean&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    rm -rf &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;CLEANUP&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;

&lt;span class="nf"&gt;.PHONY&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;help&lt;/span&gt; &lt;span class="n"&gt;git&lt;/span&gt;-&lt;span class="n"&gt;config&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;-&lt;span class="n"&gt;jupter&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt;-&lt;span class="n"&gt;reqs&lt;/span&gt; &lt;span class="n"&gt;setup&lt;/span&gt; &lt;span class="n"&gt;clean&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;If you want to start using it right away, download the &lt;a href="https://gist.github.com/bsmith89/c6811893c1cbd2a72cc1d144a197bef2"&gt;gist&lt;/a&gt;,
which includes a couple of other necessary files.
As long as you aren't saving it over another makefile, it won't mess anything
up.&lt;/p&gt;
&lt;p&gt;But let's break it down so you can see how it's made and why it's awesome.&lt;/p&gt;
&lt;p&gt;From the top!&lt;/p&gt;
&lt;h2&gt;A help message for your project&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="cp"&gt;define PROJECT_HELP_MSG&lt;/span&gt;

&lt;span class="nf"&gt;Usage&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    make &lt;span class="nb"&gt;help&lt;/span&gt;                   show this message
    make clean                  remove intermediate files &lt;span class="o"&gt;(&lt;/span&gt;see CLEANUP&lt;span class="o"&gt;)&lt;/span&gt;

    make git-config             &lt;span class="nb"&gt;set&lt;/span&gt; &lt;span class="nb"&gt;local&lt;/span&gt; git configuration
    make &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;VENV&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;                make a virtualenv in the base directory &lt;span class="o"&gt;(&lt;/span&gt;see VENV&lt;span class="o"&gt;)&lt;/span&gt;
    make python-reqs            install python packages in requirements.pip
    make setup                  git init&lt;span class="p"&gt;;&lt;/span&gt; make python-reqs git-config

    make start-jupyter          launch a jupyter server from the &lt;span class="nb"&gt;local&lt;/span&gt; virtualenv

&lt;span class="cp"&gt;endef&lt;/span&gt;
&lt;span class="k"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;PROJECT_HELP_MSG&lt;/span&gt;

&lt;span class="nf"&gt;help&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$$&lt;/span&gt;PROJECT_HELP_MSG
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The top of our makefile is a help message.
Running the traditional invocation &lt;code&gt;make help&lt;/code&gt; will call that recipe and we'll
see an abridged list of the available recipes printed to our terminal.
Since &lt;code&gt;help&lt;/code&gt; is the very first recipe in the makefile, it will also be the
default recipe;
typing &lt;code&gt;make&lt;/code&gt; alone prints the help message.&lt;/p&gt;
&lt;p&gt;As you start adding additional recipes, fill out this usage message.
That way you'll have both documentation about the analysis targets, and also
a handy cheatsheet.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Edit (2016-06-15):&lt;/em&gt; &lt;a href="https://www.reddit.com/r/bioinformatics/comments/4o7aaa/a_simple_makefile_to_make_your_life_simple_xpost/d4aa8ir"&gt;On Reddit, /r/guepier&lt;/a&gt; suggests using a
nifty trick to auto-generate these help messages,
keeping documentation and recipes together in your makefile.&lt;/p&gt;
&lt;h2&gt;Streamline git setup&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nf"&gt;.git&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    git init
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Every project should be &lt;a href="https://dx.doi.org/10.1186/1751-0473-8-7"&gt;version controlled&lt;/a&gt;.
I prefer git, but the makefile can probably be adapted for Mercurial,
Subversion, darcs, etc.
This recipe is so simple as to appear useless (since &lt;code&gt;make .git&lt;/code&gt; is no easier
to type than &lt;code&gt;git init&lt;/code&gt;) but we use the directory &lt;code&gt;.git/&lt;/code&gt; as an
&lt;a href="https://www.gnu.org/software/make/manual/html_node/Prerequisite-Types.html"&gt;order-only prerequisite&lt;/a&gt;
for the next recipe:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nf"&gt;git-config&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; .&lt;span class="n"&gt;git&lt;/span&gt; 
    git config --local filter.dropoutput_jupyter.clean &lt;span class="se"&gt;\&lt;/span&gt;
        drop_jupyter_output.sh
    git config --local filter.dropoutput_jupyter.smudge cat
    git config --local core.page &lt;span class="s1"&gt;&amp;#39;less -x4&amp;#39;&lt;/span&gt;
    git config --local &lt;span class="se"&gt;\&lt;/span&gt;
        diff.daff-csv.command &lt;span class="s2"&gt;&amp;quot;daff.py diff --git&amp;quot;&lt;/span&gt;
    git config --local &lt;span class="se"&gt;\&lt;/span&gt;
        merge.daff-csv.name &lt;span class="s2"&gt;&amp;quot;daff.py tabular merge&amp;quot;&lt;/span&gt;
    git config --local &lt;span class="se"&gt;\&lt;/span&gt;
        merge.daff-csv.driver &lt;span class="s2"&gt;&amp;quot;daff.py merge --output %A %O %A %B&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Git configuration is &lt;em&gt;just&lt;/em&gt; annoying enough that I often put it off for a new
project.
With this recipe I don't have to!&lt;/p&gt;
&lt;p&gt;There are three parts to the configuration above;
customize it for how you use git.&lt;/p&gt;
&lt;h3&gt;Drop Jupyter Notebook output&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;git config --local filter.dropoutput_jupyter.clean &lt;span class="se"&gt;\&lt;/span&gt;
    ./drop_jupyter_output.sh
git config --local filter.dropoutput_jupyter.smudge cat
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I set up a &lt;a href="https://git-scm.com/book/en/v2/Customizing-Git-Git-Attributes"&gt;clean/smudge filter&lt;/a&gt; for my Jupyter notebooks.
Outputs of analysis should generally not be version controlled,
and this includes those outputs that are inlined in a Jupyter notebook.
Now, when you &lt;code&gt;git add&lt;/code&gt; and &lt;code&gt;git diff&lt;/code&gt; notebooks, the output from cells will
be automatically ignored.
Thankfully, using this filter won't change the contents of the &lt;code&gt;.ipynb&lt;/code&gt; file
itself, just the contents of the diff.
This does mean, however, that when you &lt;code&gt;git checkout&lt;/code&gt; an old version of your
notebook you'll have to re-execute all of the cells to get the results.&lt;/p&gt;
&lt;p&gt;Two other files are needed for this configuration to have any effect.
First, &lt;code&gt;.gitattributes&lt;/code&gt; which is a tab-separated file mapping filename patterns
to special git configuration.
The first line in that file should be the following.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;*.ipynb filter=dropoutput_jupyter&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;(That's a tab after &lt;code&gt;*.ipynb&lt;/code&gt;.)&lt;/p&gt;
&lt;p&gt;The second file is the filter &lt;code&gt;drop_jupyter_output.sh&lt;/code&gt;,
which needs to be executable.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="ch"&gt;#!/usr/bin/env bash&lt;/span&gt;
&lt;span class="c1"&gt;# run `chmod +x drop_jupyter_output.sh` to make it executable.&lt;/span&gt;

&lt;span class="nv"&gt;file&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;mktemp&lt;span class="k"&gt;)&lt;/span&gt;
cat &amp;lt;&lt;span class="p"&gt;&amp;amp;&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &amp;gt;&lt;span class="nv"&gt;$file&lt;/span&gt;
jupyter nbconvert --to notebook --ClearOutputPreprocessor.enabled&lt;span class="o"&gt;=&lt;/span&gt;True &lt;span class="se"&gt;\&lt;/span&gt;
    &lt;span class="nv"&gt;$file&lt;/span&gt; --stdout &lt;span class="m"&gt;2&lt;/span&gt;&amp;gt;/dev/null
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;Display tabs as four spaces&lt;/h3&gt;
&lt;p&gt;I also configure &lt;code&gt;less&lt;/code&gt; to show four spaces for tabs.
This makes &lt;code&gt;git diff&lt;/code&gt;-ing my makefile much easier on the eyes.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;git config --local core.page &lt;span class="s1"&gt;&amp;#39;less -x4&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;Smart &lt;code&gt;diff&lt;/code&gt;s for tabular data&lt;/h3&gt;
&lt;p&gt;Since git considers changes on a per-line basis, looking at
&lt;code&gt;diff&lt;/code&gt;s of comma-delimited and tab-delimited files can get obnoxious.
The program &lt;a href="http://paulfitz.github.io/daff/"&gt;&lt;code&gt;daff&lt;/code&gt;&lt;/a&gt; fixes this problem.&lt;/p&gt;
&lt;p&gt;We'll configure git to use &lt;code&gt;daff&lt;/code&gt; for all tabular files.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;git config --local &lt;span class="se"&gt;\&lt;/span&gt;
    diff.daff-csv.command &lt;span class="s2"&gt;&amp;quot;daff.py diff --git&amp;quot;&lt;/span&gt;
git config --local &lt;span class="se"&gt;\&lt;/span&gt;
    merge.daff-csv.name &lt;span class="s2"&gt;&amp;quot;daff.py tabular merge&amp;quot;&lt;/span&gt;
git config --local &lt;span class="se"&gt;\&lt;/span&gt;
    merge.daff-csv.driver &lt;span class="s2"&gt;&amp;quot;daff.py merge --output %A %O %A %B&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Just like the output filter for Jupyter notebooks, we need to associate
this configuration with CSVs and TSVs in our &lt;code&gt;.gitattributes&lt;/code&gt; file by adding
the following two lines.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;tc&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="n"&gt;sv&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;diff&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;daff&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;csv&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;tc&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="n"&gt;sv&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;merge&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;daff&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;csv&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;Automatic python virtual environments&lt;/h2&gt;
&lt;p&gt;There are plenty of &lt;a href="https://www.davidfischer.name/2010/04/why-you-should-be-using-pip-and-virtualenv/"&gt;reasons&lt;/a&gt; to sandbox your python environments.
If you're like me and keep a separate virtual environment for every project,
you'll appreciate these recipes to automate creating them and updating
packages.&lt;/p&gt;
&lt;p&gt;If you don't use python/pip, these recipes can be swapped out for other
sandboxing systems.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;VENV&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; .venv
&lt;span class="k"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;VIRTUAL_ENV&lt;/span&gt; &lt;span class="o"&gt;:=&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;abspath &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;VENV&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;PATH&lt;/span&gt; &lt;span class="o"&gt;:=&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;VIRTUAL_ENV&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;/bin:&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;PATH&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;

&lt;span class="nf"&gt;${VENV}&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    python3 -m venv &lt;span class="nv"&gt;$@&lt;/span&gt;

&lt;span class="nf"&gt;python-reqs&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;requirements&lt;/span&gt;.&lt;span class="n"&gt;pip&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; ${&lt;span class="n"&gt;VENV&lt;/span&gt;}
    pip install --upgrade -r requirements.pip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In the top block, we first set a variable &lt;code&gt;VENV&lt;/code&gt; to be the location of our
virtual environment.
We then set &lt;code&gt;VIRTUAL_ENV&lt;/code&gt; and prepend its &lt;code&gt;bin/&lt;/code&gt; to our &lt;code&gt;PATH&lt;/code&gt;.
By exporting these variables, all recipes run from this makefile will
use python packages and executables from the virtual environment.
We don't have to remember to &lt;code&gt;source .venv/bin/activate&lt;/code&gt; first!&lt;/p&gt;
&lt;p&gt;(&lt;em&gt;Edit (2016-06-22):&lt;/em&gt; Based on my own testing, it would appear that this
approach to virtual environments in recipes does not work with the default
&lt;em&gt;GNU Make&lt;/em&gt; version installed on OS X.
It will, however, work with &lt;a href="http://brew.sh/"&gt;Homebrew&lt;/a&gt;'s version which is
installed as &lt;code&gt;gmake&lt;/code&gt; instead of &lt;code&gt;make&lt;/code&gt;.
It is unclear to me why the behavior is different.)&lt;/p&gt;
&lt;p&gt;The next block is the recipe to initialize the virtual environment.
If you're not using Python 3 for your project you will have to edit this one.&lt;/p&gt;
&lt;p&gt;And finally, a recipe to install and update all of the packages listed in
&lt;code&gt;requirements.pip&lt;/code&gt;.
If you want to make a change to your python requirements, add it to
&lt;code&gt;requirements.pip&lt;/code&gt; and re-run &lt;code&gt;make python-reqs&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;You can bootstrap other software installations similarly.
And, if you discipline yourself to make all changes to your execution
environment in this way, you'll have a permanently up-to-date record of your
system requirements.&lt;/p&gt;
&lt;h2&gt;Single-command project setup&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nf"&gt;setup&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; ${&lt;span class="n"&gt;VENV&lt;/span&gt;} &lt;span class="n"&gt;python&lt;/span&gt;-&lt;span class="n"&gt;reqs&lt;/span&gt; &lt;span class="n"&gt;git&lt;/span&gt;-&lt;span class="n"&gt;config&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; .&lt;span class="n"&gt;git&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;With this meta-target a simple &lt;code&gt;make setup&lt;/code&gt; will have our new project
configured and ready to go.
This is particularly useful if you work on multiple machines:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;git clone git@github.com:username/project.git
&lt;span class="nb"&gt;cd&lt;/span&gt; project
make setup
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;is all it takes to get up and running.&lt;/p&gt;
&lt;h2&gt;Launch your tools without the hassle&lt;/h2&gt;
&lt;p&gt;I use Jupyter Notebooks a lot.
With this recipe (and the &lt;code&gt;PATH&lt;/code&gt; we export above) I don't have to remember
to activate my virtual environment or invoke specific configuration files
when I launch a server.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nf"&gt;start-jupyter&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    jupyter notebook --config&lt;span class="o"&gt;=&lt;/span&gt;jupyter_notebook_config.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Put whatever you'd like into the &lt;a href="http://jupyter-notebook.readthedocs.io/en/latest/config.html"&gt;config file&lt;/a&gt;.
I like to keep my notebooks in a subdirectory, so my invocation is a little different:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;jupyter notebook --config&lt;span class="o"&gt;=&lt;/span&gt;ipynb/jupyter_notebook_config.py &lt;span class="se"&gt;\&lt;/span&gt;
    --notebook-dir&lt;span class="o"&gt;=&lt;/span&gt;ipynb/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;And my configuration automatically changes the working directory to
the project root when launching a new notebook.&lt;/p&gt;
&lt;p&gt;Customize!
The same general idea works for any other software you can start from the shell.
No need to remember any of the obnoxious command-line flags.&lt;/p&gt;
&lt;h2&gt;Quick cleanup&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;CLEANUP&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; *.pyc

&lt;span class="nf"&gt;clean&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    rm -rf &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;CLEANUP&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;A ubiquitous target for &lt;em&gt;Make&lt;/em&gt; is &lt;code&gt;clean&lt;/code&gt; to tidy up the repository.
With this makefile, run &lt;code&gt;make clean&lt;/code&gt; to remove all the &lt;code&gt;*.pyc&lt;/code&gt; files.
Customize the &lt;code&gt;CLEANUP&lt;/code&gt; variable with filenames and globs you find yourself
&lt;code&gt;rm&lt;/code&gt;-ing repeatedly.
For me, this includes a bunch of &lt;code&gt;*.log&lt;/code&gt; and &lt;code&gt;*.logfile&lt;/code&gt; files.&lt;/p&gt;
&lt;h2&gt;Fork this code!&lt;/h2&gt;
&lt;p&gt;That's all I've got for a default makefile.
And even this one is more complicated than it has to be;
any &lt;em&gt;one&lt;/em&gt; component from it can make your life easier when practicing
reproducible research.&lt;/p&gt;
&lt;p&gt;The whole point is to hide as much of the humdrum stuff as you can so you get
to focus on what counts.
I've found this makefile saves me both time and, more importantly, mental
energy.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;Makefile&lt;/code&gt;, &lt;code&gt;.gitattributes&lt;/code&gt;, &lt;code&gt;requirements.pip&lt;/code&gt; and
&lt;code&gt;drop_jupyter_output.sh&lt;/code&gt; described
here can all be downloaded from &lt;a href="https://gist.github.com/bsmith89/c6811893c1cbd2a72cc1d144a197bef2"&gt;this gist&lt;/a&gt;&lt;sup id="fnref:bootstrap-idea"&gt;&lt;a class="footnote-ref" href="#fn:bootstrap-idea"&gt;4&lt;/a&gt;&lt;/sup&gt;.
Next time you're starting a project, download them to the project directory,
run &lt;code&gt;make setup&lt;/code&gt;, and let me know what you think!&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:shorter-tutorials"&gt;
&lt;p&gt;My tutorial is designed to fill a three hour
    Software Carpentry lesson.  There are a number of much shorter
    primers to get you started (e.g. &lt;a href="http://zmjones.com/make/"&gt;#1&lt;/a&gt;,
    &lt;a href="https://bost.ocks.org/mike/make/"&gt;#2&lt;/a&gt;, &lt;a href="http://kbroman.org/minimal_make/"&gt;#3&lt;/a&gt;).&amp;#160;&lt;a class="footnote-backref" href="#fnref:shorter-tutorials" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:xkcd-refs"&gt;
&lt;p&gt;Randall Munroe does not agree.
    Relevant XKCDs: &lt;a href="https://xkcd.com/1205/"&gt;#1&lt;/a&gt;,
    &lt;a href="https://xkcd.com/1319/"&gt;#2&lt;/a&gt;, and &lt;a href="https://xkcd.com/974/"&gt;#3&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:xkcd-refs" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:cook-ref"&gt;
&lt;p&gt;John Cook makes &lt;a href="http://www.johndcook.com/blog/2015/12/22/automate-to-save-mental-energy-not-time/"&gt;this argument&lt;/a&gt; on his blog.&amp;#160;&lt;a class="footnote-backref" href="#fnref:cook-ref" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:bootstrap-idea"&gt;
&lt;p&gt;Even better, you could write a recipe to download those files
    on &lt;code&gt;make setup&lt;/code&gt;!&amp;#160;&lt;a class="footnote-backref" href="#fnref:bootstrap-idea" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Computing"></category><category term="make"></category><category term="pipelines"></category><category term="bioinformatics"></category><category term="protips"></category><category term="git"></category><category term="venv"></category><category term="python"></category></entry><entry><title>Software carpentry instructor training</title><link href="//blog.byronjsmith.com/instructor-survival.html" rel="alternate"></link><published>2016-05-30T12:00:00-04:00</published><updated>2016-05-31T12:00:00-04:00</updated><author><name>Byron J. Smith</name></author><id>tag:blog.byronjsmith.com,2016-05-30:/instructor-survival.html</id><summary type="html">&lt;p&gt;&lt;em&gt;Edit (2016-05-31): Added a hypothesis for why my results differ somewhat from
&lt;a href="http://www.datacarpentry.org/blog/instructor-metrics/"&gt;Erin Becker's&lt;/a&gt;.  Briefly: I removed individuals who taught
before they were officially certified.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;A couple weeks ago, Greg Wilson &lt;a href="http://lists.software-carpentry.org/pipermail/discuss/2016-May/004471.html"&gt;asked&lt;/a&gt; the &lt;a href="http://software-carpentry.org/"&gt;Software
Carpentry&lt;/a&gt; community for &lt;a href="http://software-carpentry.org/blog/2016/05/looking-for-a-model.html"&gt;feedback&lt;/a&gt; on a collection of
data about the organization's instructors, when they were certified, and when
they taught.
Having dabbled in &lt;a href="https://en.wikipedia.org/wiki/Survival_analysis"&gt;survival analysis&lt;/a&gt;,
I was excited to explore the data within that context.&lt;/p&gt;
&lt;p&gt;Survival analysis is focused on time-to-event data,
for example time from birth until death, but also time to failure of
engineered systems,
or in this case, time from instructor certification to first teaching a
workshop.
The language is somewhat morbid, but helps with talking
precisely about models that can easily be applied to a variety of data,
only sometimes involving death or failure.
The power of modern survival analysis is the ability to include results from
subjects who have not …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;Edit (2016-05-31): Added a hypothesis for why my results differ somewhat from
&lt;a href="http://www.datacarpentry.org/blog/instructor-metrics/"&gt;Erin Becker's&lt;/a&gt;.  Briefly: I removed individuals who taught
before they were officially certified.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;A couple weeks ago, Greg Wilson &lt;a href="http://lists.software-carpentry.org/pipermail/discuss/2016-May/004471.html"&gt;asked&lt;/a&gt; the &lt;a href="http://software-carpentry.org/"&gt;Software
Carpentry&lt;/a&gt; community for &lt;a href="http://software-carpentry.org/blog/2016/05/looking-for-a-model.html"&gt;feedback&lt;/a&gt; on a collection of
data about the organization's instructors, when they were certified, and when
they taught.
Having dabbled in &lt;a href="https://en.wikipedia.org/wiki/Survival_analysis"&gt;survival analysis&lt;/a&gt;,
I was excited to explore the data within that context.&lt;/p&gt;
&lt;p&gt;Survival analysis is focused on time-to-event data,
for example time from birth until death, but also time to failure of
engineered systems,
or in this case, time from instructor certification to first teaching a
workshop.
The language is somewhat morbid, but helps with talking
precisely about models that can easily be applied to a variety of data,
only sometimes involving death or failure.
The power of modern survival analysis is the ability to include results from
subjects who have not yet experienced the event when data is collected.
After all, studies rarely have the funding or patience to continue indefinitely.
and excluding those data points entirely would falsely inflate rate
estimates.
Instead, the absence of an event for an individual during the study is useful
information that contributes to the precise estimation of rates.&lt;/p&gt;
&lt;p&gt;Let's grab the Software Carpentry data and take a look.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;curl -O http://software-carpentry.org/files/2016/05/teaching-stats-2016-05.csv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now in Python:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;patsy&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;statsmodels.api&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sm&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;seaborn&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sns&lt;/span&gt;

&lt;span class="c1"&gt;# If you&amp;#39;re using jupyter:&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;

&lt;span class="n"&gt;raw_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;teaching-stats-2016-05.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sort_values&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Person&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;raw_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tail&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;      Person   Certified      Taught&lt;/span&gt;
&lt;span class="err"&gt;1781   11268  2016-03-16         NaN&lt;/span&gt;
&lt;span class="err"&gt;1782   11278  2016-03-29         NaN&lt;/span&gt;
&lt;span class="err"&gt;1783   11280  2016-04-19         NaN&lt;/span&gt;
&lt;span class="err"&gt;1784   11292  2016-02-29         NaN&lt;/span&gt;
&lt;span class="err"&gt;1785   11293  2016-03-01         NaN&lt;/span&gt;
&lt;span class="err"&gt;1558   11294  2016-04-25  2016-04-18&lt;/span&gt;
&lt;span class="err"&gt;1557   11294  2016-04-25  2016-02-02&lt;/span&gt;
&lt;span class="err"&gt;1559   11295  2016-04-25  2016-02-02&lt;/span&gt;
&lt;span class="err"&gt;1786   11298  2016-04-21         NaN&lt;/span&gt;
&lt;span class="err"&gt;1787   11311  2016-04-19         NaN&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This data is arranged as three columns: a ID number for each person,
the date they were certified, and the date they taught.
Individuals who have taught more than once have more than one row,
and individuals who have been certified but have not yet taught have one
row where taught is &lt;code&gt;NaN&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In our analysis, each certified instructor will be a data point with a
certification date, a date of first teaching, second teaching, etc.
Let's rearrange our data to reflect this structure using pandas
split-apply-combine functionality.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_person_details&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sort_values&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Taught&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;certified&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Certified&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;drop_duplicates&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;certified&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="n"&gt;taught&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Taught&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;drop_duplicates&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;taught&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;taught_first&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;taught&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;taught_second&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nan&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;taught_first&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;taught&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;taught_second&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;taught&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Series&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;certified&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;certified&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                      &lt;span class="s1"&gt;&amp;#39;taught_first&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;taught_first&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                      &lt;span class="s1"&gt;&amp;#39;taught_second&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;taught_second&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                      &lt;span class="s1"&gt;&amp;#39;taught_count&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;taught&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;notnull&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;()})&lt;/span&gt;

&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;raw_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;groupby&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Person&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;get_person_details&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;         certified  taught_count taught_first taught_second&lt;/span&gt;
&lt;span class="err"&gt;Person&lt;/span&gt;
&lt;span class="err"&gt;48      2014-05-04             1   2014-09-11           NaN&lt;/span&gt;
&lt;span class="err"&gt;75      2013-07-20            15   2013-03-20    2013-03-24&lt;/span&gt;
&lt;span class="err"&gt;85      2014-12-23             4   2015-03-06    2015-06-17&lt;/span&gt;
&lt;span class="err"&gt;87      2013-11-25             4   2014-05-12    2015-03-20&lt;/span&gt;
&lt;span class="err"&gt;135     2015-02-03             1   2015-09-03           NaN&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;And some calculations&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;certified&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;certified&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;taught_first&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;taught_first&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;taught_second&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;taught_second&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;has_taught&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;taught_count&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;has_taught_multiple&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;taught_count&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;time_to_taught_first&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;taught_first&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;
                                &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;certified&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;days&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;time_to_taught_second&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;taught_second&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;
                                 &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;certified&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;days&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;time_between_first_second&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time_to_taught_second&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;
                                     &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time_to_taught_first&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;year_certified&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;certified&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;year&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I'd like to include data on how long instructors have been certified,
since, for instructors who have not taught, thats how long they have
gone without teaching.
To get this value I need to a collection date for the data, which I don't know.
For now, I'll use June 1st since I know the data was from May.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;COLLECTION_DATE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;year&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2016&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;month&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;day&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;time_since_certified&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;COLLECTION_DATE&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;certified&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;days&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;time_since_taught_first&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;COLLECTION_DATE&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;taught_first&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;days&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I'll take a quick peek at the key column.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;time_to_taught_first&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;        time_to_taught_first&lt;/span&gt;
&lt;span class="err"&gt;Person&lt;/span&gt;
&lt;span class="err"&gt;48                     130.0&lt;/span&gt;
&lt;span class="err"&gt;75                    -122.0&lt;/span&gt;
&lt;span class="err"&gt;85                      73.0&lt;/span&gt;
&lt;span class="err"&gt;87                     168.0&lt;/span&gt;
&lt;span class="err"&gt;135                    212.0&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Some people (Person 75, for instance) taught their first workshop before they
were officially certified.
I don't have any idea how to include them in the analysis, so I will be
removing them from this point forward.
I believe that the removal of these individuals explain differences between
my results and &lt;a href="http://www.datacarpentry.org/blog/instructor-metrics/"&gt;the analysis&lt;/a&gt; posted to the Software Carpentry
blog by Erin Becker.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time_to_taught_first&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
            &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time_to_taught_first&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isnull&lt;/span&gt;&lt;span class="p"&gt;()]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Visualization is usually a good idea:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time_to_taught_first&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bins&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;taught_count&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Days between certification and first teaching&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img alt="Histogram of days between certification and first teaching." src="//blog.byronjsmith.com/static/images/swc-survival-taught-first-hist.png"&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt; of &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt; instructors have not yet taught.&amp;quot;&lt;/span&gt;
          &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;has_taught&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Of the 474 instructors in this data, 228 have not yet taught.&lt;/p&gt;
&lt;p&gt;Now we jump into the survival analysis.
I'm going to compare time-to-first-teaching to the year in which instructors
were certified.
This is mostly because I want a covariate here, and I don't have access to
more interesting ones, e.g. what style of training it was (online, 2-day, etc.).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# We&amp;#39;ll be modifying our data, so a copy will keep the original pristine.&lt;/span&gt;
&lt;span class="n"&gt;_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# If individuals have not yet taught as of data collection,&lt;/span&gt;
&lt;span class="c1"&gt;# then we will censor them.&lt;/span&gt;
&lt;span class="c1"&gt;# statsmodels requires this time-to-censoring be in the same column as the&lt;/span&gt;
&lt;span class="c1"&gt;# time-to-event.&lt;/span&gt;
&lt;span class="n"&gt;_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time_to_taught_first&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fillna&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time_since_certified&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inplace&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Fit a proportional hazards model, comparing certification year.&lt;/span&gt;
&lt;span class="c1"&gt;# &amp;quot;Sum&amp;quot; stands for sum-to-zero coding for the design matrix.&lt;/span&gt;
&lt;span class="n"&gt;ydm&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xdm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; \
    &lt;span class="n"&gt;patsy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dmatrices&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;time_to_taught_first ~ C(year_certified, Sum)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;return_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;dataframe&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Remove the intercept term.&lt;/span&gt;
&lt;span class="n"&gt;xdm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;xdm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;drop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Intercept&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;columns&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Right censor for individuals who have not yet taught by the date&lt;/span&gt;
&lt;span class="c1"&gt;# of this data collection.&lt;/span&gt;
&lt;span class="n"&gt;fit1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PHReg&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ydm&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xdm&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;has_taught&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The most widely used model in survival analysis is called the
&lt;a href="https://en.wikipedia.org/wiki/Proportional_hazards_model"&gt;proportional hazards model&lt;/a&gt;.
In the process of testing the significance of our covariates in this model,
a survival curve is calculated.
In this case, because of the coding for certification year in the design matrix,
this "baseline" curve represents the mean of annual means.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;sf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fit1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;baseline_cumulative_hazard&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;sf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Days post-certification&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Fraction instructors not taught&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img alt="Survival curve of days to teaching for the first time" src="//blog.byronjsmith.com/static/images/swc-survival-taught-first-curve.png"&gt;&lt;/p&gt;
&lt;p&gt;The key figure in survival analysis is the survival curve, or its derivative
the hazard function.
Survival curves plot the number or percentage of individuals who have not yet
experienced the event after a given amount of time.
In the case of this data, the survival curve reflects the fraction of
instructors who have not yet taught by a given number of days after
they were certified.&lt;/p&gt;
&lt;p&gt;Despite the fact that about 50% of certified instructors have not yet taught,
many of these are recently trained and we expect them to teach in the
future.
50% of certified instructors teach by 200 days.
After more than a year, however, the survival curve flattens out.
Approximately 30% of instructors get to 400 days without having taught
and at 600 days about the same fraction have still not taught.
If we want to extrapolate beyond the data (always a bad idea) then we
might predict that these instructors will never teach.&lt;/p&gt;
&lt;p&gt;We can also test the effect of certification year on time to first workshop.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fit1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;                                   Results: PHReg&lt;/span&gt;
&lt;span class="err"&gt;====================================================================================&lt;/span&gt;
&lt;span class="c"&gt;Model:                       PH Reg                        Sample size:          474&lt;/span&gt;
&lt;span class="err"&gt;Dependent variable:          time_to_taught_first          Num. events:          246&lt;/span&gt;
&lt;span class="c"&gt;Ties:                        Breslow&lt;/span&gt;
&lt;span class="err"&gt;------------------------------------------------------------------------------------&lt;/span&gt;
&lt;span class="err"&gt;                                log HR log HR SE   HR      t    P&amp;gt;|t|  [0.025 0.975]&lt;/span&gt;
&lt;span class="err"&gt;------------------------------------------------------------------------------------&lt;/span&gt;
&lt;span class="err"&gt;C(year_certified, Sum)[S.2012]  0.1382    0.5705 1.1482  0.2422 0.8086 0.3753 3.5124&lt;/span&gt;
&lt;span class="err"&gt;C(year_certified, Sum)[S.2013]  0.2230    0.2268 1.2498  0.9830 0.3256 0.8012 1.9493&lt;/span&gt;
&lt;span class="err"&gt;C(year_certified, Sum)[S.2014] -0.1383    0.1789 0.8708 -0.7732 0.4394 0.6132 1.2366&lt;/span&gt;
&lt;span class="err"&gt;C(year_certified, Sum)[S.2015]  0.0205    0.1730 1.0207  0.1183 0.9058 0.7272 1.4327&lt;/span&gt;
&lt;span class="err"&gt;====================================================================================&lt;/span&gt;
&lt;span class="err"&gt;Confidence intervals are for the hazard ratios&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We see no significant deviation from the average year for any of the 4 years of
certification data.&lt;/p&gt;
&lt;p&gt;Just for fun, let's go even further with this data.
Of the 246 instructors who have taught at least once, 131 have taught a
second time.
Can we predict the time after first teaching that it takes to teach again?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time_to_taught_first&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;notnull&lt;/span&gt;&lt;span class="p"&gt;()]&lt;/span&gt;

&lt;span class="c1"&gt;# Fill in dates for right censoring.&lt;/span&gt;
&lt;span class="n"&gt;_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time_between_first_second&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fillna&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time_since_taught_first&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inplace&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Fit a proportional hazards model using time between certification and first taught.&lt;/span&gt;
&lt;span class="n"&gt;ydm&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xdm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;patsy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dmatrices&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;time_between_first_second ~ time_to_taught_first&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                           &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;return_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;dataframe&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;xdm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;xdm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;drop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Intercept&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;columns&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Remove the intercept term&lt;/span&gt;

&lt;span class="c1"&gt;# Right censor for individuals who have not yet taught a second time.&lt;/span&gt;
&lt;span class="n"&gt;fit2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PHReg&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ydm&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xdm&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;has_taught_multiple&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# The baseline hazard is the probability of having not taught a second&lt;/span&gt;
&lt;span class="c1"&gt;# time by a given day for someone who taught at day 0 of being certified.&lt;/span&gt;
&lt;span class="n"&gt;sf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fit2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;baseline_cumulative_hazard&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;sf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Days post-first-teaching&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Fraction instructors not taught second time&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img alt="Survival curve of days to teaching a second time after having taught once" src="//blog.byronjsmith.com/static/images/swc-survival-taught-second-curve.png"&gt;&lt;/p&gt;
&lt;p&gt;The baseline survival curve reflects expectations for a theoretical individual
who taught immediately upon being certified (day 0).
For these folks, we expect 50% to teach again within 100 days, and almost 80%
within a year.&lt;/p&gt;
&lt;p&gt;Let's take a look at the effect of time-to-first-teaching on time to teaching
again.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fit2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;                              Results: PHReg&lt;/span&gt;
&lt;span class="err"&gt;==========================================================================&lt;/span&gt;
&lt;span class="c"&gt;Model:                  PH Reg                        Sample size:     246&lt;/span&gt;
&lt;span class="err"&gt;Dependent variable:     time_between_first_second     Num. events:     131&lt;/span&gt;
&lt;span class="c"&gt;Ties:                   Breslow&lt;/span&gt;
&lt;span class="err"&gt;--------------------------------------------------------------------------&lt;/span&gt;
&lt;span class="err"&gt;                      log HR log HR SE   HR      t    P&amp;gt;|t|  [0.025 0.975]&lt;/span&gt;
&lt;span class="err"&gt;--------------------------------------------------------------------------&lt;/span&gt;
&lt;span class="err"&gt;time_to_taught_first -0.0045    0.0010 0.9955 -4.3474 0.0000 0.9935 0.9975&lt;/span&gt;
&lt;span class="err"&gt;==========================================================================&lt;/span&gt;
&lt;span class="err"&gt;Confidence intervals are for the hazard ratios&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We find a highly significant effect of time-to-first-teaching.&lt;/p&gt;
&lt;p&gt;The hazard ratio estimate is 0.9955.
We can interpret this to mean that the per-day probability of teaching again
goes down by 0.45% for every day between certification and teaching the first
time.
This isn't all that surprising; individuals who are able to teach soon
after being certified are probably both enthusiastic and have more time
to devote to teaching.&lt;/p&gt;
&lt;p&gt;That's all I've got.
Thanks for reading.
I'd love to hear what you think and if you spot any glaring mistakes in my
analysis.
All of the code to do this is available &lt;a href="https://github.com/bsmith89/swc-instructor-training-analysis"&gt;on github&lt;/a&gt;.
If you have ideas for additional analysis please leave a comment here,
submit an issue to the github repository, or even better, a pull-request.&lt;/p&gt;</content><category term="Data"></category><category term="software-carpentry"></category><category term="python"></category><category term="statistics"></category></entry><entry><title>First time teaching Python to novices</title><link href="//blog.byronjsmith.com/swc-python-lesson.html" rel="alternate"></link><published>2015-08-12T01:00:00-04:00</published><updated>2015-08-14T10:00:00-04:00</updated><author><name>Byron J. Smith</name></author><id>tag:blog.byronjsmith.com,2015-08-12:/swc-python-lesson.html</id><summary type="html">&lt;p&gt;This July I co-instructed with &lt;a href="https://impactstory.org/JenniferShelton"&gt;Jennifer Shelton&lt;/a&gt;
a Software Carpentry &lt;a href="http://i5k-kinbre-script-share.github.io/2015-07-23-stanford/"&gt;workshop&lt;/a&gt; at Stanford University,
targeted to researchers with genomic or evolutionary datasets.
Jennifer taught the shell (Bash) and version control with Git,
while I taught the general programming language Python.
I've been aware of the &lt;a href="http://software-carpentry.org/"&gt;organization&lt;/a&gt;, which teaches software
development and computational methods to scientists, since attending a
workshop in 2012.
Since then I've served as a helper at one workshop
(troubleshooting individual learner's problems and helping catch them up with
the rest of the class),
and gone through the "accelerated", two day, instructor training at Michigan
State University.
After the Stanford workshop, I took part in new-instructor debriefing
on August 4th, during which I mentioned that I had to greatly pare down the
community-written lesson plan, &lt;a href="http://swcarpentry.github.io/python-novice-inflammation/"&gt;python-novice-inflammation&lt;/a&gt;,
to fit into the two half-day session we allotted it.&lt;/p&gt;
&lt;p&gt;Karin and Tiffany, who were running the debriefing, asked me to send …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This July I co-instructed with &lt;a href="https://impactstory.org/JenniferShelton"&gt;Jennifer Shelton&lt;/a&gt;
a Software Carpentry &lt;a href="http://i5k-kinbre-script-share.github.io/2015-07-23-stanford/"&gt;workshop&lt;/a&gt; at Stanford University,
targeted to researchers with genomic or evolutionary datasets.
Jennifer taught the shell (Bash) and version control with Git,
while I taught the general programming language Python.
I've been aware of the &lt;a href="http://software-carpentry.org/"&gt;organization&lt;/a&gt;, which teaches software
development and computational methods to scientists, since attending a
workshop in 2012.
Since then I've served as a helper at one workshop
(troubleshooting individual learner's problems and helping catch them up with
the rest of the class),
and gone through the "accelerated", two day, instructor training at Michigan
State University.
After the Stanford workshop, I took part in new-instructor debriefing
on August 4th, during which I mentioned that I had to greatly pare down the
community-written lesson plan, &lt;a href="http://swcarpentry.github.io/python-novice-inflammation/"&gt;python-novice-inflammation&lt;/a&gt;,
to fit into the two half-day session we allotted it.&lt;/p&gt;
&lt;p&gt;Karin and Tiffany, who were running the debriefing, asked me to send a note
to the mentorship email list about which parts I removed and which I kept in.
I thought I'd also take the opportunity to comment on the material at large:
what worked for me and what didn't.
What started as an email quickly ballooned into this blog post.&lt;/p&gt;
&lt;p&gt;To be explicit, I was teaching from the state of the repository at the time of
the workshop&lt;sup id="fnref:repo-state"&gt;&lt;a class="footnote-ref" href="#fn:repo-state"&gt;1&lt;/a&gt;&lt;/sup&gt; .&lt;/p&gt;
&lt;p&gt;With this as my first workshop&lt;sup id="fnref:unprepared"&gt;&lt;a class="footnote-ref" href="#fn:unprepared"&gt;2&lt;/a&gt;&lt;/sup&gt;, I (incorrectly) thought
I could teach all of the topics straight through.
By the time it became apparent that this wasn't going to work,
adapting the first day's material had to be done on the fly.
After that experience, and
before the following afternoon,
I prepared a subset of the remaining material that I thought I could cover.
I'm now relying on my (somewhat traumatic) memory of the first session,
and that outline I put together for the second day to write this summary.&lt;/p&gt;
&lt;p&gt;My plan going in was to split &lt;a href="http://swcarpentry.github.io/python-novice-inflammation/index.html#topics"&gt;the material&lt;/a&gt; after Topic 6,
getting learners up to writing functions on the first day,
so that we could discuss debugging and best-practices,
and transition from the Jupyter notebook to shell scripts, the next day.
Based on my co-instructors recommendation,
I did not have learners do all of the challenge questions for each topic,
but instead picked just one or two that I thought would be most useful.&lt;/p&gt;
&lt;p&gt;I found myself wishing (especially for Topic 1: "Analyzing Patient Data") that
some of the easier questions were integrated into the lesson itself, instead of
all at the bottom.
Learners should have had more chances to problem-solve early, instead of
listening to me for the entirety of each topic before getting their feet wet.&lt;/p&gt;
&lt;h2&gt;Motivating Python&lt;/h2&gt;
&lt;p&gt;For that &lt;a href="http://swcarpentry.github.io/python-novice-inflammation/01-numpy.html"&gt;first topic&lt;/a&gt; I &lt;em&gt;did&lt;/em&gt; cover everything, but wish I hadn't,
since it was mostly focused on array operations and the specifics of working
with NumPy (e.g. operations along axes).
I appreciated that we were showing the learners powerful library features to
motivate the later work, but I didn't feel like it was great for this
workshop's "genomics" audience.
Maybe these initial motivating sections should be targeted the same way the
capstone projects are.
It was also too long relative to the other sections, in my opinion.&lt;/p&gt;
&lt;p&gt;It &lt;em&gt;was&lt;/em&gt; very good, however, for introducing some python specifics, especially
things that learners coming from other languages like R or Mathematica might
not know (e.g. 0-indexing, slices, that variable assignment happens when each
line is executed, etc.).
It gave learners a chance to be surprised by their misconceptions and ask
questions.
We should do more of that.&lt;/p&gt;
&lt;p&gt;It would have been helpful for the lesson to have pre-built explanations for
0-indexing and right-exclusive slicing, since these were the hard parts and I'm
not happy with the explanations I initially used.&lt;/p&gt;
&lt;p&gt;I found the nature of the made-up data (maximum values smooth and minimum
values as a step-function along the first axis) distracting.
I also didn't know what they were supposed to represent (beyond inflammation
over time), so the "actually doing science" part of the motivation was a bit
lost.
Is there a reason we use these data?&lt;/p&gt;
&lt;h2&gt;Python basics: lists, loops, conditionals, etc.&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://swcarpentry.github.io/python-novice-inflammation/02-loop.html"&gt;Topics 2&lt;/a&gt; and &lt;a href="http://swcarpentry.github.io/python-novice-inflammation/03-lists.html"&gt;3&lt;/a&gt;, "Repeating Actions with Loops" and
"Storing Multiple Values in Lists" respectively, were good and short.
I didn't feel like I had to cut anything out.
However, for-loop syntax was not explicitly covered early in the lesson plan.
It wasn't until I realized I had gotten ahead of myself that we talked about
loop variables, iterables&lt;sup id="fnref:iterables"&gt;&lt;a class="footnote-ref" href="#fn:iterables"&gt;3&lt;/a&gt;&lt;/sup&gt;, and the indented code-block.&lt;/p&gt;
&lt;p&gt;I also thought the segue from Topic 1 to 2 was a bit weak.
This was a theme throughout, mixing the inflammation data with much simpler
stuff (e.g. looping over short strings and lists).
I realize we want to keep the motivation going, but, as a first-time
instructor, I found it to be distracting, and didn't know which I should be
emphasizing to the learners.&lt;/p&gt;
&lt;p&gt;I also picked the wrong challenge question from Topic 1 (reverse &lt;code&gt;'Newton'&lt;/code&gt;
using a loop), since we hadn't covered &lt;code&gt;range&lt;/code&gt;, &lt;code&gt;append&lt;/code&gt;ing to lists,
&lt;code&gt;''.join&lt;/code&gt;, etc.
What novice audience is that question appropriate for?
Maybe the solution is simple and I'm just confused...&lt;/p&gt;
&lt;p&gt;The material for &lt;a href="http://swcarpentry.github.io/python-novice-inflammation/04-files.html"&gt;topic 4&lt;/a&gt;, "Analyzing Data from Multiple Files"
worked well overall.
The only mistake I remember was copy-pasting the big chunk of code from the
lesson (looping over files and drawing sets of plots) instead of typing it out.
I figured since most of the code was library calls, learners wouldn't get
anything out of me taking the time to type all of it.
That may have been true, but it meant the learners weren't executing the code
at the
same time as me, which interrupted the flow of the lesson.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://swcarpentry.github.io/python-novice-inflammation/05-cond.html"&gt;Topic 5&lt;/a&gt;, "Making Choice" (if-statements), was where things got
hairy.
I panicked a bit and went mostly off the lesson plan.
It did not go well.
When I tried to find something in the lesson to get me back on track,
I wished there was more explicit discussion of syntax and booleans.
I was able to review the topic the next day, which I think got any lost
learners
mostly caught up.&lt;/p&gt;
&lt;p&gt;As you can imagine, at this point we were nearing the end of the first day.
I did manage to show the learners the syntax for defining and using functions,
but I covered &lt;a href="http://swcarpentry.github.io/python-novice-inflammation/06-func.html"&gt;topic 6&lt;/a&gt;, "Creating Functions", in its entirety at the
start of the next
session.&lt;/p&gt;
&lt;h2&gt;Learning my lesson&lt;/h2&gt;
&lt;p&gt;After the harrowing experience with conditionals on the first day, I took the
time to write out a personalized lesson outline for the next day with learning
objectives, steps in explaining difficult concepts, and pre-picked
understanding/challenge questions.
The exercise of writing an outline of learning objectives before the class was
very helpful, and something I intend to repeat before future workshops.&lt;/p&gt;
&lt;p&gt;If I remember correctly&lt;sup id="fnref:metamemory"&gt;&lt;a class="footnote-ref" href="#fn:metamemory"&gt;4&lt;/a&gt;&lt;/sup&gt;, the second day I started once again with
functions, and largely based the lesson on the material in
&lt;a href="http://swcarpentry.github.io/python-novice-inflammation/06-func.html"&gt;the topic&lt;/a&gt;.
The temperature conversion formulas were an effective motivator for this
lesson.
I wonder if simple examples, like this one, can replace the more complex
(and, admittedly, more impressive)
inflammation tutorial to demonstrate the value of Python for scientists.
I also integrated material from the &lt;a href="http://swcarpentry.github.io/python-novice-inflammation/07-errors.html"&gt;topic on errors and exceptions&lt;/a&gt;:
tracebacks, syntax errors, etc.
In this combined topic I did not use the &lt;code&gt;import errors_01&lt;/code&gt; example.
It was unclear to me why the lesson plan, as written, uses a black-box script
like &lt;code&gt;errors_01.py&lt;/code&gt;, and not something more explicit, like an index or
attribute error, to dissect the traceback.
I think the explicit approach worked well for the learners in this workshop.
Since we were covering functions anyway, it wasn't hard to get a multi-level
traceback.
Syntax errors also combined nicely with learning function definition syntax.&lt;/p&gt;
&lt;p&gt;&lt;img alt="The author dissecting an attribute error.5" src="//blog.byronjsmith.com/static/images/swc-stanford-byron.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Somewhere in the process of talking about functions we got sidetracked with
&lt;code&gt;open()&lt;/code&gt;.
I was surprised to see that the lesson plans have only limited discussion of
file objects, only really dealing with them in the section on &lt;code&gt;IOErrors&lt;/code&gt;.
I think learners appreciated a chance to see how the array data they had used
the day before were saved as a CSV,
and how they could access the data directly.
It also gave us a chance to show that other objects besides lists and strings
can serve as iterators in for-loops.&lt;/p&gt;
&lt;p&gt;I liked how the topic 6 &lt;a href="http://swcarpentry.github.io/python-novice-inflammation/06-func.html#defining-defaults"&gt;lesson plan&lt;/a&gt; used the library
function &lt;code&gt;numpy.loadtxt()&lt;/code&gt; to talk about default arguments and the &lt;code&gt;help()&lt;/code&gt;
built-in.
I jumped back and forth between examining that function and implementing
the same things (keywords, documentation) in a &lt;code&gt;center()&lt;/code&gt; function we were
building.
The realized lesson was very similar to the repository's lesson plan,
but a little more integrated with errors and exceptions.&lt;/p&gt;
&lt;p&gt;I had the learners implement &lt;code&gt;rescale()&lt;/code&gt; as a challenge question.
We then worked together as a class to add lower and upper bounds.
This was a much more difficult task than I expected
(even just deriving the correct formula),
and served nicely to demonstrate defensive programming and debugging.
While we touched on many of the concepts in &lt;a href="http://swcarpentry.github.io/python-novice-inflammation/08-defensive.html"&gt;topics 8&lt;/a&gt; and
&lt;a href="http://swcarpentry.github.io/python-novice-inflammation/09-debugging.html"&gt;9&lt;/a&gt;,
these ideas, were spread throughout,
and I did not walk through either as an atomic lesson.&lt;/p&gt;
&lt;p&gt;My ultimate goal on the second day was to write a program to calculate
the mean inflammation of each subject in the example files and then
transform the program into a command-line script that would operate as a
UNIX-style filter.
I remember Greg Wilson teaching Python scripting (along with Bash and SQL)
that way during my first workshop (as a &lt;em&gt;learner&lt;/em&gt;!) at MSU
in May 2012&lt;sup id="fnref:swc-msu"&gt;&lt;a class="footnote-ref" href="#fn:swc-msu"&gt;6&lt;/a&gt;&lt;/sup&gt;.
This &lt;a href="http://swcarpentry.github.io/python-novice-inflammation/10-cmdline.html"&gt;last topic&lt;/a&gt; seemed like a worthwhile mini-capstone,
since it would reintroduce ideas from the Bash lesson the day before,
and we could version-control our work with git.
While we managed to run our code as a script (rather than a cell in the
Jupyter notebook), the transition was a little rough around the edges, and we
didn't have time to add &lt;code&gt;sys.argv&lt;/code&gt; or &lt;code&gt;sys.stdin&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;Take-aways&lt;/h2&gt;
&lt;p&gt;The second day of Python was much smoother than the first, and, while we
did not get to all of the material, I was satisfied with what we did cover.
It's quite remarkable that learners can go all the way from indexing into lists
to defensive programming and unit tests in just a few hours.
I'm not convinced that we got them far enough to jump right into using Python
for their own work, but I hope it was a good kick-start towards that goal.
I'm amazed some novice workshops only allocate a half-day session to the
programming language (be it Python, R, or Matlab),
although a quick survey of &lt;a href="http://software-carpentry.org/workshops/index.html#future"&gt;upcoming workshops&lt;/a&gt; suggests that almost
&lt;em&gt;all&lt;/em&gt; of them do in fact use two sessions.
Is this the recommended approach (and if so where is it documented)
or have many instructors all independently come to the same conclusion?&lt;/p&gt;
&lt;p&gt;Even so, there's still more material in python-novice-inflammation
than can be covered in two sessions.
I'm under the impression that the repository is sort of &lt;em&gt;meant&lt;/em&gt; to be like
that: way too big, so that instructors can pick and choose the parts that are
most salient for their audience.
This seems like a good idea, but
it was not sufficiently communicated to me as a first-time instructor,
and, while many of the difficulties I had could have been solved with more
comprehensive preparation,
having a "default" subset would have been helpful.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:repo-state"&gt;
&lt;p&gt;&lt;a href="https://github.com/swcarpentry/python-novice-inflammation/tree/76e3ea24406e4b8d684c9b45f3c5fd33e23ac71a"&gt;&lt;code&gt;76e3ea24406e4b8d684c9b45f3c5fd33e23ac71a&lt;/code&gt;&lt;/a&gt;: still the
HEAD as of this writing.&amp;#160;&lt;a class="footnote-backref" href="#fnref:repo-state" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:unprepared"&gt;
&lt;p&gt;and being insufficiently prepared&amp;#160;&lt;a class="footnote-backref" href="#fnref:unprepared" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:iterables"&gt;
&lt;p&gt;Actually, we talked about getting values from lists and how
strings are like lists, rather than about iterables in general.&amp;#160;&lt;a class="footnote-backref" href="#fnref:iterables" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:metamemory"&gt;
&lt;p&gt;Despite the fact that I have those notes, I actually don't
remember the details of that day's lesson as well.
I wonder if there's some weird metamemory thing going on
e.g. &lt;a href="http://www.sciencemag.org/content/333/6043/776.abstract"&gt;this&lt;/a&gt; (unfortunately paywalled).&amp;#160;&lt;a class="footnote-backref" href="#fnref:metamemory" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:photo-credit"&gt;
&lt;p&gt;Photo credit: Amy Hodge (&lt;a href="https://creativecommons.org/licenses/by/2.0/"&gt;CC-BY&lt;/a&gt;)&amp;#160;&lt;a class="footnote-backref" href="#fnref:photo-credit" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:swc-msu"&gt;
&lt;p&gt;The site for this historic event can still be found
&lt;a href="https://web.archive.org/web/20120514195748/http://software-carpentry.org/boot-camps/michigan-state-university-may-2012/"&gt;here&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref:swc-msu" title="Jump back to footnote 6 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="Education"></category><category term="software-carpentry"></category><category term="teaching"></category><category term="programming"></category><category term="mistakes"></category><category term="python"></category></entry><entry><title>Compiling SciPy on RHEL6</title><link href="//blog.byronjsmith.com/scipy-on-rhel.html" rel="alternate"></link><published>2013-05-20T12:00:00-04:00</published><updated>2013-05-20T12:00:00-04:00</updated><author><name>Byron J. Smith</name></author><id>tag:blog.byronjsmith.com,2013-05-20:/scipy-on-rhel.html</id><summary type="html">&lt;p&gt;Within the past two years I've discovered something interesting about myself
(...actually really, &lt;em&gt;really&lt;/em&gt; boring about myself):
I can be happily entertained for hours on end setting up my
computational environment &lt;em&gt;just&lt;/em&gt; right.  I find that it gives me a similar
type of satisfaction to cataloguing my music collection.  I guess you could
call it a hobby.&lt;/p&gt;
&lt;p&gt;Usually this entails installing the usual suspects (&lt;code&gt;NumPy&lt;/code&gt;, &lt;code&gt;Pandas&lt;/code&gt;,
&lt;code&gt;IPython&lt;/code&gt;, &lt;code&gt;matplotlib&lt;/code&gt;, etc.) in a python
&lt;a href="http://www.virtualenv.org/en/latest/"&gt;virtual environment&lt;/a&gt;.
When I'm particularly into it (which is always), I'll also compile the python
distribution itself.  I've had several opportunities to indulge this pasttime,
most recently in setting up my research pipeline on the
&lt;a href="http://cac.engin.umich.edu/resources/systems/flux"&gt;Flux&lt;/a&gt;
high-performance compute cluster at The University of Michigan.&lt;/p&gt;
&lt;p&gt;Installing &lt;code&gt;NumPy&lt;/code&gt; is usually no trouble at all, but for some reason
(if you know, please tell me), &lt;code&gt;SciPy&lt;/code&gt; has &lt;em&gt;always&lt;/em&gt; given me a
"BlasNotFoundError" when installing on the Red Hat Enterprise Linux distros …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Within the past two years I've discovered something interesting about myself
(...actually really, &lt;em&gt;really&lt;/em&gt; boring about myself):
I can be happily entertained for hours on end setting up my
computational environment &lt;em&gt;just&lt;/em&gt; right.  I find that it gives me a similar
type of satisfaction to cataloguing my music collection.  I guess you could
call it a hobby.&lt;/p&gt;
&lt;p&gt;Usually this entails installing the usual suspects (&lt;code&gt;NumPy&lt;/code&gt;, &lt;code&gt;Pandas&lt;/code&gt;,
&lt;code&gt;IPython&lt;/code&gt;, &lt;code&gt;matplotlib&lt;/code&gt;, etc.) in a python
&lt;a href="http://www.virtualenv.org/en/latest/"&gt;virtual environment&lt;/a&gt;.
When I'm particularly into it (which is always), I'll also compile the python
distribution itself.  I've had several opportunities to indulge this pasttime,
most recently in setting up my research pipeline on the
&lt;a href="http://cac.engin.umich.edu/resources/systems/flux"&gt;Flux&lt;/a&gt;
high-performance compute cluster at The University of Michigan.&lt;/p&gt;
&lt;p&gt;Installing &lt;code&gt;NumPy&lt;/code&gt; is usually no trouble at all, but for some reason
(if you know, please tell me), &lt;code&gt;SciPy&lt;/code&gt; has &lt;em&gt;always&lt;/em&gt; given me a
"BlasNotFoundError" when installing on the Red Hat Enterprise Linux distros
commonly used on academic clusters.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="gp"&gt;&amp;gt;&lt;/span&gt; pip install scipy
&lt;span class="go"&gt;Downloading/unpacking scipy&lt;/span&gt;
&lt;span class="go"&gt;  Downloading scipy-0.12.0.zip (10.2MB): 100% 10.2MB downloaded&lt;/span&gt;
&lt;span class="go"&gt;...&lt;/span&gt;
&lt;span class="go"&gt;numpy.distutils.system_info.BlasNotFoundError:&lt;/span&gt;
&lt;span class="go"&gt;    Blas (http://www.netlib.org/blas/) libraries not found.&lt;/span&gt;
&lt;span class="go"&gt;    Directories to search for the libraries can be specified in the&lt;/span&gt;
&lt;span class="go"&gt;    numpy/distutils/site.cfg file (section [blas]) or by setting&lt;/span&gt;
&lt;span class="go"&gt;    the BLAS environment variable.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I &lt;em&gt;know&lt;/em&gt; BLAS and LAPACK are installed as shared libraries: at Michigan State
University I had to load the respective modules, but at UMich they're right
there in &lt;code&gt;/usr/lib64/atlas&lt;/code&gt;.  So why &lt;code&gt;pip install SciPy&lt;/code&gt; always gives me that
error, I have no clue.  I've set the BLAS and LAPACK environmental
variables to the relevant shared libraries.  I've run
&lt;code&gt;python setup.py build --fcompiler=gnu95&lt;/code&gt; directly.  But I always got that
same error.&lt;/p&gt;
&lt;p&gt;Anyway, I &lt;em&gt;finally&lt;/em&gt; got it to work, so I thought I'd share the steps I took
just in case it helps someone else.  My solution was found on Stack Overflow
(surprise, surprise): The accepted answer to
&lt;a href="http://stackoverflow.com/q/7496547/848121"&gt;this&lt;/a&gt; question.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;mkdir -p ~/.local/src/
&lt;span class="nb"&gt;cd&lt;/span&gt; ~/.local/src/
wget -O BLAS.tgz http://www.netlib.org/blas/blas.tgz
tar -xzf BLAS.tgz
&lt;span class="nb"&gt;cd&lt;/span&gt; BLAS
gfortran -O3 -std&lt;span class="o"&gt;=&lt;/span&gt;legacy -m64 -fno-second-underscore -fPIC -c *.f
ar r libfblas.a *.o
ranlib libfblas.a
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;BLAS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$PWD&lt;/span&gt;/libfblas.a

&lt;span class="nb"&gt;cd&lt;/span&gt; ~/.local/src/
wget -O LAPACK.tgz http://www.netlib.org/lapack/lapack.tgz
tar -xzf LAPACK.tgz
&lt;span class="c1"&gt;# The resulting directory may be named lapack-&amp;lt;version&amp;gt;/&lt;/span&gt;
&lt;span class="c1"&gt;# the following assumes that it&amp;#39;s named LAPACK/&lt;/span&gt;
&lt;span class="nb"&gt;cd&lt;/span&gt; LAPACK
cp INSTALL/make.inc.gfortran make.inc
vim make.inc
&lt;span class="c1"&gt;# Change OPTS = -O2 to OPTS = -O2 -fPIC&lt;/span&gt;
&lt;span class="c1"&gt;# Change NOOPT = -O0 to NOOPT = -O0 -fPIC&lt;/span&gt;
make lapacklib
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;LAPACK&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$PWD&lt;/span&gt;/libflapack.a

&lt;span class="nb"&gt;cd&lt;/span&gt; ~/.local/src/
git clone https://github.com/scipy/scipy.git
&lt;span class="nb"&gt;cd&lt;/span&gt; scipy
python setup.py build --fcompiler gnu95
python setup.py install
&lt;span class="c1"&gt;# Assuming you&amp;#39;re already in the virtualenv you want to install to.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I don't know which other systems this will work on, but it does successfully
install SciPy for me.  On Python 3.3.2, running the unit tests give me
several errors and failures (nothing too scary looking), but everything passes
on Python 2.7.5!&lt;/p&gt;
&lt;p&gt;Enjoy.&lt;/p&gt;</content><category term="Computing"></category><category term="python"></category><category term="hpc"></category><category term="software"></category><category term="scipy"></category><category term="linux"></category></entry><entry><title>PyMake I: Another GNU Make clone</title><link href="//blog.byronjsmith.com/pymake-0.html" rel="alternate"></link><published>2013-05-07T19:00:00-04:00</published><updated>2016-03-04T10:00:00-05:00</updated><author><name>Byron J. Smith</name></author><id>tag:blog.byronjsmith.com,2013-05-07:/pymake-0.html</id><summary type="html">&lt;p&gt;(Edit 1): &lt;s&gt;&lt;em&gt;This is the first of two posts about my program
&lt;a href="http://github.com/bsmith89/pymake/"&gt;PyMake&lt;/a&gt;.  I'll post the link to Part II
here when I've written it.&lt;/em&gt;&lt;/s&gt;
&lt;em&gt;While I still agree with some of the many of the views expressed in
this piece, I have changed my thinking on Makefiles.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;(Edit 2): &lt;s&gt;&lt;em&gt;I'll post a new post about the topic when I take the time to write it.&lt;/em&gt;&lt;/s&gt;
&lt;em&gt;I've written a &lt;a href="//blog.byronjsmith.com/make-analysis.html"&gt;tutorial&lt;/a&gt; on using _Make&lt;/em&gt; for reproducible data
analysis_.&lt;/p&gt;
&lt;p&gt;I am an aspiring but unskilled (not yet skilled?) computer geek.
You can observe this for yourself by watching me fumble my way through
&lt;a href="https://github.com/bsmith89/dotfiles"&gt;&lt;code&gt;vim&lt;/code&gt; configuration&lt;/a&gt;,
multi-threading/processing in Python, and &lt;code&gt;git&lt;/code&gt; merges.&lt;/p&gt;
&lt;p&gt;Rarely do I actually feel like my products are worth sharing with
the wider world.  The only reason I have a GitHub account is personal
convenience and absolute confidence that no one else will ever look at it
besides me …&lt;/p&gt;</summary><content type="html">&lt;p&gt;(Edit 1): &lt;s&gt;&lt;em&gt;This is the first of two posts about my program
&lt;a href="http://github.com/bsmith89/pymake/"&gt;PyMake&lt;/a&gt;.  I'll post the link to Part II
here when I've written it.&lt;/em&gt;&lt;/s&gt;
&lt;em&gt;While I still agree with some of the many of the views expressed in
this piece, I have changed my thinking on Makefiles.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;(Edit 2): &lt;s&gt;&lt;em&gt;I'll post a new post about the topic when I take the time to write it.&lt;/em&gt;&lt;/s&gt;
&lt;em&gt;I've written a &lt;a href="//blog.byronjsmith.com/make-analysis.html"&gt;tutorial&lt;/a&gt; on using _Make&lt;/em&gt; for reproducible data
analysis_.&lt;/p&gt;
&lt;p&gt;I am an aspiring but unskilled (not yet skilled?) computer geek.
You can observe this for yourself by watching me fumble my way through
&lt;a href="https://github.com/bsmith89/dotfiles"&gt;&lt;code&gt;vim&lt;/code&gt; configuration&lt;/a&gt;,
multi-threading/processing in Python, and &lt;code&gt;git&lt;/code&gt; merges.&lt;/p&gt;
&lt;p&gt;Rarely do I actually feel like my products are worth sharing with
the wider world.  The only reason I have a GitHub account is personal
convenience and absolute confidence that no one else will ever look at it
besides me.  (Yes, I realize that I am invalidating the previous sentence
with that glaring "Fork me on GitHub" ribbon in the top-right corner of
this page.  I'm putting myself out there!  OKAY?!)&lt;/p&gt;
&lt;p&gt;As an aspiring scientist, too, I've had plenty of opportunities to practice
the relevant skill sets.  A laboratory rotation with
&lt;a href="http://ivory.idyll.org/blog/"&gt;Titus Brown&lt;/a&gt;, and the resulting exposure to his
reproducible research and &lt;a href="http://software-carpentry.org"&gt;Software Carpentry&lt;/a&gt;
evangelizing, has certainly influenced the tools and techniques in my belt.&lt;/p&gt;
&lt;p&gt;I try to use the &lt;code&gt;NumPy&lt;/code&gt;/&lt;code&gt;SciPy&lt;/code&gt;/&lt;code&gt;Pandas&lt;/code&gt;/&lt;code&gt;matplotlib&lt;/code&gt; stack for my
computational and visualization tasks.  I am a relatively competent &lt;code&gt;BASH&lt;/code&gt;-ist
and I work hard to write my scripts so that they'll
make sense to me 5 years from now.  I have even been known to do some of my
data analysis in IPython notebooks.&lt;/p&gt;
&lt;h1&gt;A Pipeline is only sometimes a Makefile&lt;/h1&gt;
&lt;p&gt;Despite (or maybe because of) my obsession with writing simple,
reproducible pipelines, one tool I have never come to terms with is
GNU &lt;code&gt;make&lt;/code&gt;.  While it's not quite mainstream for bioinformaticians and
other computational folk, &lt;code&gt;make&lt;/code&gt;
&lt;a href="http://archive.nodalpoint.org/2007/03/18/a_pipeline_is_a_makefile"&gt;promises&lt;/a&gt;
to tie all those *&lt;code&gt;NIX&lt;/code&gt; style
scripts together seamlessly and with built-in
parallelization, selective re-running, and more, all under a declarative
language syntax.  I say 'promises' because, for me, it never did any of those
things.&lt;/p&gt;
&lt;p&gt;Now, I don't want to suggest that this ubiquitous piece of GNU software
doesn't work well.  I recognize that it does much of what the average
user needs, but for my particular pipeline it just wasn't the right tool.&lt;/p&gt;
&lt;p&gt;My problem was a seemingly simple one.  I had a set of gene models (HMMs)
and a set of FASTQ formatted sequences from an Illumina
sequencer.  The goal was to search every sample for every gene using HMMER3
and to output the results (plus a respectable amount of pre- and
post-processing).  The problem is, &lt;code&gt;make&lt;/code&gt; is designed for
software compilation. Processing &lt;code&gt;foo.c&lt;/code&gt; and &lt;code&gt;bar.h&lt;/code&gt; into &lt;code&gt;foo.o&lt;/code&gt; is easy.
I, however, was asking &lt;code&gt;make&lt;/code&gt; to generate the product of $n$ samples and $m$
models (&lt;strong&gt;complete aside&lt;/strong&gt;: if you're curious about how I got the
$\LaTeX$ formatting, see
&lt;a href="http://www.ceremade.dauphine.fr/~amic/blog/mathjax-and-pelican-en.html"&gt;this&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;While, after a dozen hours of smashing my head against the table, I was able
to get my &lt;code&gt;Makefile&lt;/code&gt; to work, it required some &lt;em&gt;really&lt;/em&gt; ugly tricks like
secondary expansion and gratuitous calls to &lt;code&gt;sed&lt;/code&gt; in my macros (for others
with similar problems see &lt;a href="http://stackoverflow.com/q/3745177/848121"&gt;here&lt;/a&gt;,
and &lt;a href="http://stackoverflow.com/q/2880975/848121"&gt;here&lt;/a&gt;).  Plus, debugging
&lt;code&gt;make&lt;/code&gt; is torture, surely against the Geneva Conventions.&lt;/p&gt;
&lt;p&gt;I &lt;em&gt;wanted&lt;/em&gt; to use &lt;code&gt;make&lt;/code&gt;, I swear I did.  It's open source, well used,
extensively tested, available on all relevant systems, etc.
And I probably could have... but only by keeping the ugly hack or hard-coding
the recipe for each model, and that just didn't jive with my
recently acquired simple/reproducible mentality.  Converts always are
the most zealous, afterall.&lt;/p&gt;
&lt;h1&gt;They say graduate school is a time to explore&lt;/h1&gt;
&lt;p&gt;So what did I do?  No, I didn't immediately start writing a make replacement
with all of the features I wanted like some over-eager graduate student.
Jeeze!  What do you people think of me!? First I checked out the
&lt;a href="http://freecode.com/articles/make-alternatives"&gt;extant alternatives&lt;/a&gt;...
I hated everything.  So &lt;em&gt;then&lt;/em&gt; I started writing a make replacement with all
of the features I wanted.&lt;/p&gt;
&lt;p&gt;The result was one of the first pieces of general purpose software to come
off my laptop which I wouldn't be entirely ashamed to show to an experienced
programmer.  It's rough, don't get me wrong, but it does everything I need
and is actually kinda pretty internally.  Well, at least it was before I
fixed some glaring problems.  Whatever.  The point is I want to share
&lt;a href="https://github.com/bsmith89/pymake"&gt;it&lt;/a&gt; with
the world; what better stage exists for its introduction than this blog, which
absolutely no one reads?&lt;/p&gt;
&lt;p&gt;...Yeah, I'll probably post it to &lt;a href="http://reddit.com/r/python"&gt;/r/python&lt;/a&gt; too.&lt;/p&gt;
&lt;p&gt;Tune in for Part II, in which I explain why &lt;em&gt;you&lt;/em&gt; should use my software.&lt;/p&gt;</content><category term="Computing"></category><category term="python"></category><category term="software"></category><category term="development"></category><category term="make"></category><category term="pipelines"></category><category term="bioinformatics"></category></entry></feed>