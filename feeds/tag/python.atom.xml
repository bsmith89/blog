<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Deep Ecology - python</title><link href="http://bsmith89.github.io/blog/" rel="alternate"></link><link href="http://bsmith89.github.io/blog/feeds/tag/python.atom.xml" rel="self"></link><id>http://bsmith89.github.io/blog/</id><updated>2016-06-14T12:00:00-04:00</updated><entry><title>Take five minutes to simplify your life with Make</title><link href="http://bsmith89.github.io/blog/makefile-shortcuts.html" rel="alternate"></link><published>2016-06-14T12:00:00-04:00</published><author><name>Byron J. Smith</name></author><id>tag:bsmith89.github.io,2016-06-14:blog/makefile-shortcuts.html</id><summary type="html">&lt;p&gt;I use &lt;em&gt;GNU Make&lt;/em&gt; to automate my data processing pipelines. I've written a &lt;a href="make-analysis.html"&gt;tutorial&lt;/a&gt; &lt;a href="#fn1" class="footnoteRef" id="fnref1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; for novices on the basics of using &lt;em&gt;Make&lt;/em&gt; for reproducible analysis and I think that everyone who writes more than one script, or runs more than one shell command to process their data can benefit from automating that process. &lt;a href="http://kbroman.org/minimal_make/"&gt;I'm&lt;/a&gt; &lt;a href="https://bost.ocks.org/mike/make/"&gt;not&lt;/a&gt; &lt;a href="http://zmjones.com/make/"&gt;alone&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;However, the investment required to learn &lt;em&gt;Make&lt;/em&gt; and to convert an entire project can seem daunting to many time-strapped researchers. Even if you aren't living the dream—rebuilding a paper from raw data with a single invocation of &lt;code&gt;make paper&lt;/code&gt;—I still think you can benefit from adding a simple &lt;code&gt;Makefile&lt;/code&gt; to your project root.&lt;/p&gt;
&lt;p&gt;When done right, scripting the tedious parts of your job &lt;em&gt;can&lt;/em&gt; save you time in the long run&lt;a href="#fn2" class="footnoteRef" id="fnref2"&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;. But the time savings aren't the only reason to do it. For me, a bigger advantage is that I get to save my mental energy for more interesting problems&lt;a href="#fn3" class="footnoteRef" id="fnref3"&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;. &lt;em&gt;Make&lt;/em&gt; goes a step further and lets me forget about everything but my real objective. With a &lt;code&gt;make [target]&lt;/code&gt; invocation I don't even need to remember the name of the script.&lt;/p&gt;
&lt;h2 id="the-default-makefile"&gt;The default makefile&lt;/h2&gt;
&lt;p&gt;TL;DR: All of the code in this post is available as a &lt;a href="https://gist.github.com/bsmith89/c6811893c1cbd2a72cc1d144a197bef2"&gt;gist&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here's what a minimal makefile might look like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="cp"&gt;define PROJECT_HELP_MSG&lt;/span&gt;

&lt;span class="nf"&gt;Usage&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    make &lt;span class="nb"&gt;help                   &lt;/span&gt;show this message
    make clean                  remove intermediate files &lt;span class="o"&gt;(&lt;/span&gt;see CLEANUP&lt;span class="o"&gt;)&lt;/span&gt;

    make &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;VENV&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;                make a virtualenv in the base directory &lt;span class="o"&gt;(&lt;/span&gt;see VENV&lt;span class="o"&gt;)&lt;/span&gt;
    make python-reqs            install python packages in requirements.pip
    make git-config             &lt;span class="nb"&gt;set local &lt;/span&gt;git configuration
    make setup                  git init&lt;span class="p"&gt;;&lt;/span&gt; make python-reqs git-config

    make start-jupyter          launch a jupyter server from the &lt;span class="nb"&gt;local &lt;/span&gt;virtualenv
    make start-ipython          launch ipython from the &lt;span class="nb"&gt;local &lt;/span&gt;virtualenv

&lt;span class="cp"&gt;endef&lt;/span&gt;
&lt;span class="k"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;PROJECT_HELP_MSG&lt;/span&gt;

&lt;span class="nf"&gt;help&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
	&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$$&lt;/span&gt;PROJECT_HELP_MSG &lt;span class="p"&gt;|&lt;/span&gt; less

&lt;span class="nf"&gt;.git&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
	git init

&lt;span class="nf"&gt;git-config&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; .&lt;span class="n"&gt;git&lt;/span&gt; 
	git config --local filter.dropoutput_jupyter.clean &lt;span class="se"&gt;\&lt;/span&gt;
        drop_jupyter_output.sh
	git config --local filter.dropoutput_jupyter.smudge cat
	git config --local core.page &lt;span class="s1"&gt;&amp;#39;less -x4&amp;#39;&lt;/span&gt;
	git config --local diff.daff-csv.command &lt;span class="s2"&gt;&amp;quot;daff.py diff --git&amp;quot;&lt;/span&gt;
	git config --local merge.daff-csv.name &lt;span class="s2"&gt;&amp;quot;daff.py tabular merge&amp;quot;&lt;/span&gt;
	git config --local merge.daff-csv.driver &lt;span class="s2"&gt;&amp;quot;daff.py merge --output %A %O %A %B&amp;quot;&lt;/span&gt;

&lt;span class="nv"&gt;VENV&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; .venv
&lt;span class="k"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;VIRTUAL_ENV&lt;/span&gt; &lt;span class="o"&gt;:=&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;abspath &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;VENV&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;PATH&lt;/span&gt; &lt;span class="o"&gt;:=&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;VIRTUAL_ENV&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;/bin:&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;PATH&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;

&lt;span class="nf"&gt;${VENV}&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
	python3 -m venv &lt;span class="nv"&gt;$@&lt;/span&gt;

&lt;span class="nf"&gt;python-reqs&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;requirements&lt;/span&gt;.&lt;span class="n"&gt;pip&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; ${&lt;span class="n"&gt;VENV&lt;/span&gt;}
	pip install --upgrade -r requirements.pip

&lt;span class="nf"&gt;setup&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; ${&lt;span class="n"&gt;VENV&lt;/span&gt;} &lt;span class="n"&gt;python&lt;/span&gt;-&lt;span class="n"&gt;reqs&lt;/span&gt; &lt;span class="n"&gt;git&lt;/span&gt;-&lt;span class="n"&gt;config&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; .&lt;span class="n"&gt;git&lt;/span&gt;

&lt;span class="nf"&gt;start-jupyter&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
	jupyter notebook --config&lt;span class="o"&gt;=&lt;/span&gt;jupyter_notebook_config.py

&lt;span class="nv"&gt;CLEANUP&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; *.pyc

&lt;span class="nf"&gt;clean&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
	rm -rf &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;CLEANUP&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;

&lt;span class="nf"&gt;.PHONY&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;help&lt;/span&gt; &lt;span class="n"&gt;git&lt;/span&gt;-&lt;span class="n"&gt;config&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;-&lt;span class="n"&gt;jupter&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt;-&lt;span class="n"&gt;reqs&lt;/span&gt; &lt;span class="n"&gt;setup&lt;/span&gt; &lt;span class="n"&gt;clean&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;If you want to start using it right away, download the &lt;a href="https://gist.github.com/bsmith89/c6811893c1cbd2a72cc1d144a197bef2"&gt;gist&lt;/a&gt;, which includes a couple of other necessary files. As long as you aren't saving it over another makefile, it won't mess anything up.&lt;/p&gt;
&lt;p&gt;But let's break it down so you can see how it's made and why it's awesome.&lt;/p&gt;
&lt;p&gt;From the top!&lt;/p&gt;
&lt;h2 id="a-help-message-for-your-project"&gt;A help message for your project&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="cp"&gt;define PROJECT_HELP_MSG&lt;/span&gt;

&lt;span class="nf"&gt;Usage&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    make &lt;span class="nb"&gt;help                   &lt;/span&gt;show this message
    make clean                  remove intermediate files &lt;span class="o"&gt;(&lt;/span&gt;see CLEANUP&lt;span class="o"&gt;)&lt;/span&gt;

    make git-config             &lt;span class="nb"&gt;set local &lt;/span&gt;git configuration
    make &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;VENV&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;                make a virtualenv in the base directory &lt;span class="o"&gt;(&lt;/span&gt;see VENV&lt;span class="o"&gt;)&lt;/span&gt;
    make python-reqs            install python packages in requirements.pip
    make setup                  git init&lt;span class="p"&gt;;&lt;/span&gt; make python-reqs git-config

    make start-jupyter          launch a jupyter server from the &lt;span class="nb"&gt;local &lt;/span&gt;virtualenv
    make start-ipython          launch ipython from the &lt;span class="nb"&gt;local &lt;/span&gt;virtualenv

&lt;span class="cp"&gt;endef&lt;/span&gt;
&lt;span class="k"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;PROJECT_HELP_MSG&lt;/span&gt;

&lt;span class="nf"&gt;help&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
	&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$$&lt;/span&gt;PROJECT_HELP_MSG
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The top of our makefile is a help message. Running the traditional invocation &lt;code&gt;make help&lt;/code&gt; will call that recipe and we'll see an abridged list of the available recipes printed to our terminal. Since &lt;code&gt;help&lt;/code&gt; is the very first recipe in the makefile, it will also be the default recipe; typing &lt;code&gt;make&lt;/code&gt; alone prints the help message.&lt;/p&gt;
&lt;p&gt;As you start adding additional recipes, fill out this usage message. That way you'll have both documentation about the analysis targets, and also a handy cheatsheet.&lt;/p&gt;
&lt;h2 id="streamline-git-setup"&gt;Streamline git setup&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nf"&gt;.git&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
	git init
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Every project should be &lt;a href="https://dx.doi.org/10.1186/1751-0473-8-7"&gt;version controlled&lt;/a&gt;. I prefer git, but the makefile can probably be adapted for Mercurial, Subversion, darcs, etc. This recipe is so simple as to appear useless (since &lt;code&gt;make .git&lt;/code&gt; is no easier to type than &lt;code&gt;git init&lt;/code&gt;) but we use the directory &lt;code&gt;.git/&lt;/code&gt; as an &lt;a href="https://www.gnu.org/software/make/manual/html_node/Prerequisite-Types.html"&gt;order-only prerequisite&lt;/a&gt; for the next recipe:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nf"&gt;git-config&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; .&lt;span class="n"&gt;git&lt;/span&gt; 
	git config --local filter.dropoutput_jupyter.clean &lt;span class="se"&gt;\&lt;/span&gt;
        drop_jupyter_output.sh
	git config --local filter.dropoutput_jupyter.smudge cat
	git config --local core.page &lt;span class="s1"&gt;&amp;#39;less -x4&amp;#39;&lt;/span&gt;
	git config --local &lt;span class="se"&gt;\&lt;/span&gt;
        diff.daff-csv.command &lt;span class="s2"&gt;&amp;quot;daff.py diff --git&amp;quot;&lt;/span&gt;
	git config --local &lt;span class="se"&gt;\&lt;/span&gt;
        merge.daff-csv.name &lt;span class="s2"&gt;&amp;quot;daff.py tabular merge&amp;quot;&lt;/span&gt;
	git config --local &lt;span class="se"&gt;\&lt;/span&gt;
        merge.daff-csv.driver &lt;span class="s2"&gt;&amp;quot;daff.py merge --output %A %O %A %B&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Git configuration is &lt;em&gt;just&lt;/em&gt; annoying enough that I often put it off for a new project. With this recipe I don't have to!&lt;/p&gt;
&lt;p&gt;There are three parts to the configuration above; customize it for how you use git.&lt;/p&gt;
&lt;h3 id="drop-jupyter-notebook-output"&gt;Drop Jupyter Notebook output&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;git config --local filter.dropoutput_jupyter.clean &lt;span class="se"&gt;\&lt;/span&gt;
    ./drop_jupyter_output.sh
git config --local filter.dropoutput_jupyter.smudge cat
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I set up a &lt;a href="https://git-scm.com/book/en/v2/Customizing-Git-Git-Attributes"&gt;clean/smudge filter&lt;/a&gt; for my Jupyter notebooks. Outputs of analysis should generally not be version controlled, and this includes those outputs that are inlined in a Jupyter notebook. Now, when you &lt;code&gt;git add&lt;/code&gt; and &lt;code&gt;git diff&lt;/code&gt; notebooks, the output from cells will be automatically ignored. Thankfully, using this filter won't change the contents of the &lt;code&gt;.ipynb&lt;/code&gt; file itself, just the contents of the diff. This does mean, however, that when you &lt;code&gt;git checkout&lt;/code&gt; an old version of your notebook you'll have to re-execute all of the cells to get the results.&lt;/p&gt;
&lt;p&gt;Two other files are needed for this configuration to have any effect. First, &lt;code&gt;.gitattributes&lt;/code&gt; which is a tab-separated file mapping filename patterns to special git configuration. The first line in that file should be the following.&lt;/p&gt;
&lt;div class ="highlight"&gt;&lt;pre&gt;*.ipynb	filter=dropoutput_jupyter
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;(That's a tab after &lt;code&gt;*.ipynb&lt;/code&gt;.)&lt;/p&gt;
&lt;p&gt;The second file is the filter &lt;code&gt;drop_jupyter_output.sh&lt;/code&gt;, which needs to be executable.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/usr/bin/env bash&lt;/span&gt;
&lt;span class="c"&gt;# run `chmod +x drop_jupyter_output.sh` to make it executable.&lt;/span&gt;

&lt;span class="nv"&gt;file&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;mktemp&lt;span class="k"&gt;)&lt;/span&gt;
cat &amp;lt;&lt;span class="p"&gt;&amp;amp;&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &amp;gt;&lt;span class="nv"&gt;$file&lt;/span&gt;
jupyter nbconvert --to notebook --ClearOutputPreprocessor.enabled&lt;span class="o"&gt;=&lt;/span&gt;True &lt;span class="se"&gt;\&lt;/span&gt;
    &lt;span class="nv"&gt;$file&lt;/span&gt; --stdout 2&amp;gt;/dev/null
&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id="display-tabs-as-four-spaces"&gt;Display tabs as four spaces&lt;/h3&gt;
&lt;p&gt;I also configure &lt;code&gt;less&lt;/code&gt; to show four spaces for tabs. This makes &lt;code&gt;git diff&lt;/code&gt;-ing my makefile much easier on the eyes.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;git config --local core.page &lt;span class="s1"&gt;&amp;#39;less -x4&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id="smart-diffs-for-tabular-data"&gt;Smart &lt;code&gt;diff&lt;/code&gt;s for tabular data&lt;/h3&gt;
&lt;p&gt;Since git considers changes on a per-line basis, looking at &lt;code&gt;diff&lt;/code&gt;s of comma-delimited and tab-delimited files can get obnoxious. The program &lt;a href="http://paulfitz.github.io/daff/"&gt;&lt;code&gt;daff&lt;/code&gt;&lt;/a&gt; fixes this problem.&lt;/p&gt;
&lt;p&gt;We'll configure git to use &lt;code&gt;daff&lt;/code&gt; for all tabular files.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;git config --local &lt;span class="se"&gt;\&lt;/span&gt;
    diff.daff-csv.command &lt;span class="s2"&gt;&amp;quot;daff.py diff --git&amp;quot;&lt;/span&gt;
git config --local &lt;span class="se"&gt;\&lt;/span&gt;
    merge.daff-csv.name &lt;span class="s2"&gt;&amp;quot;daff.py tabular merge&amp;quot;&lt;/span&gt;
git config --local &lt;span class="se"&gt;\&lt;/span&gt;
    merge.daff-csv.driver &lt;span class="s2"&gt;&amp;quot;daff.py merge --output %A %O %A %B&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Just like the output filter for Jupyter notebooks, we need to associate this configuration with CSVs and TSVs in our &lt;code&gt;.gitattributes&lt;/code&gt; file by adding the following two lines.&lt;/p&gt;
&lt;div class ="highlight"&gt;&lt;pre&gt;*.[tc]sv diff=daff-csv
*.[tc]sv merge=daff-csv
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="automatic-python-virtual-environments"&gt;Automatic python virtual environments&lt;/h2&gt;
&lt;p&gt;There are plenty of &lt;a href="https://www.davidfischer.name/2010/04/why-you-should-be-using-pip-and-virtualenv/"&gt;reasons&lt;/a&gt; to sandbox your python environments. If you're like me and keep a separate virtual environment for every project, you'll appreciate these recipes to automate creating them and updating packages.&lt;/p&gt;
&lt;p&gt;If you don't use python/pip, these recipes can be swapped out for other sandboxing systems.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;VENV&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; .venv
&lt;span class="k"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;VIRTUAL_ENV&lt;/span&gt; &lt;span class="o"&gt;:=&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;abspath &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;VENV&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;PATH&lt;/span&gt; &lt;span class="o"&gt;:=&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;VIRTUAL_ENV&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;/bin:&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;PATH&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;

&lt;span class="nf"&gt;${VENV}&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
	python3 -m venv &lt;span class="nv"&gt;$@&lt;/span&gt;

&lt;span class="nf"&gt;python-reqs&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;requirements&lt;/span&gt;.&lt;span class="n"&gt;pip&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; ${&lt;span class="n"&gt;VENV&lt;/span&gt;}
	pip install --upgrade -r requirements.pip
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In the top block, we first set a variable &lt;code&gt;VENV&lt;/code&gt; to be the location of our virtual environment. We then set &lt;code&gt;VIRTUAL_ENV&lt;/code&gt; and prepend its &lt;code&gt;bin/&lt;/code&gt; to our &lt;code&gt;PATH&lt;/code&gt;. By exporting these variables, all recipes run from this makefile will use python packages and executables from the virtual environment. We don't have to remember to &lt;code&gt;source .venv/bin/activate&lt;/code&gt; first!&lt;/p&gt;
&lt;p&gt;The next block is the recipe to initialize the virtual environment. If you're not using Python 3 for your project you will have to edit this one.&lt;/p&gt;
&lt;p&gt;And finally, a recipe to install and update all of the packages listed in &lt;code&gt;requirements.pip&lt;/code&gt;. If you want to make a change to your python requirements, add it to &lt;code&gt;requirements.pip&lt;/code&gt; and re-run &lt;code&gt;make python-reqs&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;You can bootstrap other software installations similarly. And, if you discipline yourself to make all changes to your execution environment in this way, you'll have a permanently up-to-date record of your system requirements.&lt;/p&gt;
&lt;h2 id="single-command-project-setup"&gt;Single-command project setup&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nf"&gt;setup&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; ${&lt;span class="n"&gt;VENV&lt;/span&gt;} &lt;span class="n"&gt;python&lt;/span&gt;-&lt;span class="n"&gt;reqs&lt;/span&gt; &lt;span class="n"&gt;git&lt;/span&gt;-&lt;span class="n"&gt;config&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; .&lt;span class="n"&gt;git&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;With this meta-target a simple &lt;code&gt;make setup&lt;/code&gt; will have our new project configured and ready to go. This is particularly useful if you work on multiple machines:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;git clone git@github.com:username/project.git
&lt;span class="nb"&gt;cd &lt;/span&gt;project
make setup
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;is all it takes to get up and running.&lt;/p&gt;
&lt;h2 id="launch-your-tools-without-the-hassle"&gt;Launch your tools without the hassle&lt;/h2&gt;
&lt;p&gt;I use Jupyter Notebook's a lot. With this recipe (and the &lt;code&gt;PATH&lt;/code&gt; we export above) I don't have to remember to activate my virtual environment or invoke specific configuration files when I launch a server.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nf"&gt;start-jupyter&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
	jupyter notebook --config&lt;span class="o"&gt;=&lt;/span&gt;jupyter_notebook_config.py
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Put whatever you'd like into the &lt;a href="http://jupyter-notebook.readthedocs.io/en/latest/config.html"&gt;config file&lt;/a&gt;. I like to keep my notebooks in a subdirectory, so my invocation is a little different:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;jupyter notebook --config&lt;span class="o"&gt;=&lt;/span&gt;ipynb/jupyter_notebook_config.py --notebook-dir&lt;span class="o"&gt;=&lt;/span&gt;ipynb/
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;And my configuration is set to automatically changes the working directory to the project root when launching a new notebook.&lt;/p&gt;
&lt;p&gt;Customize! The same general idea works for any other software you can start from the shell No need to remember any of the obnoxious command-line flags.&lt;/p&gt;
&lt;h2 id="quick-cleanup"&gt;Quick cleanup&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;CLEANUP&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; *.pyc

&lt;span class="nf"&gt;clean&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
	rm -rf &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;CLEANUP&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;A ubiquitous target for &lt;em&gt;Make&lt;/em&gt; is &lt;code&gt;clean&lt;/code&gt; to tidy up the repository. With this makefile, run &lt;code&gt;make clean&lt;/code&gt; to remove all the &lt;code&gt;*.pyc&lt;/code&gt; files. Customize the &lt;code&gt;CLEANUP&lt;/code&gt; variable with filenames and globs you find yourself &lt;code&gt;rm&lt;/code&gt;-ing repeatedly. For me, this includes a bunch of &lt;code&gt;*.log&lt;/code&gt; and &lt;code&gt;*.logfile&lt;/code&gt; files.&lt;/p&gt;
&lt;h2 id="fork-this-code"&gt;Fork this code!&lt;/h2&gt;
&lt;p&gt;That's all I've got for a default makefile. And even this one is more complicated than it has to be; any &lt;em&gt;one&lt;/em&gt; component from it can make your life easier when practicing reproducible research.&lt;/p&gt;
&lt;p&gt;The whole point is to hide as much of the humdrum stuff as you can so you get to focus on what counts. I've found this makefile saves me both time and, more importantly, mental energy.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;Makefile&lt;/code&gt;, &lt;code&gt;.gitattributes&lt;/code&gt;, &lt;code&gt;requirements.pip&lt;/code&gt; and &lt;code&gt;drop_jupyter_output.sh&lt;/code&gt; described here can all be downloaded from &lt;a href="https://gist.github.com/bsmith89/c6811893c1cbd2a72cc1d144a197bef2"&gt;this gist&lt;/a&gt;&lt;a href="#fn4" class="footnoteRef" id="fnref4"&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;. Next time you're starting a project, download them to the project directory, run &lt;code&gt;make setup&lt;/code&gt;, and let me know what you think!&lt;/p&gt;
&lt;section class="footnotes"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn1"&gt;&lt;p&gt;My tutorial is designed to fill a three hour Software Carpentry lesson. There are a number of much shorter primers to get you started (e.g. &lt;a href="http://zmjones.com/make/"&gt;#1&lt;/a&gt;, &lt;a href="https://bost.ocks.org/mike/make/"&gt;#2&lt;/a&gt;, [#3][kborman-tutorial] ).&lt;a href="#fnref1"&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn2"&gt;&lt;p&gt;Randall Munroe does not agree. Relevant XKCDs: &lt;a href="https://xkcd.com/1205/"&gt;#1&lt;/a&gt;, &lt;a href="https://xkcd.com/1319/"&gt;#2&lt;/a&gt;, and &lt;a href="https://xkcd.com/974/"&gt;#3&lt;/a&gt;&lt;a href="#fnref2"&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn3"&gt;&lt;p&gt;John Cook makes &lt;a href="http://www.johndcook.com/blog/2015/12/22/automate-to-save-mental-energy-not-time/"&gt;this argument&lt;/a&gt; on his blog.&lt;a href="#fnref3"&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn4"&gt;&lt;p&gt;Even better, you could write a recipe to download those files on &lt;code&gt;make setup&lt;/code&gt;!&lt;a href="#fnref4"&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</summary><category term="make"></category><category term="pipelines"></category><category term="bioinformatics"></category><category term="protips"></category><category term="git"></category><category term="venv"></category><category term="python"></category></entry><entry><title>Software carpentry instructor training</title><link href="http://bsmith89.github.io/blog/instructor-survival.html" rel="alternate"></link><published>2016-05-30T12:00:00-04:00</published><updated>2016-05-31T12:00:00-04:00</updated><author><name>Byron J. Smith</name></author><id>tag:bsmith89.github.io,2016-05-30:blog/instructor-survival.html</id><summary type="html">&lt;p&gt;&lt;em&gt;Edit (2016-05-31): Added a hypothesis for why my results differ somewhat from &lt;a href="http://www.datacarpentry.org/blog/instructor-metrics/"&gt;Erin Becker's&lt;/a&gt;. Briefly: I removed individuals who taught before they were officially certified.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;A couple weeks ago, Greg Wilson &lt;a href="http://lists.software-carpentry.org/pipermail/discuss/2016-May/004471.html"&gt;asked&lt;/a&gt; the &lt;a href="http://software-carpentry.org/"&gt;Software Carpentry&lt;/a&gt; community for &lt;a href="http://software-carpentry.org/blog/2016/05/looking-for-a-model.html"&gt;feedback&lt;/a&gt; on a collection of data about the organization's instructors, when they were certified, and when they taught. Having dabbled in &lt;a href="https://en.wikipedia.org/wiki/Survival_analysis"&gt;survival analysis&lt;/a&gt;, I was excited to explore the data within that context.&lt;/p&gt;
&lt;p&gt;Survival analysis is focused on time-to-event data, for example time from birth until death, but also time to failure of engineered systems, or in this case, time from instructor certification to first teaching a workshop. The language is somewhat morbid, but helps with talking precisely about models that can easily be applied to a variety of data, only sometimes involving death or failure. The power of modern survival analysis is the ability to include results from subjects who have not yet experienced the event when data is collected. After all, studies rarely have the funding or patience to continue indefinitely. and excluding those data points entirely would falsely inflate rate estimates. Instead, the absence of an event for an individual during the study is useful information that contributes to the precise estimation of rates.&lt;/p&gt;
&lt;p&gt;Let's grab the Software Carpentry data and take a look.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;curl -O http://software-carpentry.org/files/2016/05/teaching-stats-2016-05.csv
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now in Python:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;patsy&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;statsmodels.api&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sm&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;seaborn&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sns&lt;/span&gt;

&lt;span class="c"&gt;# If you&amp;#39;re using jupyter:&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;

&lt;span class="n"&gt;raw_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;teaching-stats-2016-05.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sort_values&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Person&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;raw_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tail&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class ="highlight"&gt;&lt;pre&gt;      Person   Certified      Taught
1781   11268  2016-03-16         NaN
1782   11278  2016-03-29         NaN
1783   11280  2016-04-19         NaN
1784   11292  2016-02-29         NaN
1785   11293  2016-03-01         NaN
1558   11294  2016-04-25  2016-04-18
1557   11294  2016-04-25  2016-02-02
1559   11295  2016-04-25  2016-02-02
1786   11298  2016-04-21         NaN
1787   11311  2016-04-19         NaN
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This data is arranged as three columns: a ID number for each person, the date they were certified, and the date they taught. Individuals who have taught more than once have more than one row, and individuals who have been certified but have not yet taught have one row where taught is &lt;code&gt;NaN&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In our analysis, each certified instructor will be a data point with a certification date, a date of first teaching, second teaching, etc. Let's rearrange our data to reflect this structure using pandas split-apply-combine functionality.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_person_details&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sort_values&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Taught&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;certified&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Certified&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;drop_duplicates&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;certified&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="n"&gt;taught&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Taught&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;drop_duplicates&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;taught&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;taught_first&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;taught&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;taught_second&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nan&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;taught_first&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;taught&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;taught_second&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;taught&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Series&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;certified&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;certified&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                      &lt;span class="s"&gt;&amp;#39;taught_first&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;taught_first&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                      &lt;span class="s"&gt;&amp;#39;taught_second&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;taught_second&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                      &lt;span class="s"&gt;&amp;#39;taught_count&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;taught&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;notnull&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;()})&lt;/span&gt;

&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;raw_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;groupby&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Person&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;get_person_details&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class ="highlight"&gt;&lt;pre&gt;         certified  taught_count taught_first taught_second
Person
48      2014-05-04             1   2014-09-11           NaN
75      2013-07-20            15   2013-03-20    2013-03-24
85      2014-12-23             4   2015-03-06    2015-06-17
87      2013-11-25             4   2014-05-12    2015-03-20
135     2015-02-03             1   2015-09-03           NaN
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And some calculations&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;certified&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;certified&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;taught_first&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;taught_first&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;taught_second&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;taught_second&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;has_taught&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;taught_count&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;has_taught_multiple&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;taught_count&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;time_to_taught_first&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;taught_first&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;
                                &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;certified&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;days&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;time_to_taught_second&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;taught_second&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;
                                 &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;certified&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;days&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;time_between_first_second&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time_to_taught_second&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;
                                     &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time_to_taught_first&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;year_certified&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;certified&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;year&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I'd like to include data on how long instructors have been certified, since, for instructors who have not taught, thats how long they have gone without teaching. To get this value I need to a collection date for the data, which I don't know. For now, I'll use June 1st since I know the data was from May.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;COLLECTION_DATE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;year&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2016&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;month&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;day&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;time_since_certified&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;COLLECTION_DATE&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;certified&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;days&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;time_since_taught_first&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;COLLECTION_DATE&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;taught_first&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;days&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I'll take a quick peek at the key column.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;time_to_taught_first&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class ="highlight"&gt;&lt;pre&gt;        time_to_taught_first
Person
48                     130.0
75                    -122.0
85                      73.0
87                     168.0
135                    212.0
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Some people (Person 75, for instance) taught their first workshop before they were officially certified. I don't have any idea how to include them in the analysis, so I will be removing them from this point forward. I believe that the removal of these individuals explain differences between my results and &lt;a href="http://www.datacarpentry.org/blog/instructor-metrics/"&gt;the analysis&lt;/a&gt; posted to the Software Carpentry blog by Erin Becker.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time_to_taught_first&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;
            &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time_to_taught_first&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isnull&lt;/span&gt;&lt;span class="p"&gt;()]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Visualization is usually a good idea:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time_to_taught_first&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bins&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;taught_count&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Days between certification and first teaching&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;figure&gt;
&lt;img src="http://bsmith89.github.io/blog/static/images/swc-survival-taught-first-hist.png" alt="Histogram of days between certification and first teaching." /&gt;&lt;figcaption&gt;Histogram of days between certification and first teaching.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;{} of {} instructors have not yet taught.&amp;quot;&lt;/span&gt;
          &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;has_taught&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Of the 474 instructors in this data, 228 have not yet taught.&lt;/p&gt;
&lt;p&gt;Now we jump into the survival analysis. I'm going to compare time-to-first-teaching to the year in which instructors were certified. This is mostly because I want a covariate here, and I don't have access to more interesting ones, e.g. what style of training it was (online, 2-day, etc.).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;# We&amp;#39;ll be modifying our data, so a copy will keep the original pristine.&lt;/span&gt;
&lt;span class="n"&gt;_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c"&gt;# If individuals have not yet taught as of data collection,&lt;/span&gt;
&lt;span class="c"&gt;# then we will censor them.&lt;/span&gt;
&lt;span class="c"&gt;# statsmodels requires this time-to-censoring be in the same column as the&lt;/span&gt;
&lt;span class="c"&gt;# time-to-event.&lt;/span&gt;
&lt;span class="n"&gt;_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time_to_taught_first&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fillna&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time_since_certified&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inplace&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# Fit a proportional hazards model, comparing certification year.&lt;/span&gt;
&lt;span class="c"&gt;# &amp;quot;Sum&amp;quot; stands for sum-to-zero coding for the design matrix.&lt;/span&gt;
&lt;span class="n"&gt;ydm&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xdm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; \
    &lt;span class="n"&gt;patsy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dmatrices&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;time_to_taught_first ~ C(year_certified, Sum)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;return_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;dataframe&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c"&gt;# Remove the intercept term.&lt;/span&gt;
&lt;span class="n"&gt;xdm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;xdm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;drop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Intercept&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;columns&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# Right censor for individuals who have not yet taught by the date&lt;/span&gt;
&lt;span class="c"&gt;# of this data collection.&lt;/span&gt;
&lt;span class="n"&gt;fit1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PHReg&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ydm&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xdm&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;has_taught&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The most widely used model in survival analysis is called the &lt;a href="https://en.wikipedia.org/wiki/Proportional_hazards_model"&gt;proportional hazards model&lt;/a&gt;. In the process of testing the significance of our covariates in this model, a survival curve is calculated. In this case, because of the coding for certification year in the design matrix, this &amp;quot;baseline&amp;quot; curve represents the mean of annual means.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;sf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fit1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;baseline_cumulative_hazard&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;sf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Days post-certification&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Fraction instructors not taught&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;figure&gt;
&lt;img src="http://bsmith89.github.io/blog/static/images/swc-survival-taught-first-curve.png" alt="Survival curve of days to teaching for the first time" /&gt;&lt;figcaption&gt;Survival curve of days to teaching for the first time&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;The key figure in survival analysis is the survival curve, or its derivative the hazard function. Survival curves plot the number or percentage of individuals who have not yet experienced the event after a given amount of time. In the case of this data, the survival curve reflects the fraction of instructors who have not yet taught by a given number of days after they were certified.&lt;/p&gt;
&lt;p&gt;Despite the fact that about 50% of certified instructors have not yet taught, many of these are recently trained and we expect them to teach in the future. 50% of certified instructors teach by 200 days. After more than a year, however, the survival curve flattens out. Approximately 30% of instructors get to 400 days without having taught and at 600 days about the same fraction have still not taught. If we want to extrapolate beyond the data (always a bad idea) then we might predict that these instructors will never teach.&lt;/p&gt;
&lt;p&gt;We can also test the effect of certification year on time to first workshop.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fit1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class ="highlight"&gt;&lt;pre&gt;                                   Results: PHReg
====================================================================================
Model:                       PH Reg                        Sample size:          474
Dependent variable:          time_to_taught_first          Num. events:          246
Ties:                        Breslow
------------------------------------------------------------------------------------
                                log HR log HR SE   HR      t    P&gt;|t|  [0.025 0.975]
------------------------------------------------------------------------------------
C(year_certified, Sum)[S.2012]  0.1382    0.5705 1.1482  0.2422 0.8086 0.3753 3.5124
C(year_certified, Sum)[S.2013]  0.2230    0.2268 1.2498  0.9830 0.3256 0.8012 1.9493
C(year_certified, Sum)[S.2014] -0.1383    0.1789 0.8708 -0.7732 0.4394 0.6132 1.2366
C(year_certified, Sum)[S.2015]  0.0205    0.1730 1.0207  0.1183 0.9058 0.7272 1.4327
====================================================================================
Confidence intervals are for the hazard ratios
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We see no significant deviation from the average year for any of the 4 years of certification data.&lt;/p&gt;
&lt;p&gt;Just for fun, let's go even further with this data. Of the 246 instructors who have taught at least once, 131 have taught a second time. Can we predict the time after first teaching that it takes to teach again?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;_data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time_to_taught_first&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;notnull&lt;/span&gt;&lt;span class="p"&gt;()]&lt;/span&gt;

&lt;span class="c"&gt;# Fill in dates for right censoring.&lt;/span&gt;
&lt;span class="n"&gt;_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time_between_first_second&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fillna&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time_since_taught_first&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inplace&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# Fit a proportional hazards model using time between certification and first taught.&lt;/span&gt;
&lt;span class="n"&gt;ydm&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xdm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;patsy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dmatrices&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;time_between_first_second ~ time_to_taught_first&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                           &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;return_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;dataframe&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;xdm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;xdm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;drop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Intercept&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;columns&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c"&gt;# Remove the intercept term&lt;/span&gt;

&lt;span class="c"&gt;# Right censor for individuals who have not yet taught a second time.&lt;/span&gt;
&lt;span class="n"&gt;fit2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sm&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PHReg&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ydm&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xdm&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;has_taught_multiple&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c"&gt;# The baseline hazard is the probability of having not taught a second&lt;/span&gt;
&lt;span class="c"&gt;# time by a given day for someone who taught at day 0 of being certified.&lt;/span&gt;
&lt;span class="n"&gt;sf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fit2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;baseline_cumulative_hazard&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;sf&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Days post-first-teaching&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Fraction instructors not taught second time&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;figure&gt;
&lt;img src="http://bsmith89.github.io/blog/static/images/swc-survival-taught-second-curve.png" alt="Survival curve of days to teaching a second time after having taught once" /&gt;&lt;figcaption&gt;Survival curve of days to teaching a second time after having taught once&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;The baseline survival curve reflects expectations for a theoretical individual who taught immediately upon being certified (day 0). For these folks, we expect 50% to teach again within 100 days, and almost 80% within a year.&lt;/p&gt;
&lt;p&gt;Let's take a look at the effect of time-to-first-teaching on time to teaching again.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fit2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class ="highlight"&gt;&lt;pre&gt;                              Results: PHReg
==========================================================================
Model:                  PH Reg                        Sample size:     246
Dependent variable:     time_between_first_second     Num. events:     131
Ties:                   Breslow
--------------------------------------------------------------------------
                      log HR log HR SE   HR      t    P&gt;|t|  [0.025 0.975]
--------------------------------------------------------------------------
time_to_taught_first -0.0045    0.0010 0.9955 -4.3474 0.0000 0.9935 0.9975
==========================================================================
Confidence intervals are for the hazard ratios
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We find a highly significant effect of time-to-first-teaching.&lt;/p&gt;
&lt;p&gt;The hazard ratio estimate is 0.9955. We can interpret this to mean that the per-day probability of teaching again goes down by 0.45% for every day between certification and teaching the first time. This isn't all that surprising; individuals who are able to teach soon after being certified are probably both enthusiastic and have more time to devote to teaching.&lt;/p&gt;
&lt;p&gt;That's all I've got. Thanks for reading. I'd love to hear what you think and if you spot any glaring mistakes in my analysis. All of the code to do this is available &lt;a href="https://github.com/bsmith89/swc-instructor-training-analysis"&gt;on github&lt;/a&gt;. If you have ideas for additional analysis please leave a comment here, submit an issue to the github repository, or even better, a pull-request.&lt;/p&gt;
</summary><category term="software-carpentry"></category><category term="python"></category><category term="statistics"></category></entry><entry><title>First time teaching Python to novices</title><link href="http://bsmith89.github.io/blog/swc-python-lesson.html" rel="alternate"></link><published>2015-08-12T01:00:00-04:00</published><updated>2015-08-14T10:00:00-04:00</updated><author><name>Byron J. Smith</name></author><id>tag:bsmith89.github.io,2015-08-12:blog/swc-python-lesson.html</id><summary type="html">&lt;p&gt;This July I co-instructed with &lt;a href="https://impactstory.org/JenniferShelton"&gt;Jennifer Shelton&lt;/a&gt; a Software Carpentry &lt;a href="http://i5k-kinbre-script-share.github.io/2015-07-23-stanford/"&gt;workshop&lt;/a&gt; at Stanford University, targeted to researchers with genomic or evolutionary datasets. Jennifer taught the shell (Bash) and version control with Git, while I taught the general programming language Python. I've been aware of the &lt;a href="http://software-carpentry.org/"&gt;organization&lt;/a&gt;, which teaches software development and computational methods to scientists, since attending a workshop in 2012. Since then I've served as a helper at one workshop (troubleshooting individual learner's problems and helping catch them up with the rest of the class), and gone through the &amp;quot;accelerated&amp;quot;, two day, instructor training at Michigan State University. After the Stanford workshop, I took part in new-instructor debriefing on August 4th, during which I mentioned that I had to greatly pare down the community-written lesson plan, &lt;a href="http://swcarpentry.github.io/python-novice-inflammation/"&gt;python-novice-inflammation&lt;/a&gt;, to fit into the two half-day session we allotted it.&lt;/p&gt;
&lt;p&gt;Karin and Tiffany, who were running the debriefing, asked me to send a note to the mentorship email list about which parts I removed and which I kept in. I thought I'd also take the opportunity to comment on the material at large: what worked for me and what didn't. What started as an email quickly ballooned into this blog post.&lt;/p&gt;
&lt;p&gt;To be explicit, I was teaching from the state of the repository at the time of the workshop&lt;a href="#fn1" class="footnoteRef" id="fnref1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; .&lt;/p&gt;
&lt;p&gt;With this as my first workshop&lt;a href="#fn2" class="footnoteRef" id="fnref2"&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;, I (incorrectly) thought I could teach all of the topics straight through. By the time it became apparent that this wasn't going to work, adapting the first day's material had to be done on the fly. After that experience, and before the following afternoon, I prepared a subset of the remaining material that I thought I could cover. I'm now relying on my (somewhat traumatic) memory of the first session, and that outline I put together for the second day to write this summary.&lt;/p&gt;
&lt;p&gt;My plan going in was to split &lt;a href="http://swcarpentry.github.io/python-novice-inflammation/index.html#topics"&gt;the material&lt;/a&gt; after Topic 6, getting learners up to writing functions on the first day, so that we could discuss debugging and best-practices, and transition from the Jupyter notebook to shell scripts, the next day. Based on my co-instructors recommendation, I did not have learners do all of the challenge questions for each topic, but instead picked just one or two that I thought would be most useful.&lt;/p&gt;
&lt;p&gt;I found myself wishing (especially for Topic 1: &amp;quot;Analyzing Patient Data&amp;quot;) that some of the easier questions were integrated into the lesson itself, instead of all at the bottom. Learners should have had more chances to problem-solve early, instead of listening to me for the entirety of each topic before getting their feet wet.&lt;/p&gt;
&lt;h2 id="motivating-python"&gt;Motivating Python&lt;/h2&gt;
&lt;p&gt;For that &lt;a href="http://swcarpentry.github.io/python-novice-inflammation/01-numpy.html"&gt;first topic&lt;/a&gt; I &lt;em&gt;did&lt;/em&gt; cover everything, but wish I hadn't, since it was mostly focused on array operations and the specifics of working with NumPy (e.g. operations along axes). I appreciated that we were showing the learners powerful library features to motivate the later work, but I didn't feel like it was great for this workshop's &amp;quot;genomics&amp;quot; audience. Maybe these initial motivating sections should be targeted the same way the capstone projects are. It was also too long relative to the other sections, in my opinion.&lt;/p&gt;
&lt;p&gt;It &lt;em&gt;was&lt;/em&gt; very good, however, for introducing some python specifics, especially things that learners coming from other languages like R or Mathematica might not know (e.g. 0-indexing, slices, that variable assignment happens when each line is executed, etc.). It gave learners a chance to be surprised by their misconceptions and ask questions. We should do more of that.&lt;/p&gt;
&lt;p&gt;It would have been helpful for the lesson to have pre-built explanations for 0-indexing and right-exclusive slicing, since these were the hard parts and I'm not happy with the explanations I initially used.&lt;/p&gt;
&lt;p&gt;I found the nature of the made-up data (maximum values smooth and minimum values as a step-function along the first axis) distracting. I also didn't know what they were supposed to represent (beyond inflammation over time), so the &amp;quot;actually doing science&amp;quot; part of the motivation was a bit lost. Is there a reason we use these data?&lt;/p&gt;
&lt;h2 id="python-basics-lists-loops-conditionals-etc."&gt;Python basics: lists, loops, conditionals, etc.&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://swcarpentry.github.io/python-novice-inflammation/02-loop.html"&gt;Topics 2&lt;/a&gt; and &lt;a href="http://swcarpentry.github.io/python-novice-inflammation/03-lists.html"&gt;3&lt;/a&gt;, &amp;quot;Repeating Actions with Loops&amp;quot; and &amp;quot;Storing Multiple Values in Lists&amp;quot; respectively, were good and short. I didn't feel like I had to cut anything out. However, for-loop syntax was not explicitly covered early in the lesson plan. It wasn't until I realized I had gotten ahead of myself that we talked about loop variables, iterables&lt;a href="#fn3" class="footnoteRef" id="fnref3"&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;, and the indented code-block.&lt;/p&gt;
&lt;p&gt;I also thought the segue from Topic 1 to 2 was a bit weak. This was a theme throughout, mixing the inflammation data with much simpler stuff (e.g. looping over short strings and lists). I realize we want to keep the motivation going, but, as a first-time instructor, I found it to be distracting, and didn't know which I should be emphasizing to the learners.&lt;/p&gt;
&lt;p&gt;I also picked the wrong challenge question from Topic 1 (reverse &lt;code&gt;'Newton'&lt;/code&gt; using a loop), since we hadn't covered &lt;code&gt;range&lt;/code&gt;, &lt;code&gt;append&lt;/code&gt;ing to lists, &lt;code&gt;''.join&lt;/code&gt;, etc. What novice audience is that question appropriate for? Maybe the solution is simple and I'm just confused...&lt;/p&gt;
&lt;p&gt;The material for &lt;a href="http://swcarpentry.github.io/python-novice-inflammation/04-files.html"&gt;topic 4&lt;/a&gt;, &amp;quot;Analyzing Data from Multiple Files&amp;quot; worked well overall. The only mistake I remember was copy-pasting the big chunk of code from the lesson (looping over files and drawing sets of plots) instead of typing it out. I figured since most of the code was library calls, learners wouldn't get anything out of me taking the time to type all of it. That may have been true, but it meant the learners weren't executing the code at the same time as me, which interrupted the flow of the lesson.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://swcarpentry.github.io/python-novice-inflammation/05-cond.html"&gt;Topic 5&lt;/a&gt;, &amp;quot;Making Choice&amp;quot; (if-statements), was where things got hairy. I panicked a bit and went mostly off the lesson plan. It did not go well. When I tried to find something in the lesson to get me back on track, I wished there was more explicit discussion of syntax and booleans. I was able to review the topic the next day, which I think got any lost learners mostly caught up.&lt;/p&gt;
&lt;p&gt;As you can imagine, at this point we were nearing the end of the first day. I did manage to show the learners the syntax for defining and using functions, but I covered &lt;a href="http://swcarpentry.github.io/python-novice-inflammation/06-func.html"&gt;topic 6&lt;/a&gt;, &amp;quot;Creating Functions&amp;quot;, in its entirety at the start of the next session.&lt;/p&gt;
&lt;h2 id="learning-my-lesson"&gt;Learning my lesson&lt;/h2&gt;
&lt;p&gt;After the harrowing experience with conditionals on the first day, I took the time to write out a personalized lesson outline for the next day with learning objectives, steps in explaining difficult concepts, and pre-picked understanding/challenge questions. The exercise of writing an outline of learning objectives before the class was very helpful, and something I intend to repeat before future workshops.&lt;/p&gt;
&lt;p&gt;If I remember correctly&lt;a href="#fn4" class="footnoteRef" id="fnref4"&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;, the second day I started once again with functions, and largely based the lesson on the material in &lt;a href="http://swcarpentry.github.io/python-novice-inflammation/06-func.html"&gt;the topic&lt;/a&gt;. The temperature conversion formulas were an effective motivator for this lesson. I wonder if simple examples, like this one, can replace the more complex (and, admittedly, more impressive) inflammation tutorial to demonstrate the value of Python for scientists. I also integrated material from the &lt;a href="http://swcarpentry.github.io/python-novice-inflammation/07-errors.html"&gt;topic on errors and exceptions&lt;/a&gt;: tracebacks, syntax errors, etc. In this combined topic I did not use the &lt;code&gt;import errors_01&lt;/code&gt; example. It was unclear to me why the lesson plan, as written, uses a black-box script like &lt;code&gt;errors_01.py&lt;/code&gt;, and not something more explicit, like an index or attribute error, to dissect the traceback. I think the explicit approach worked well for the learners in this workshop. Since we were covering functions anyway, it wasn't hard to get a multi-level traceback. Syntax errors also combined nicely with learning function definition syntax.&lt;/p&gt;
&lt;figure&gt;
&lt;img src="http://bsmith89.github.io/blog/static/images/swc-stanford-byron.jpg" alt="The author dissecting an attribute error." /&gt;&lt;figcaption&gt;The author dissecting an attribute error.&lt;a href="#fn5" class="footnoteRef" id="fnref5"&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Somewhere in the process of talking about functions we got sidetracked with &lt;code&gt;open()&lt;/code&gt;. I was surprised to see that the lesson plans have only limited discussion of file objects, only really dealing with them in the section on &lt;code&gt;IOErrors&lt;/code&gt;. I think learners appreciated a chance to see how the array data they had used the day before were saved as a CSV, and how they could access the data directly. It also gave us a chance to show that other objects besides lists and strings can serve as iterators in for-loops.&lt;/p&gt;
&lt;p&gt;I liked how the topic 6 &lt;a href="http://swcarpentry.github.io/python-novice-inflammation/06-func.html#defining-defaults"&gt;lesson plan&lt;/a&gt; used the library function &lt;code&gt;numpy.loadtxt()&lt;/code&gt; to talk about default arguments and the &lt;code&gt;help()&lt;/code&gt; built-in. I jumped back and forth between examining that function and implementing the same things (keywords, documentation) in a &lt;code&gt;center()&lt;/code&gt; function we were building. The realized lesson was very similar to the repository's lesson plan, but a little more integrated with errors and exceptions.&lt;/p&gt;
&lt;p&gt;I had the learners implement &lt;code&gt;rescale()&lt;/code&gt; as a challenge question. We then worked together as a class to add lower and upper bounds. This was a much more difficult task than I expected (even just deriving the correct formula), and served nicely to demonstrate defensive programming and debugging. While we touched on many of the concepts in &lt;a href="http://swcarpentry.github.io/python-novice-inflammation/08-defensive.html"&gt;topics 8&lt;/a&gt; and &lt;a href="http://swcarpentry.github.io/python-novice-inflammation/09-debugging.html"&gt;9&lt;/a&gt;, these ideas, were spread throughout, and I did not walk through either as an atomic lesson.&lt;/p&gt;
&lt;p&gt;My ultimate goal on the second day was to write a program to calculate the mean inflammation of each subject in the example files and then transform the program into a command-line script that would operate as a UNIX-style filter. I remember Greg Wilson teaching Python scripting (along with Bash and SQL) that way during my first workshop (as a &lt;em&gt;learner&lt;/em&gt;!) at MSU in May 2012&lt;a href="#fn6" class="footnoteRef" id="fnref6"&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt;. This &lt;a href="http://swcarpentry.github.io/python-novice-inflammation/10-cmdline.html"&gt;last topic&lt;/a&gt; seemed like a worthwhile mini-capstone, since it would reintroduce ideas from the Bash lesson the day before, and we could version-control our work with git. While we managed to run our code as a script (rather than a cell in the Jupyter notebook), the transition was a little rough around the edges, and we didn't have time to add &lt;code&gt;sys.argv&lt;/code&gt; or &lt;code&gt;sys.stdin&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id="take-aways"&gt;Take-aways&lt;/h2&gt;
&lt;p&gt;The second day of Python was much smoother than the first, and, while we did not get to all of the material, I was satisfied with what we did cover. It's quite remarkable that learners can go all the way from indexing into lists to defensive programming and unit tests in just a few hours. I'm not convinced that we got them far enough to jump right into using Python for their own work, but I hope it was a good kick-start towards that goal. I'm amazed some novice workshops only allocate a half-day session to the programming language (be it Python, R, or Matlab), although a quick survey of &lt;a href="http://software-carpentry.org/workshops/index.html#future"&gt;upcoming workshops&lt;/a&gt; suggests that almost &lt;em&gt;all&lt;/em&gt; of them do in fact use two sessions. Is this the recommended approach (and if so where is it documented) or have many instructors all independently come to the same conclusion?&lt;/p&gt;
&lt;p&gt;Even so, there's still more material in python-novice-inflammation than can be covered in two sessions. I'm under the impression that the repository is sort of &lt;em&gt;meant&lt;/em&gt; to be like that: way too big, so that instructors can pick and choose the parts that are most salient for their audience. This seems like a good idea, but it was not sufficiently communicated to me as a first-time instructor, and, while many of the difficulties I had could have been solved with more comprehensive preparation, having a &amp;quot;default&amp;quot; subset would have been helpful.&lt;/p&gt;
&lt;section class="footnotes"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn1"&gt;&lt;p&gt;&lt;a href="https://github.com/swcarpentry/python-novice-inflammation/tree/76e3ea24406e4b8d684c9b45f3c5fd33e23ac71a"&gt;&lt;code&gt;76e3ea24406e4b8d684c9b45f3c5fd33e23ac71a&lt;/code&gt;&lt;/a&gt;: still the HEAD as of this writing.&lt;a href="#fnref1"&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn2"&gt;&lt;p&gt;and being insufficiently prepared&lt;a href="#fnref2"&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn3"&gt;&lt;p&gt;Actually, we talked about getting values from lists and how strings are like lists, rather than about iterables in general.&lt;a href="#fnref3"&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn4"&gt;&lt;p&gt;Despite the fact that I have those notes, I actually don't remember the details of that day's lesson as well. I wonder if there's some weird metamemory thing going on e.g. &lt;a href="http://www.sciencemag.org/content/333/6043/776.abstract"&gt;this&lt;/a&gt; (unfortunately paywalled).&lt;a href="#fnref4"&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn5"&gt;&lt;p&gt;Photo credit: Amy Hodge (&lt;a href="https://creativecommons.org/licenses/by/2.0/"&gt;CC-BY&lt;/a&gt;)&lt;a href="#fnref5"&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn6"&gt;&lt;p&gt;The site for this historic event can still be found &lt;a href="https://web.archive.org/web/20120514195748/http://software-carpentry.org/boot-camps/michigan-state-university-may-2012/"&gt;here&lt;/a&gt;.&lt;a href="#fnref6"&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</summary><category term="software-carpentry"></category><category term="teaching"></category><category term="programming"></category><category term="mistakes"></category><category term="python"></category></entry><entry><title>Compiling SciPy on RHEL6</title><link href="http://bsmith89.github.io/blog/scipy-on-rhel.html" rel="alternate"></link><published>2013-05-20T12:00:00-04:00</published><author><name>Byron J. Smith</name></author><id>tag:bsmith89.github.io,2013-05-20:blog/scipy-on-rhel.html</id><summary type="html">&lt;p&gt;Within the past two years I've discovered something interesting about myself (...actually really, &lt;em&gt;really&lt;/em&gt; boring about myself): I can be happily entertained for hours on end setting up my computational environment &lt;em&gt;just&lt;/em&gt; right. I find that it gives me a similar type of satisfaction to cataloguing my music collection. I guess you could call it a hobby.&lt;/p&gt;
&lt;p&gt;Usually this entails installing the usual suspects (&lt;code&gt;NumPy&lt;/code&gt;, &lt;code&gt;Pandas&lt;/code&gt;, &lt;code&gt;IPython&lt;/code&gt;, &lt;code&gt;matplotlib&lt;/code&gt;, etc.) in a python &lt;a href="http://www.virtualenv.org/en/latest/"&gt;virtual environment&lt;/a&gt;. When I'm particularly into it (which is always), I'll also compile the python distribution itself. I've had several opportunities to indulge this pasttime, most recently in setting up my research pipeline on the &lt;a href="http://cac.engin.umich.edu/resources/systems/flux"&gt;Flux&lt;/a&gt; high-performance compute cluster at The University of Michigan.&lt;/p&gt;
&lt;p&gt;Installing &lt;code&gt;NumPy&lt;/code&gt; is usually no trouble at all, but for some reason (if you know, please tell me), &lt;code&gt;SciPy&lt;/code&gt; has &lt;em&gt;always&lt;/em&gt; given me a &amp;quot;BlasNotFoundError&amp;quot; when installing on the Red Hat Enterprise Linux distros commonly used on academic clusters.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="gp"&gt;&amp;gt;&lt;/span&gt; pip install scipy
&lt;span class="go"&gt;Downloading/unpacking scipy&lt;/span&gt;
&lt;span class="go"&gt;  Downloading scipy-0.12.0.zip (10.2MB): 100% 10.2MB downloaded&lt;/span&gt;
&lt;span class="go"&gt;...&lt;/span&gt;
&lt;span class="go"&gt;numpy.distutils.system_info.BlasNotFoundError:&lt;/span&gt;
&lt;span class="go"&gt;    Blas (http://www.netlib.org/blas/) libraries not found.&lt;/span&gt;
&lt;span class="go"&gt;    Directories to search for the libraries can be specified in the&lt;/span&gt;
&lt;span class="go"&gt;    numpy/distutils/site.cfg file (section [blas]) or by setting&lt;/span&gt;
&lt;span class="go"&gt;    the BLAS environment variable.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I &lt;em&gt;know&lt;/em&gt; BLAS and LAPACK are installed as shared libraries: at Michigan State University I had to load the respective modules, but at UMich they're right there in &lt;code&gt;/usr/lib64/atlas&lt;/code&gt;. So why &lt;code&gt;pip install SciPy&lt;/code&gt; always gives me that error, I have no clue. I've set the BLAS and LAPACK environmental variables to the relevant shared libraries. I've run &lt;code&gt;python setup.py build --fcompiler=gnu95&lt;/code&gt; directly. But I always got that same error.&lt;/p&gt;
&lt;p&gt;Anyway, I &lt;em&gt;finally&lt;/em&gt; got it to work, so I thought I'd share the steps I took just in case it helps someone else. My solution was found on Stack Overflow (surprise, surprise): The accepted answer to &lt;a href="http://stackoverflow.com/q/7496547/848121"&gt;this&lt;/a&gt; question.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;mkdir -p ~/.local/src/
&lt;span class="nb"&gt;cd&lt;/span&gt; ~/.local/src/
wget -O BLAS.tgz http://www.netlib.org/blas/blas.tgz
tar -xzf BLAS.tgz
&lt;span class="nb"&gt;cd &lt;/span&gt;BLAS
gfortran -O3 -std&lt;span class="o"&gt;=&lt;/span&gt;legacy -m64 -fno-second-underscore -fPIC -c *.f
ar r libfblas.a *.o
ranlib libfblas.a
&lt;span class="nb"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;BLAS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$PWD&lt;/span&gt;/libfblas.a

&lt;span class="nb"&gt;cd&lt;/span&gt; ~/.local/src/
wget -O LAPACK.tgz http://www.netlib.org/lapack/lapack.tgz
tar -xzf LAPACK.tgz
&lt;span class="c"&gt;# The resulting directory may be named lapack-&amp;lt;version&amp;gt;/&lt;/span&gt;
&lt;span class="c"&gt;# the following assumes that it&amp;#39;s named LAPACK/&lt;/span&gt;
&lt;span class="nb"&gt;cd &lt;/span&gt;LAPACK
cp INSTALL/make.inc.gfortran make.inc
vim make.inc
&lt;span class="c"&gt;# Change OPTS = -O2 to OPTS = -O2 -fPIC&lt;/span&gt;
&lt;span class="c"&gt;# Change NOOPT = -O0 to NOOPT = -O0 -fPIC&lt;/span&gt;
make lapacklib
&lt;span class="nb"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;LAPACK&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$PWD&lt;/span&gt;/libflapack.a

&lt;span class="nb"&gt;cd&lt;/span&gt; ~/.local/src/
git clone https://github.com/scipy/scipy.git
&lt;span class="nb"&gt;cd &lt;/span&gt;scipy
python setup.py build --fcompiler gnu95
python setup.py install
&lt;span class="c"&gt;# Assuming you&amp;#39;re already in the virtualenv you want to install to.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I don't know which other systems this will work on, but it does successfully install SciPy for me. On Python 3.3.2, running the unit tests give me several errors and failures (nothing too scary looking), but everything passes on Python 2.7.5!&lt;/p&gt;
&lt;p&gt;Enjoy.&lt;/p&gt;
</summary><category term="python"></category><category term="hpc"></category><category term="software"></category><category term="scipy"></category><category term="linux"></category></entry><entry><title>PyMake I: Another GNU Make clone</title><link href="http://bsmith89.github.io/blog/pymake-0.html" rel="alternate"></link><published>2013-05-07T19:00:00-04:00</published><updated>2016-03-04T10:00:00-05:00</updated><author><name>Byron J. Smith</name></author><id>tag:bsmith89.github.io,2013-05-07:blog/pymake-0.html</id><summary type="html">&lt;p&gt;(Edit 1): &lt;del&gt;&lt;em&gt;This is the first of two posts about my program &lt;a href="http://github.com/bsmith89/pymake/"&gt;PyMake&lt;/a&gt;. I'll post the link to Part II here when I've written it.&lt;/em&gt;&lt;/del&gt; &lt;em&gt;While I still agree with some of the many of the views expressed in this piece, I have changed my thinking on Makefiles.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;(Edit 2): &lt;del&gt;&lt;em&gt;I'll post a new post about the topic when I take the time to write it.&lt;/em&gt;&lt;/del&gt; &lt;em&gt;I've written a &lt;a href="make-analysis.html"&gt;tutorial&lt;/a&gt; on using &lt;em&gt;Make&lt;/em&gt; for reproducible data analysis&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;I am an aspiring but unskilled (not yet skilled?) computer geek. You can observe this for yourself by watching me fumble my way through &lt;a href="https://github.com/bsmith89/dotfiles"&gt;&lt;code&gt;vim&lt;/code&gt; configuration&lt;/a&gt;, multi-threading/processing in Python, and &lt;code&gt;git&lt;/code&gt; merges.&lt;/p&gt;
&lt;p&gt;Rarely do I actually feel like my products are worth sharing with the wider world. The only reason I have a GitHub account is personal convenience and absolute confidence that no one else will ever look at it besides me. (Yes, I realize that I am invalidating the previous sentence with that glaring &amp;quot;Fork me on GitHub&amp;quot; ribbon in the top-right corner of this page. I'm putting myself out there! OKAY?!)&lt;/p&gt;
&lt;p&gt;As an aspiring scientist, too, I've had plenty of opportunities to practice the relevant skill sets. A laboratory rotation with &lt;a href="http://ivory.idyll.org/blog/"&gt;Titus Brown&lt;/a&gt;, and the resulting exposure to his reproducible research and &lt;a href="http://software-carpentry.org"&gt;Software Carpentry&lt;/a&gt; evangelizing, has certainly influenced the tools and techniques in my belt.&lt;/p&gt;
&lt;p&gt;I try to use the &lt;code&gt;NumPy&lt;/code&gt;/&lt;code&gt;SciPy&lt;/code&gt;/&lt;code&gt;Pandas&lt;/code&gt;/&lt;code&gt;matplotlib&lt;/code&gt; stack for my computational and visualization tasks. I am a relatively competent &lt;code&gt;BASH&lt;/code&gt;-ist and I work hard to write my scripts so that they'll make sense to me 5 years from now. I have even been known to do some of my data analysis in IPython notebooks.&lt;/p&gt;
&lt;h1 id="a-pipeline-is-only-sometimes-a-makefile"&gt;A Pipeline is only sometimes a Makefile&lt;/h1&gt;
&lt;p&gt;Despite (or maybe because of) my obsession with writing simple, reproducible pipelines, one tool I have never come to terms with is GNU &lt;code&gt;make&lt;/code&gt;. While it's not quite mainstream for bioinformaticians and other computational folk, &lt;code&gt;make&lt;/code&gt; &lt;a href="http://archive.nodalpoint.org/2007/03/18/a_pipeline_is_a_makefile"&gt;promises&lt;/a&gt; to tie all those *&lt;code&gt;NIX&lt;/code&gt; style scripts together seamlessly and with built-in parallelization, selective re-running, and more, all under a declarative language syntax. I say 'promises' because, for me, it never did any of those things.&lt;/p&gt;
&lt;p&gt;Now, I don't want to suggest that this ubiquitous piece of GNU software doesn't work well. I recognize that it does much of what the average user needs, but for my particular pipeline it just wasn't the right tool.&lt;/p&gt;
&lt;p&gt;My problem was a seemingly simple one. I had a set of gene models (HMMs) and a set of FASTQ formatted sequences from an Illumina sequencer. The goal was to search every sample for every gene using HMMER3 and to output the results (plus a respectable amount of pre- and post-processing). The problem is, &lt;code&gt;make&lt;/code&gt; is designed for software compilation. Processing &lt;code&gt;foo.c&lt;/code&gt; and &lt;code&gt;bar.h&lt;/code&gt; into &lt;code&gt;foo.o&lt;/code&gt; is easy. I, however, was asking &lt;code&gt;make&lt;/code&gt; to generate the product of &lt;span class="math inline"&gt;&lt;em&gt;n&lt;/em&gt;&lt;/span&gt; samples and &lt;span class="math inline"&gt;&lt;em&gt;m&lt;/em&gt;&lt;/span&gt; models (&lt;strong&gt;complete aside&lt;/strong&gt;: if you're curious about how I got the &lt;span class="math inline"&gt;$\LaTeX$&lt;/span&gt; formatting, see &lt;a href="http://www.ceremade.dauphine.fr/~amic/blog/mathjax-and-pelican-en.html"&gt;this&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;While, after a dozen hours of smashing my head against the table, I was able to get my &lt;code&gt;Makefile&lt;/code&gt; to work, it required some &lt;em&gt;really&lt;/em&gt; ugly tricks like secondary expansion and gratuitous calls to &lt;code&gt;sed&lt;/code&gt; in my macros (for others with similar problems see &lt;a href="http://stackoverflow.com/q/3745177/848121"&gt;here&lt;/a&gt;, and &lt;a href="http://stackoverflow.com/q/2880975/848121"&gt;here&lt;/a&gt;). Plus, debugging &lt;code&gt;make&lt;/code&gt; is torture, surely against the Geneva Conventions.&lt;/p&gt;
&lt;p&gt;I &lt;em&gt;wanted&lt;/em&gt; to use &lt;code&gt;make&lt;/code&gt;, I swear I did. It's open source, well used, extensively tested, available on all relevant systems, etc. And I probably could have... but only by keeping the ugly hack or hard-coding the recipe for each model, and that just didn't jive with my recently acquired simple/reproducible mentality. Converts always are the most zealous, afterall.&lt;/p&gt;
&lt;h1 id="they-say-graduate-school-is-a-time-to-explore"&gt;They say graduate school is a time to explore&lt;/h1&gt;
&lt;p&gt;So what did I do? No, I didn't immediately start writing a make replacement with all of the features I wanted like some over-eager graduate student. Jeeze! What do you people think of me!? First I checked out the &lt;a href="http://freecode.com/articles/make-alternatives"&gt;extant alternatives&lt;/a&gt;... I hated everything. So &lt;em&gt;then&lt;/em&gt; I started writing a make replacement with all of the features I wanted.&lt;/p&gt;
&lt;p&gt;The result was one of the first pieces of general purpose software to come off my laptop which I wouldn't be entirely ashamed to show to an experienced programmer. It's rough, don't get me wrong, but it does everything I need and is actually kinda pretty internally. Well, at least it was before I fixed some glaring problems. Whatever. The point is I want to share &lt;a href="https://github.com/bsmith89/pymake"&gt;it&lt;/a&gt; with the world; what better stage exists for its introduction than this blog, which absolutely no one reads?&lt;/p&gt;
&lt;p&gt;...Yeah, I'll probably post it to &lt;a href="http://reddit.com/r/python"&gt;/r/python&lt;/a&gt; too.&lt;/p&gt;
&lt;p&gt;Tune in for Part II, in which I explain why &lt;em&gt;you&lt;/em&gt; should use my software.&lt;/p&gt;
</summary><category term="python"></category><category term="software"></category><category term="development"></category><category term="make"></category><category term="pipelines"></category><category term="bioinformatics"></category></entry></feed>