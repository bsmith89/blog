<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" type="image/x-icon" href="favicon.ico">
  <title>
Deep Ecology - Tutorial: Reproducible data analysis pipelines using Snakemake
  </title>
<!-- #feeds -->
<link href="https://test2.byronjsmith.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Deep Ecology Full Atom Feed" />
<link href="https://test2.byronjsmith.com/feeds/category/computing.atom.xml" type="application/atom+xml" rel="alternate" title="Deep Ecology Categories Atom Feed" />
<!-- /#feeds -->
  <link rel="stylesheet" type="text/css" href="https://test2.byronjsmith.com/theme/css/main.css" />
  <link rel="stylesheet" type="text/css" href="https://test2.byronjsmith.com/theme/css/pygment.css" />
<!-- #google-analytics-script -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-40659359-2', 'auto');
  ga('require', 'linkid', 'linkid.js');
  ga('send', 'pageview');

</script>
<!-- /#google-analytics-script -->


</head>

<body id="main">
<!-- #github-ribbon -->
<a href="https://github.com/bsmith89">
  <img style="position: absolute; top: 0; right: 0; border: 0;"
      src="https://camo.githubusercontent.com/38ef81f8aca64bb9a64448d0d70f1308ef5341ab/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f6461726b626c75655f3132313632312e706e67"
      alt="Fork me on GitHub"
      id="gh-ribbon" />
</a>
<!-- /#github-ribbon -->


  <div id="all-text">
    <header id="main-banner" class="banner">
<!-- page-chrome -->
<h1 id="blog-title">
  <a href="https://test2.byronjsmith.com/">
    Deep Ecology
    <span id="blog-subtitle">
      A blog of the new microbiology.
    </span>
  </a>
</h1>

<nav>
  <ul>
    <li>
      <a href="https://test2.byronjsmith.com/about.html"
         >
        About
      </a>
    </li>
    <li>
      <a href="https://test2.byronjsmith.com/category/biology.html"
>
        Biology
      </a>
    </li>
    <li>
      <a href="https://test2.byronjsmith.com/category/computing.html"
        class="active"
>
        Computing
      </a>
    </li>
    <li>
      <a href="https://test2.byronjsmith.com/category/data.html"
>
        Data
      </a>
    </li>
    <li>
      <a href="https://test2.byronjsmith.com/category/education.html"
>
        Education
      </a>
    </li>
    <li>
      <a href="https://test2.byronjsmith.com/category/misc.html"
>
        Misc.
      </a>
    </li>
  </ul>
</nav>
<!-- /page-chrome -->
    </header>
    <div id="page-content">
<article itemscope itemtype="https://schema.org/BlogPosting">
  <header>
    <h1 id="page-title" class="headline" itemprop="headline">
      <a href="https://test2.byronjsmith.com/snakemake-analysis.html" rel="bookmark"
         title="Permalink to Tutorial: Reproducible data analysis pipelines using Snakemake">
        Tutorial: Reproducible data analysis pipelines using Snakemake
      </a>
    </h1>
  </header>
<footer class="article-info">

  <div class="published">
    <span class="info-tag">published:</span>
    <span class="info-value" itemprop="datePublished">
      <abbr title="2017-11-19 17:00:00-05:00">
        Sunday, November 19, 2017
      </abbr>
    </span>
  </div>



  <div class="category">
    <span class="info-tag">category:</span>
    <span class="info-value" itemprop="articleSection">
      <a href="https://test2.byronjsmith.com/category/computing.html">
        Computing
      </a>
    </span>
  </div>

  <div class="tags">
    <span class="info-tag">tags:</span>
    <span class="info-value" itemprop="keywords">
      <ul class="article-tag-list">
        <li>
          <a href="https://test2.byronjsmith.com/tag/teaching.html">
            teaching
          </a>
        </li>
        <li>
          <a href="https://test2.byronjsmith.com/tag/programming.html">
            programming
          </a>
        </li>
        <li>
          <a href="https://test2.byronjsmith.com/tag/python.html">
            python
          </a>
        </li>
        <li>
          <a href="https://test2.byronjsmith.com/tag/pipelines.html">
            pipelines
          </a>
        </li>
        <li>
          <a href="https://test2.byronjsmith.com/tag/bioinformatics.html">
            bioinformatics
          </a>
        </li>
        <li>
          <a href="https://test2.byronjsmith.com/tag/software.html">
            software
          </a>
        </li>
      </ul>
    </span>
  </div><!-- /.tags -->

</footer>
  <div class="article-content" itemprop="articleBody">
    <p>In many areas of natural and social science, as well as engineering, data
analysis involves a series of transformations: filtering, aggregating,
comparing to theoretical models, culminating in the visualization and
communication of results.
This process is rarely static, however, and
components of the analysis pipeline are frequently subject to replacement
and refinement, resulting in challenges for reproducing computational
results.
Describing data analysis as a directed network of transformations
has proven useful for translating between human intuition and computer
automation.
In the past I've <a href="https://test2.byronjsmith.com/makefile-shortcuts.html">evangelized extensively for GNU Make</a>,
which takes advantage of this graph representation to enable incremental builds
and parallelization.</p>
<p><em>Snakemake</em> is a next-generation tool based on this concept and designed
specifically for bioinformatics and other complex, computationally
challenging analyses.
I've started using <em>Snakemake</em> for my own data analysis projects, and I've
found it to be a consistent improvement, enabling more complex pipelines with
fewer of the "hacks" that are often necessary when using <em>Make</em>.</p>
<p>I've taught <a href="https://test2.byronjsmith.com/make-analysis.html"><em>Make</em> workshops in the past</a>,
so, when I was invited to present to the Boise State University Joint
User Groups, I was excited to convert that tutorial to <em>Snakemake</em>.
Here, I've converted that tutorial into a blog post.
The original (and therefore this lesson as well) is inspired by the
<a href="https://swcarpentry.github.io/make-novice/">Software Carpentry <em>Make</em> lesson</a>,
to which I am also a contributor.</p>
<p>Some prior experience with the command line is assumed, and learners are
encouraged to follow along on their own computers.
The entire tutorial, including questions for the learner are designed to
take 2 hours as a live-coded, Software Carpentry style lesson.
A standalone lesson repository can be found <a href="https://github.com/bsmith89/snakemake-boise">here</a> and is
licensed CC-BY.</p>
<h1>Setup</h1>
<p>If not already on your computer, install the following prerequistes.</p>
<ul>
<li>A <em>Bash</em> terminal</li>
<li>Python 3.6 and the following packages<ul>
<li><code>snakemake</code></li>
<li><code>matplotlib</code></li>
<li><code>numpy</code></li>
</ul>
</li>
<li>The lesson assumes the following programs are also installed, but
    they're not absolutely necessary for the flow of the lesson,
    and/or alternatives are widely available:<ul>
<li><code>head</code></li>
<li><code>nano</code></li>
<li><code>dot</code></li>
<li><code>tree</code></li>
</ul>
</li>
</ul>
<p><a href="https://github.com/bsmith89/zipf-example">This example directory</a> should be downloaded to the user's
desktop and navigated into at the command line.
(e.g. <code>git clone https://github.com/bsmith89/zipf-example; cd zipf-example</code>)</p>
<h1>Motivation</h1>
<h2>Zipf's Law [10 minutes]</h2>
<blockquote>
<p>The most frequently-occurring word occurs approximately twice as
often as the second most frequent word. This is
<a href="http://en.wikipedia.org/wiki/Zipf%27s_law">Zipf's Law</a>.</p>
</blockquote>
<p>Let's imagine that we're interested in testing Zipf's law in some of our
favorite books.
We've compiled our raw data: the books we want to analyze,
and have prepared several Python scripts that together make up our
analysis pipeline.</p>
<p>The <code>tree</code> command produces a handy tree-diagram of the directory.
(You may not have this program installed on your computer.)</p>
<div class="highlight"><pre><span></span>.
├── analysis.sh
├── books
│   ├── LICENSE_TEXTS.md
│   ├── abyss.txt
│   ├── isles.txt
│   ├── last.txt
│   └── sierra.txt
├── matplotlibrc
├── requirements.pip
└── scripts
    ├── plotcount.py
    └── wordcount.py

2 directories, 10 files
</pre></div>


<p>Here you see that we're starting with a well designed project directory.
The raw data (books) are stored in their own directory, and scripts have
informative names.</p>
<p>Let's take a look at our raw data</p>
<div class="highlight"><pre><span></span>head books/isles.txt
</pre></div>


<p>Our first step is to count the frequency of each word in a book.</p>
<div class="highlight"><pre><span></span>scripts/wordcount.py books/isles.txt isles.tsv
</pre></div>


<p>Let's take a quick peek at the result.</p>
<div class="highlight"><pre><span></span>head -5 isles.tsv
</pre></div>


<p>shows us the top 5 lines in the output file:</p>
<div class="highlight"><pre><span></span>the 3822    6.7371760973
of  2460    4.33632998414
and 1723    3.03719372466
to  1479    2.60708619778
a   1308    2.30565838181
</pre></div>


<p>Each row shows the word itself, the number of occurrences of that
word, and the number of occurrences as a percentage of the total
number of words in the text file.</p>
<p>We can do the same thing for a different book:</p>
<div class="highlight"><pre><span></span>scripts/wordcount.py books/abyss.txt abyss.tsv
head -5 abyss.tsv
</pre></div>


<p>Finally, let's visualize the results.</p>
<div class="highlight"><pre><span></span>scripts/plotcount.py isles.tsv ascii
</pre></div>


<p>The <code>ascii</code> argument has been added so that we get a text-based
bar-plot printed to the screen.</p>
<p>The script is also able to render a graphical bar-plot using matplotlib
and save the figure to a named file.</p>
<div class="highlight"><pre><span></span>scripts/plotcount.py isles.tsv isles.png
</pre></div>


<p>Together these scripts implement a common workflow:</p>
<ol>
<li>Read a data file.</li>
<li>Perform an analysis on this data file.</li>
<li>Write the analysis results to a new file.</li>
<li>Plot a graph of the analysis results.</li>
<li>Save the graph as an image, so we can publish it.</li>
</ol>
<h2>Writing a script to do our analysis [5 minutes]</h2>
<p>Running this pipeline for one book is relatively simple using the command-line.
But once the number of files and the number of steps in the pipeline
expands, this can turn into a lot of work.
Plus, no one wants to sit and wait for a command to finish, even just for 30
seconds.</p>
<p>The most common solution to the tedium of data processing is to write
a master script that runs the whole pipeline from start to finish.</p>
<p>We can see such a script in <code>analysis.sh</code>, which contains:</p>
<div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env bash</span>
<span class="c1"># USAGE: bash analysis.sh</span>
<span class="c1"># to produce plots for isles and abyss.</span>

scripts/wordcount.py books/isles.txt isles.tsv
scripts/wordcount.py books/abyss.txt abyss.tsv

scripts/plotcount.py isles.tsv isles.png
scripts/plotcount.py abyss.tsv abyss.png

<span class="c1"># Archive the results.</span>
rm -rf zipf_results
mkdir zipf_results
cp isles.tsv abyss.tsv isles.png abyss.png zipf_results/
tar -czf zipf_results.tgz zipf_results
rm -r zipf_results
</pre></div>


<p>This master script solved several problems in computational reproducibility:</p>
<ol>
<li>It explicitly documents our pipeline,
    making communication with colleagues (and our future selves) more efficient.</li>
<li>It allows us to type a single command, <code>bash analysis.sh</code>, to
    reproduce the full analysis.</li>
<li>It prevents us from <em>repeating</em> typos or mistakes.
    You might not get it right the first time, but once you fix something
    it'll (probably) stay that way.</li>
</ol>
<h2>What are the problems with this approach? [10 minutes]</h2>
<p>A master script is a good start, but it has a few shortcomings.</p>
<p>Let's imagine that we adjusted the width of the bars in our plot
by editing <code>scripts/plotcount.py</code>;
in the function definition for
<code>plot_word_counts</code>, <code>width = 1.0</code> is now <code>width = 0.8</code>.</p>
<p>Now we want to recreate our figures.
We <em>could</em> <code>bash analysis.sh</code> again.
That would work, but it could also be a big pain if counting words takes
more than a few seconds.
The word counting routine hasn't changed; we shouldn't need to recreate
those files.</p>
<p>Alternatively, we could manually rerun the plotting for each word-count file
and recreate the archive.</p>
<div class="highlight"><pre><span></span><span class="k">for</span> file in *.tsv<span class="p">;</span> <span class="k">do</span>
    scripts/plotcount.py <span class="nv">$file</span> <span class="si">${</span><span class="nv">file</span><span class="p">/.tsv/.png</span><span class="si">}</span>
<span class="k">done</span>

rm -rf zipf_results
mkdir zipf_results
cp isles.tsv abyss.tsv isles.png abyss.png zipf_results/
tar -czf zipf_results.tgz zipf_results
rm -r zipf_results
</pre></div>


<p>But by then we've nullified many of the benefits of having a master script in
the first place.</p>
<p>Another popular option is to comment out a subset of the lines in
<code>analysis.sh</code>:</p>
<div class="highlight"><pre><span></span><span class="ch">#!/usr/bin/env bash</span>
<span class="c1"># USAGE: bash analysis.sh</span>
<span class="c1"># to produce plots for isles and abyss.</span>

<span class="c1"># These lines are commented out because they don&#39;t need to be rerun.</span>
<span class="c1">#scripts/wordcount.py isles.txt isles.tsv</span>
<span class="c1">#scripts/wordcount.py abyss.txt abyss.tsv</span>

scripts/plotcount.py isles.tsv isles.png
scripts/plotcount.py abyss.tsv abyss.png

<span class="c1"># Archive the results.</span>
rm -rf zipf_results
mkdir zipf_results
cp isles.tsv abyss.tsv isles.png abyss.png zipf_results/
tar -czf zipf_results.tgz zipf_results
rm -r zipf_results
</pre></div>


<p>Followed by <code>bash analysis.sh</code>.</p>
<p>But this process, and subsequently undoing it,
can be a hassle and source of errors in complicated pipelines.</p>
<p>What we really want is an executable <em>description</em> of our pipeline that
allows software to do the tricky part for us:
figuring out what steps need to be rerun.
It would also be nice if this tool encourage a <em>modular</em> analysis
and reusing instead of rewriting parts of our pipeline.
As an added benefit, we'd like it all to play nice with the other
mainstays of reproducible research: version control, Unix-style tools,
and a variety of scripting languages.</p>
<h1>Snakemake background [5 minutes]</h1>
<p><em>Snakemake</em> comes from a lineage of computer programs&mdash;most notably
 <em>Make</em>&mdash;originally designed to
automate the compilation and installation of software.
Programs like <em>Make</em> automate the building of target files through a series of
discrete steps.
Despite the original purpose, this design makes it a great fit for
bioinformatics pipelines, which usually work by transforming data from one form
to another
(e.g. <em>raw data</em> &#8594; <em>word counts</em> &#8594; <em>???</em> &#8594; <em>profit</em>).</p>
<p><em>Snakemake</em> is inspired by this approach, but designed specifically for
computationally intensive and/or complex data analysis pipelines.
The name is a reference to the programming language <em>Python</em>, which forms
the basis for the <em>Snakemake</em> syntax.
You don't need to be an expert at <em>Python</em> to use <em>Snakemake</em>, but it can
sometimes be very useful.
There are pros and cons to using <em>Snakemake</em> versus any other analysis pipeline
tools, and it is worth considering other options, including:</p>
<ul>
<li><em>GNU Make</em></li>
<li><em>doit</em></li>
<li><em>Galaxy</em></li>
</ul>
<h1>Tutorial</h1>
<h2>Writing and Running Snakefiles [10 minutes]</h2>
<p>Let's get started writing a description of our analysis for <em>Snakemake</em>.</p>
<p>Open up a file called <code>Snakefile</code> in your editor and add the following:</p>
<div class="highlight"><pre><span></span>rule wordcount_isles:
    input: &quot;books/isles.txt&quot;
    output: &quot;isles.tsv&quot;
    shell: &quot;scripts/wordcount.py books/isles.txt isles.tsv&quot;
</pre></div>


<p>We have now written the simplest, non-trivial snakefile.
The <code>shell:</code> line is pretty reminiscent of one of the lines from our master
script.
I bet you can already see what this snakefile means.</p>
<p>Let's walk through what we've written.
The first line uses the keyword <code>rule</code> followed by the name of our rule:
<code>wordcount_isles</code>.
We end that line with a colon.
All of the following lines in our rule are indented with four spaces.
The second line says that it takes an input file, using the <code>input</code>
keyword which is again followed by a colon.
We then give it the path to this prerequisite (<code>books/isles.txt</code>), wrapped in
quotes.
The third line does the same thing with the output file (<code>isles.tsv</code>).
And the last line is the exact shell command that we used in our shell script
earlier to create the target output file.
Like scripting, <em>Snakemake</em> allows us to wrap a series of shell commands, but
is more expressive and flexible than a script.</p>
<p>Our snakefile describes a (very short) pipeline:</p>
<ol>
<li>We are generating a file called <code>isles.tsv</code></li>
<li>Creating this file requires <code>books/isles.txt</code></li>
<li>The command to create this file runs the script runs <code>wordcount.py</code></li>
</ol>
<p>We'll think about our pipeline as a network of files that are dependent
on one another.
Right now our Snakefile describes a pretty simple <strong>dependency graph</strong>.</p>
<blockquote>
<p><code>books/isles.txt</code> &#8594; <code>isles.tsv</code></p>
</blockquote>
<p>where the "&#8594;" is pointing from requirements to targets.</p>
<h3>Running Snakemake</h3>
<p>Now that we have a (currently incomplete) description of our pipeline,
let's use <em>Snakemake</em> to execute it.</p>
<p>First, remove the previously generated files.</p>
<div class="highlight"><pre><span></span>rm *.tsv *.png zipf_results.tgz
</pre></div>


<div class="highlight"><pre><span></span>snakemake isles.tsv
</pre></div>


<p>You should see the following print to the terminal:</p>
<div class="highlight"><pre><span></span>Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
        count   jobs
        1       wordcount_isles
        1

rule wordcount_isles:
    input: books/isles.txt
    output: isles.tsv
    jobid: 0

Finished job 0.
1 of 1 steps (100%) done
</pre></div>


<p>By default, <em>Snakemake</em> prints a summary of the recipes that it
executes.</p>
<p>Let's see if we got what we expected.</p>
<div class="highlight"><pre><span></span>head -5 isles.tsv
</pre></div>


<p>The first 5 lines of that file should look exactly like before.</p>
<h3>Re-running Snakemake</h3>
<p>Let's try running <em>Snakemake</em> the same way again.</p>
<div class="highlight"><pre><span></span>snakemake isles.tsv
</pre></div>


<p>This time, instead of executing the same recipe,
<em>Snakemake</em> prints <code>Nothing to be done.</code></p>
<p>What's happening here?</p>
<p>When you ask <em>Snakemake</em> to make <code>isles.tsv</code> it first looks at
the modification time of that target.
Next it looks at the modification time for the target's prerequisites.
If the target is newer than the prerequisites <em>Snakemake</em> decides that
the target is up-to-date and does not need to be remade.</p>
<p>Much has been said about using modification times as the cue for remaking
files.
This can be another <em>Snakemake</em> gotcha, so keep it in mind.</p>
<p>If you want to induce the original behavior, you only have to
change the modification time of <code>books/isles.txt</code> so that it is newer
than <code>isles.tsv</code>.</p>
<div class="highlight"><pre><span></span>touch books/isles.txt
snakemake isles.tsv
</pre></div>


<p>The original behavior is restored.</p>
<p>Sometimes you only want <em>Snakemake</em> to tell you what it thinks about the
current state of your files.
<code>snakemake --dryrun isles.tsv</code> will print <em>Snakemake</em>'s execution plan,
without actually carrying it out.
The flag can also be abbreviated as <code>-n</code>.</p>
<p>If you don't pass a target as an argument to snakemake (i.e. run
<code>snakemake</code>) it will assume that you want to build the first target in the
snakefile.</p>
<h2>Expanding our Snakefile with more recipes (and challenge) [20 minutes]</h2>
<p>Now that <em>Make</em> knows how to build <code>isles.tsv</code>,
we can add a rule for plotting those results.</p>
<div class="highlight"><pre><span></span>rule plotcount_isles:
    input: &quot;isles.tsv&quot;
    output: &quot;isles.png&quot;
    shell: &quot;scripts/plotcount.py isles.tsv isles.png&quot;
</pre></div>


<p>The dependency graph now looks like:</p>
<blockquote>
<p><code>books/isles.txt</code> &#8594; <code>isles.tsv</code> &#8594; <code>isles.png</code></p>
</blockquote>
<p>Let's add a few more recipes to our Snakefile.</p>
<div class="highlight"><pre><span></span>rule wordcount_abyss:
    input: &quot;books/abyss.txt&quot;
    output: &quot;abyss.tsv&quot;
    shell: &quot;scripts/wordcount.py books/abyss.txt abyss.tsv&quot;

rule archive_results:
    input: &quot;isles.tsv&quot;, &quot;abyss.tsv&quot;, &quot;isles.png&quot;, &quot;abyss.png&quot;
    output: &quot;zipf_results.tgz&quot;
    shell:
        &quot;&quot;&quot;
        rm -rf zipf_results/
        mkdir zipf_results/
        cp isles.tsv abyss.tsv isles.png abyss.png zipf_results/
        tar -czf zipf_results.tgz zipf_results/
        rm -r zipf_results/
        &quot;&quot;&quot;
</pre></div>


<p>Here the recipe for <code>zipf_results.tgz</code> takes multiple input files,
each of which must be quoted and separated by commas, and involves
involves running a series of shell commands.
When building the archive, <em>Snakemake</em> will run each line successively unless
any return an error.</p>
<blockquote>
<h4>Question</h4>
<p>Without doing it, what happens if you run <code>snakemake isles.png</code>?</p>
<h4>Challenge</h4>
<p>What does the dependency graph look like for your Snakefile?</p>
<h4>Try it</h4>
<p>What happens if you run <code>snakemake zipf_results.tgz</code> right now?</p>
<h4>Practice</h4>
<p>Write a recipe for <code>abyss.png</code>.</p>
</blockquote>
<p>Once you've written a recipe for <code>abyss.png</code> you should be able to
run <code>snakemake zipf_results.tgz</code>.</p>
<p>Let's delete all of our files and try it out.</p>
<div class="highlight"><pre><span></span>rm abyss.* isles.*
snakemake zipf_results.tgz
</pre></div>


<p>You should get the something like the following output
(the order may be different)
to your terminal:</p>
<div class="highlight"><pre><span></span>Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
        count   jobs
        1       archive_results
        1       plotcount_abyss
        1       plotcount_isles
        1       wordcount_abyss
        1       wordcount_isles
        5

rule wordcount_abyss:
    input: books/abyss.txt
    output: abyss.tsv
    jobid: 1

Finished job 1.
1 of 5 steps (20%) done

rule wordcount_isles:
    input: books/abyss.txt
    output: abyss.tsv
    jobid: 2

Finished job 2.
2 of 5 steps (40%) done

rule plotcount_abyss:
    input: abyss.tsv
    output: abyss.png
    jobid: 4

Finished job 4.
3 of 5 steps (60%) done

rule plotcount_isles:
    input: isles.tsv
    output: isles.png
    jobid: 3

Finished job 3.
4 of 5 steps (80%) done

rule archive_results:
    input: isles.tsv, abyss.tsv, isles.png, abyss.png
    output: zipf_results.tgz
    jobid: 0

Finished job 0.
5 of 5 steps (100%) done
</pre></div>


<p>Since you asked for <code>zipf_results.tgz</code> <em>Snakemake</em> looked first for that file.
Not finding it, <em>Snakemake</em> looked for its prerequisites.
Since none of those existed it remade the ones it could,
<code>abyss.tsv</code> and <code>isles.tsv</code>.
Once those were finished it was able to make <code>abyss.png</code> and
<code>isles.png</code>, before finally building <code>zipf_results.tgz</code>.</p>
<blockquote>
<h4>Try it</h4>
<p>What happens if you <code>touch abyss.tsv</code> and
then <code>snakemake zipf_results.tgz</code>?</p>
</blockquote>
<h2>Running Snakemake in parallel</h2>
<p>And check this out!</p>
<div class="highlight"><pre><span></span>snakemake clean
snakemake --threads <span class="m">2</span>
</pre></div>


<p>Did you see it?
The <code>--threads 2</code> flag (just "<code>-j2</code>" works too) tells <em>Make</em> to run recipes in
two <em>parallel</em> threads.
Our dependency graph clearly shows that
<code>abyss.tsv</code> and <code>isles.tsv</code> are mutually independent and can
both be built at the same time.
Likewise for <code>abyss.png</code> and <code>isles.png</code>.
If you've got a bunch of independent branches in your analysis, this can
greatly speed up your build process.</p>
<h3>Phony targets</h3>
<p>Sometimes we want to build a bunch of different files simultaneously.</p>
<div class="highlight"><pre><span></span>rule all:
    input: &quot;isles.png&quot;, &quot;abyss.png&quot;
</pre></div>


<p>Even though this rule doesn't have a recipe, it does have prerequisites.
Now, when you run <code>snakemake all</code> <em>Snakemake</em> will do what it needs to to bring
both of those targets up to date.</p>
<p>It is traditional for "<code>all</code>" to be the first recipe in a snakefile,
since the first recipe is what is built by default
when no other target is passed as an argument.</p>
<p>Another traditional target is "<code>clean</code>".
Add the following to your snakefile.</p>
<div class="highlight"><pre><span></span>rule clean:
    shell: &quot;rm --force *.tsv *.png zipf_results.tgz&quot;
</pre></div>


<p>Running <code>snakemake clean</code> will now remove all of the cruft.</p>
<h2>Diagramming the DAG [5 minutes]</h2>
<p>(If you'd prefer not to bake this Snakefile from scratch, you can
get one we've been hiding in the oven the whole time:
<code>cp .extra/Snakefile.1 Snakefile</code>)</p>
<p>Right now, our snakefile looks like this:</p>
<div class="highlight"><pre><span></span># Dummy targets
rule all:
    input: &quot;isles.png&quot;, &quot;abyss.png&quot;

rule clean:
    shell: &quot;rm --force *.tsv *.png zipf_results.tgz&quot;

# Analysis
rule wordcount_isles:
    input: &quot;books/isles.txt&quot;
    output: &quot;isles.tsv&quot;
    shell: &quot;scripts/wordcount.py books/isles.txt isles.tsv&quot;

rule wordcount_abyss:
    input: &quot;books/abyss.txt&quot;
    output: &quot;abyss.tsv&quot;
    shell: &quot;scripts/wordcount.py books/abyss.txt abyss.tsv&quot;

# Plotting
rule plotcount_isles:
    input: &quot;isles.tsv&quot;
    output: &quot;isles.png&quot;
    shell: &quot;scripts/plotcount.py isles.tsv isles.png&quot;

rule plotcount_abyss:
    input: &quot;abyss.tsv&quot;
    output: &quot;abyss.png&quot;
    shell: &quot;scripts/plotcount.py abyss.tsv abyss.png&quot;

# Deliverables
rule archive_results:
    input: &quot;isles.tsv&quot;, &quot;abyss.tsv&quot;, &quot;isles.png&quot;, &quot;abyss.png&quot;
    output: &quot;zipf_results.tgz&quot;
    shell:
        &quot;&quot;&quot;
        rm -rf zipf_results/
        mkdir zipf_results/
        cp isles.tsv abyss.tsv isles.png abyss.png zipf_results/
        tar -czf zipf_results.tgz zipf_results/
        rm -r zipf_results/
        &quot;&quot;&quot;
</pre></div>


<p>Looks good, don't you think?
Notice the added comments, starting with the "<code>#</code>" character just like in
Python, R, shell, etc.</p>
<p>Using these recipes, a simple call to <code>snakemake</code> builds all the same files
that we were originally making either manually or using the master script, but
with a few bonus features.</p>
<p>Now, if we change one of the inputs, we don't have to rebuild everything.
Instead, <em>Snakemake</em> knows to only rebuild the files that, either directly or
indirectly, depend on the file that changed.
This is called an <strong>incremental build</strong>.
It's no longer our job to track those dependencies.
One fewer cognitive burden getting in the way of research progress!</p>
<p>In addition, a snakefile explicitly documents the inputs to and outputs
from every step in the analysis.
These are like informal "USAGE:" documentation for our scripts.</p>
<p>It is worth pointing out that our pipeline (and every pipeline) <em>must</em> be
acyclic: no file can be an input to itself or to any of its inputs, <em>ad
infinitum</em>.
Officially we talk about the relationships between files as a Directed Acyclic
Graph (DAG).
While earlier we took the time to diagram our DAG by hand, <em>Snakemake</em>
has tools for plotting this network automatically.</p>
<div class="highlight"><pre><span></span>snakemake --dag zipf_results.tgz <span class="p">|</span> dot -Tpng &gt; dag.png
</pre></div>


<p>Open that file and check it out.</p>
<p><img alt="A visualization of the analysis DAG" src="https://test2.byronjsmith.com/static/images/snakemake-dag.png"></p>
<p>Diagrams like this one can be a very useful way to debug problems with an
analysis pipeline.</p>
<h2>Don't repeat yourself</h2>
<p>In many programming language, the bulk of the language features are there
to allow the programmer to describe long-winded computational routines as
short, expressive, beautiful code.
Features in Python or R like user-defined variables and functions are
useful in part because they mean we don't have to write out (or think about)
all of the details over and over again.
This good habit of writing things out only once is known as the D.R.Y.
principle.</p>
<p>In <em>Snakemake</em> a number of features are designed to minimize repetitive code.
Our current snakefile does <em>not</em> conform to this principle,
but <em>Snakemake</em> is perfectly capable of doing so.</p>
<h3>Automatic variables [10 minutes]</h3>
<blockquote>
<h4>Question</h4>
<p>What are some of the repetitive components of our snakefile?</p>
</blockquote>
<p>One overly repetitive part of our Snakefile:
Inputs and outputs are in both the header <em>and</em> the recipe of each rule.</p>
<p>It turns out, that</p>
<div class="highlight"><pre><span></span>rule wordcount_isles:
    input: &quot;books/isles.txt&quot;
    output: &quot;isles.tsv&quot;
    shell: &quot;scripts/wordcount.py books/isles.txt isles.tsv&quot;
</pre></div>


<p>Can be rewritten as</p>
<div class="highlight"><pre><span></span>rule wordcount_isles:
    input: &quot;books/isles.txt&quot;
    output: &quot;isles.tsv&quot;
    shell: &quot;scripts/wordcount.py {input} {output}&quot;
</pre></div>


<p>Here we've replaced the input "<code>books/isles.txt</code>" in the recipe
with "<code>{input}</code>" and the output "<code>isles.dat</code>" with "<code>{output}</code>".
Both "<code>{input}</code>" and "<code>{output}</code>" are placeholders that refer to all of the
prerequisites and target of a rule, respectively.
In <em>Snakemake</em>, placeholders are all wrapped in opening and closing brackets,
and are replaced with the value of that variable at runtime.
If you are familiar with modern Python format strings, that's where the syntax
comes from.</p>
<p>Likewise</p>
<div class="highlight"><pre><span></span>rule archive_results:
    input: &quot;isles.tsv&quot;, &quot;abyss.tsv&quot;, &quot;isles.png&quot;, &quot;abyss.png&quot;
    output: &quot;zipf_results.tgz&quot;
    shell:
        &quot;&quot;&quot;
        rm -rf zipf_results/
        mkdir zipf_results/
        cp isles.tsv abyss.tsv isles.png abyss.png zipf_results/
        tar -czf zipf_results.tgz zipf_results/
        rm -r zipf_results/
        &quot;&quot;&quot;
</pre></div>


<p>can now be rewritten as</p>
<div class="highlight"><pre><span></span>rule archive_results:
    input: &quot;isles.tsv&quot;, &quot;abyss.tsv&quot;, &quot;isles.png&quot;, &quot;abyss.png&quot;
    output: &quot;zipf_results.tgz&quot;
    shell:
        &quot;&quot;&quot;
        rm -rf zipf_results/
        mkdir zipf_results/
        cp {input} zipf_results/
        tar -czf {output} zipf_results/
        rm -r zipf_results/
        &quot;&quot;&quot;
</pre></div>


<p>That's a little less cluttered,
and still perfectly understandable once you know what the variables mean.
The best part, is that if I want to change the input files, I only need to
edit my snakefile in one place.</p>
<blockquote>
<h4>Try it</h4>
<p>```bash
snakemake clean
snakemake isles.tsv
``````````
<!--Those extra backticks are because of Vim syntax highlighting.--></p>
</blockquote>
<p>You should get the same output as last time.
Internally, <em>Snakemake</em> replaced "<code>{output}</code>" with "<code>isles.tsv</code>"
and "<code>{input}</code>" with "<code>books/isles.txt</code>"
before running the recipe.</p>
<blockquote>
<h4>Practice</h4>
<p>Go ahead and rewrite all of the rules in Snakefile to minimize
repetition and take advantage of the "<code>{input}</code>" and "<code>{output}</code>"
placeholders.</p>
</blockquote>
<h3>Wildcard Filenames [10 minutes]</h3>
<p>Another deviation from D.R.Y.:
We have nearly identical recipes for <code>abyss.tsv</code> and <code>isles.tsv</code>.</p>
<p>It turns out we can replace <em>both</em> of those rules with a single rule,
by telling <em>Snakemake</em> about the relationships between filenames with
<em>wildcards</em>.</p>
<p>Using wildcards looks like this</p>
<div class="highlight"><pre><span></span>rule wordcount:
    input: &quot;books/{name}.txt&quot;
    output: &quot;{name}.tsv&quot;
    shell: &quot;scripts/wordcount.py {input} {output}&quot;
</pre></div>


<p>Here we've replaced the book name with "<code>{name}</code>".
The "<code>{name}</code>" matches any part of the input filename between "<code>books/</code>"
and "<code>.txt</code>", and must be the same as "<code>{name}</code>" in the output filename.
You don't have to use "name" as your wildcard name, and you should be
descriptive.</p>
<p>This rule can be interpreted as:</p>
<blockquote>
<p>In order to build a file named <code>[something].tsv</code> (the target)
find a file named <code>books/[that same something].txt</code> (the prerequisite)
and run <code>scripts/wordcount.py [the prerequisite] [the target]</code>.</p>
</blockquote>
<p>Notice how helpful the automatic input/output variables were here.
This recipe will work no matter what stem is being matched!</p>
<p>Go ahead and make this change in your snakefile.</p>
<blockquote>
<h4>Try it</h4>
<p>After you've replaced the two rules with one
rule using wildcards, try removing all of the products (<code>snakemake clean</code>)
and rerunning the pipeline.</p>
<p>Is anything different now that you're using the new, universal rule?</p>
<h4>Practice</h4>
<p>Replace the rules for <code>abyss.png</code> and <code>isles.png</code>
with a single rule.</p>
<h4>Challenge</h4>
<p>Add <code>books/sierra.txt</code> to your pipeline.</p>
<p>(i.e. <code>snakemake all</code> should plot the word counts and add the plots to
<code>zipf_results.tgz</code>)</p>
</blockquote>
<p>(If you'd prefer a pre-cooked snakefile: <code>cp .extra/Snakefile.2 Snakefile</code>)</p>
<h2>Scripts as prerequisites [10 minutes]</h2>
<p>We've talked a lot about the power of <em>Snakemake</em> for
rebuilding research outputs when input data changes.
When doing novel data analysis, however, it's very common for our <em>scripts</em> to
be as or <em>more</em> dynamic than the data.</p>
<p>What happens when we edit our scripts instead of changing our data?</p>
<blockquote>
<h4>Try it</h4>
<p>First, run <code>snakemake all</code> so your analysis is up-to-date.</p>
<p>Let's change the default number of entries in the rank/frequency
plot from 10 to 5.</p>
<p>(Hint: edit the function definition for <code>plot_word_counts</code> in
<code>plotcount.py</code> to read <code>limit=5</code>.)</p>
<p>Now run <code>snakemake all</code> again.  What happened?</p>
</blockquote>
<p>As it stands, we have to run <code>snakemake clean</code> followed by <code>snakemake all</code>
to update our analysis with the new script.
We're missing out on the benefits of incremental analysis when our scripts
are changing too.</p>
<p>There must be a better way...and there is.
Scripts should be considered inputs too!</p>
<p>Let's edit the rule for <code>{name}.png</code> to include <code>plotcount.py</code>
as an input.</p>
<div class="highlight"><pre><span></span>rule plotcount:
    input:
        script=&quot;scripts/plotcount.py&quot;,
        data=&quot;{name}.tsv&quot;
    output: &quot;{name}.png&quot;
    shell: &quot;{input.script} {input.data} {output}&quot;
</pre></div>


<p>Here we've assigned names to our two inputs.</p>
<p>This recipe works because "<code>{input.script}</code>" is replaced with
"<code>scripts/plotcount.py</code>"
and "<code>{input.data}</code>" with the appropriate expansion of "<code>{name}.tsv</code>".
When building <code>abyss.png</code>, for instance,
"<code>{input.script} {input.data} {output}</code>" becomes
"<code>scripts/plotcount.py abyss.tsv abyss.png</code>", which is exactly what we want.</p>
<blockquote>
<h4>Try it</h4>
<p>What happens when you run the pipeline after modifying your script again?</p>
<p>(Changes to your script can be simulated with <code>touch plotcount.py</code>.)</p>
<h4>Practice</h4>
<p>Update your other rules to include the relevant scripts as inputs.</p>
</blockquote>
<p>(Final snakefile: <code>cp .extra/Snakefile.3 Snakefile</code>)</p>
<h1>Conclusion [1 minutes]</h1>
<p>I hope that I've convinced you of the value of <em>Snakemake</em> for data analysis.
What I have shown you today barely scratches the surface of the software's
functionality;
I encourage you to check out the <a href="https://snakemake.readthedocs.io">website</a>.
In my experience, though, the topics we've gone over today already provide
90% of the benefits:
we can forget about script names
and intermediate steps and focus instead on the output files that we want.
This <a href="https://en.wikipedia.org/wiki/Declarative_programming">'declarative'</a> approach to pipelines
pipelines has transformed the way I do data analysis.
I think it can do the same for you.</p>
  </div>
  
</article>
<div class="comments">
  <h2>Comments</h2>
  <div id="disqus_thread"></div>
</div>
<script type="text/javascript">
    var disqus_shortname = 'byronjsmithblog';
    var disqus_identifier = 'snakemake-analysis.html';
    var disqus_title = 'Tutorial: Reproducible data analysis pipelines using Snakemake';
    var disqus_url = 'https://test2.byronjsmith.com/snakemake-analysis.html';
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the
  <a href="https://disqus.com/?ref_noscript" rel="nofollow">
    comments powered by Disqus.
  </a>
</noscript>



    </div>
    <footer id="bottom">
<div id="extras">
  <div class="blogroll">
    <h2>blogroll</h2>
    <ul>
      <li><a href="http://ivory.idyll.org/blog/">Living in an Ivory Basement</a></li>
      <li><a href="http://www.johndcook.com/blog/">The Endeavor</a></li>
    </ul>
  </div>
  <div class="social">
    <h2>social</h2>
    <ul>
      <li><a  href="https://test2.byronjsmith.com/feeds/all.atom.xml"
          type="application/atom+xml"
          rel="alternate">
        atom feed
      </a></li>
      <li><a href="https://twitter.com/ByronJSmith">twitter</a></li>
      <li><a href="https://linkedin.com/profile/view?id=76273001">linkedin</a></li>
      <li><a href="https://github.com/bsmith89">github</a></li>
    </ul>
  </div>
</div><!-- /#extras -->

<div id="site-info">
  <p id="site-copyright">
    The contents of this blog are licensed <a rel="license" href="https://creativecommons.org/licenses/by/4.0"><img title="CC-BY" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a>
  </p>
  <p id="theme-info">
    This <a href="https://github.com/bsmith89/blog-theme">theme</a>
    was originally created for
    <a href="http://blog.byronjsmith.com">blog.byronjsmith.com</a>
    and is powered by <a href="https://getpelican.com">Pelican</a>
  </p>
</div>
    </footer>
  </div>

<!-- #mathjax-scripts -->
<!-- Using MathJax, with the delimiters $ -->
<!-- Conflict with pygments for the .mo and .mi -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  "HTML-CSS": {
  styles: {
  ".MathJax .mo, .MathJax .mi": {color: "black ! important"}}
  },
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']],processEscapes: true}
  });
  MathJax.Hub.Register.StartupHook("HTML-CSS Jax Ready",function () {
  var VARIANT = MathJax.OutputJax["HTML-CSS"].FONTDATA.VARIANT;
  VARIANT["normal"].fonts.unshift("MathJax_SansSerif");
  VARIANT["bold"].fonts.unshift("MathJax_SansSerif-bold");
  VARIANT["italic"].fonts.unshift("MathJax_SansSerif-italic");
  VARIANT["-tex-mathit"].fonts.unshift("MathJax_SansSerif-italic");
  });
  MathJax.Hub.Register.StartupHook("SVG Jax Ready",function () {
  var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;
  VARIANT["normal"].fonts.unshift("MathJax_SansSerif");
  VARIANT["bold"].fonts.unshift("MathJax_SansSerif-bold");
  VARIANT["italic"].fonts.unshift("MathJax_SansSerif-italic");
  VARIANT["-tex-mathit"].fonts.unshift("MathJax_SansSerif-italic");
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
<!-- /#mathjax-scripts -->


</body>
</html>